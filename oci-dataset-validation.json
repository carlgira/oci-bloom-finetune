[
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Oracle Cloud Agent service, \n Step 2: Verify that Oracle Cloud Agent is Running, \nAfter you confirm that Oracle Cloud Agent is installed, follow these steps to confirm that it is running.\n\nConnect to the instance and run one of the following commands to restart Oracle Cloud Agent.Oracle Linux 6.xinitctl status oracle-cloud-agentExpected response if Oracle Cloud Agent is running:oracle-cloud-agent start/running, process 13809Oracle Linux 7.x and later versionssystemctl is-enabled oracle-cloud-agent &>/dev/null && echo \"OCA is enabled\" || echo \"OCA is disabled\" \\\n && systemctl is-active oracle-cloud-agent &> /dev/null && echo \"OCA is running\" || echo \"OCA is not running\"Expected response if Oracle Cloud Agent is running:OCA is enabled\nOCA is runningUbuntusnap services oracle-cloud-agentExpected response if Oracle Cloud Agent is running:Service                               Startup Current Notes\noracle-cloud-agent.oracle-cloud-agent enabled active  -Windows ServerRun the command in Windows PowerShell as an administrator.sc.exe query \"OCA\"|findstr \"RUNNING\"Expected response if Oracle Cloud Agent is running:STATE : 4 RUNNING\nIf the message indicating that Oracle Cloud Agent is running does not display after you run the command, run the diagnostic tool and then file a support ticket with the file that contains debugging information and logs for the plugins. If Oracle Cloud Agent is running, proceed to the next step to verify that it can connect to Oracle services.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Document Understanding, \nFor known issues with Document Understanding, see Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Language, \nCurrently, there are no known issues with the Language\n            service.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Oracle Cloud Marketplace Territory and Export Compliance Policy service, \n \nFirst Publication: 04-Dec-2019\nRevised: 29-Mar-2022\nThe Oracle Cloud Marketplace Territory Policy (\u00e2\u0080\u009cPolicy\u00e2\u0080\u009d) outlines the territory restrictions that apply to various listings of Marketplace Content on the Oracle Cloud Marketplace. This Policy is subject to change or termination at any time at Oracle's sole discretion without prior notice.\nMarketplace Content\n\"Marketplace Content\" means any content that publisher promotes, licenses, sells, or grants access to customers through the Oracle Cloud Marketplace including but not limited to content delivered via a software-as-a-service model, any related technical support or other services publisher provides, content description information, and any marketing or promotion materials related to publisher\u00e2\u0080\u0099s products and services. \nTerritory for Bring Your Own License (BYOL) and Free Listings of Marketplace Content; Roving Edge Exportable Listings\nThe territory for Bring Your Own License (BYOL) and Free Listings shall be worldwide, subject to the Export section of this Policy. For BYOL or Free Listings only, publisher may be enabled to choose, through a mechanism within the Oracle Cloud Marketplace designated by Oracle for such purpose, to designate its BYOL or Free Listing as \u00e2\u0080\u009cRoving Edge Exportable\u00e2\u0080\u009d, which listing shall remain subject to the preceding sentence of this Territory Policy. Publisher acknowledges and agrees that listings of Marketplace Content that are designated as \u00e2\u0080\u009cRoving Edge Exportable\u00e2\u0080\u009d in accordance with the foregoing may be distributed, transmitted, or otherwise made available by Oracle through or into Oracle Roving Edge Infrastructure (as described in the applicable service descriptions at Oracle.com/contracts) that has been procured by the applicable customer. \nTerritory for Paid Publisher Listings of Marketplace Content\n \nThe territory for Paid Publisher Listings shall be as set forth below, subject to the Export section of this Policy and the terms of the applicable publisher agreement and any amendments thereto executed between Oracle and publisher:\n \nPublisher Domicile: United States.\n \nCustomer Domicile: United States, Japan*, Canada, United Kingdom, or Brazil.\n \nCurrency of Paid Publisher Listing (Customer Currency): The applicable customer currency(ies) for each market (country) are listed in italics below. Publishers may elect between available customer currencies for a Paid Publisher Listing in a given market (country); however, customers in such market (country) whose subscription is not aligned to the customer currency chosen by the publisher may not be able to transact that Paid Publisher Listing.\n \nCustomer Currency(ies) by Market (Country):\nUNITED STATES = USD\nCANADA = CAD, USD\nUNITED KINGDOM = GBP, USD\nBRAZIL = BRL, USD\n\nCurrency of Remittance of Payment from Oracle to Publisher (Remittance Currency): United States Dollar. With respect to Paid Publisher Listings transacted with a customer in a currency other than the United States Dollar, Oracle will convert the customer currency into the remittance currency via Oracle\u00e2\u0080\u0099s calculation of the applicable currency conversion rate based on Bloomberg\u00e2\u0080\u0099s reported spot currency rates at the close of the day that is three days prior to the end of the calendar month in which the customer used the Paid Publisher Listing.\nData Center Domicile: Any Oracle data center worldwide.\n*Japan \u00e2\u0080\u0093 Currently limited to a single customer entity domiciled in Japan with a Dedicated Region Oracle data center in Japan and the following requirements: 1) publisher entity domicile in United States or Japan, and 2) customer currency and remittance currency are United States Dollar.\nExport Compliance\nYou are responsible for complying with all U.S. and applicable import, re-import, export, and re-export control and economic sanctions (\u00e2\u0080\u009cTrade Compliance\u00e2\u0080\u009d) laws and regulations. You may not access, download, use, or export Marketplace Content provided on or through the Oracle Cloud Marketplace in violation of U.S. or applicable Trade Compliance laws and regulations. Neither the services or products of Oracle nor the underlying information or technology may be downloaded or otherwise provided or made available, either directly or indirectly, into any country subject to U.S. trade sanctions, (Supplement No. 1 to Part 740, Export Administration Regulations, Country Group E:1), to individuals or entities controlled by such countries, or to nationals or residents of such countries other than nationals who are lawfully admitted permanent residents of countries not subject to such sanctions. As applicable, You shall obtain and bear all expenses related to any necessary licenses, authorizations, and/or exemptions with respect to Your own use of the services of Oracle. \nYou are responsible for any violation of the Trade Compliance laws and regulations applicable to Your Marketplace Content and the manner in which You use the Oracle Cloud Marketplace including Your transfer, upload, and download of Your Marketplace Content and the provision of Your Marketplace Content to Customers. \nIn order to publish your Marketplace Content, Oracle requires export classification information including the applicable U.S. Export Control Classification Number (ECCN) for your data, goods, software, or technology. \nYou agree that You will not publish Marketplace Content nor provide any executables that require Customer download and/or installation. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Model Deployments service, \n Error Occurred when Starting the Web Server, \nEnable the model deployment predict logs to help you debug the errors. Generally, this happens when your code has issues or is missing required dependencies.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Completing a Migration Project service, \n In Oracle Cloud Migrations, after you successfully migrate\n        to the target environment and validate the migration assets, you must mark the project as\n        complete.\nAfter you mark a migration project as complete, the migration modules are blocked\n            from attempting to discover further changes to the source environment or suggesting new\n            recommendations.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Deleting an Artifact service, \n Using the API, \nTo delete a reference to an artifact, use the DeleteDeployArtifact operation.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating and Training Models service, \n Using the Console, \n\nOpen the navigation menu and click Analytics & AI. Under AI Services, click Anomaly Detection. \n\nYou can use an existing project (skip to step 8), or create a new project. To create a new project, click Create Project.\n\nSelect a compartment for the resource.\nYou can select a different compartment to store the resource instead of the default.\n\nEnter a unique name (255 character limit) for the resource. If you don't provide a name, a name is automatically generated for you using the format aianomalydetectionprojectYYYYNNDDHHMMSS. For example, aianomalydetectionproject20221125155844.\n\nEnter a description (400 character limit) for the resource. If you don't add a description, it remains empty.\n\nClick Create.\n\nChoose the project you want to use.\n\nClick Create and Train Model\n\nSelect an existing data asset if any exist or click Create a\n                            new data asset.\n\nClick Next.\n\nSet the target False Alarm Probability (FAP) in the 0 to 0.05 range.\n\nFAP indicates model performance. Lower FAP indicates better model\n                        performance.\n\n\nSet the training fraction ratio in the 0.5 to 0.8 range.\n\nTraining Fraction Ratio indicates the split ratio between training data and\n                        validation data\n\n\nAdd tags to easily locate and track resources by\n                    selecting a tag namespace, then entering the key and value. To add more than one\n                    tag, click +Additional Tags.\n\nTagging describes the various tags\n                        that you can use organize and find resources including cost-tracking tags.\n\n\nClick Create.\nTraining a model can take awhile. The page is automatically refreshed every 20\n                    seconds.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Certificate Authorities service, \n Using the Console, \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Pod Security Policies with Container Engine for Kubernetes service, \n Using the Console to Enable the PodSecurityPolicy Admission Controller, \nTo enable the PodSecurityPolicy admission controller when creating new clusters using the Console:\n\nLog in to the Console.\n\nFollow the instructions to create a new cluster in Using the Console to create a Cluster with Explicitly Defined Settings in the 'Custom Create' workflow, click Show Advanced Options, and select the Pod Security Policies\n                        - Enforced option. This option enables the PodSecurityPolicy admission\n                    controller.\nNo application pods will be accepted into the new cluster unless suitable pod security policies exist, along with  roles (or clusterroles) and rolebindings (or clusterrolebindings) to associate pods with policies. \n\nFollow the instructions to set the remaining cluster details, and click Create Cluster to create the new cluster.\n\nFollow the instructions in Creating a Pod Security Policy for Application Pods to create pod security policies for the PodSecurityPolicy admission controller to enforce when accepting pods into the new cluster.\n\n\nTo enable the PodSecurityPolicy admission controller in existing clusters using the Console:\n\n\nFollow the instructions in Creating a Pod Security Policy for Application Pods to create pod security policies for the PodSecurityPolicy admission controller to enforce when accepting pods into the existing cluster.\nWe strongly recommend you first verify the pod security policies in a development or test environment. That way, you can be sure the  pod security policies work as you expect and correctly allow (or refuse) pods to start on the cluster.\n\nIn the Console, open the navigation menu and click Developer Services. Under Containers, click Kubernetes Clusters (OKE).\nChoose a Compartment you have permission to work in.\nOn the Cluster List page, click the name of the cluster you want to modify.\nOn the Cluster Details tab, click Not Enforced beside Pod Security Policies.\n\nIn the Pod Security Policies window, select Enforced. \nFrom now on, no new application pods will be accepted into the cluster unless suitable pod security policies exist, along with  roles (or clusterroles) and rolebindings (or clusterrolebindings) to associate pods with policies. Note that any currently running pods will continue to run regardless.\n\nClick Save Changes.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Summary Information on the Overview Page service, \n Understanding the Risk Score, The Risk Score on the Overview page provides a rough estimate of the risk level to your\n        environment that's posed by the problems that Cloud Guard\n        detects.\n\nThe risk score is related to the number and severity of problems. In general,\n                organizations with many more resources are likely to have more problems, and thus a\n                higher risk scores. The risk score is closely related to the \"potential surface\n                area\" of risk. If you have many OCI resources, you might have an excellent security\n                score (overall assessment) and still have a higher risk score.\n\nViewing the Risk Score\n\nFrom the Cloud Guard options panel on the left, select\nOverview.\nView the Risk Score tile in the top center.\n\n\nHow the Risk Score is Calculated\n\nThe numeric risk score is updated every 15 minutes, and reflects the total\n                    number of problems that Cloud Guard has detected, the risk level of each\n                    problem, and the types of resources involved.\n                        Different\n                        categories of resources are more sensitive to security threats and that\n                        sensitivity weights the scoring. For example, users (IAM) and buckets are\n                        considered more sensitive, based on factors such as how easy they are to\n                        access and how they can be used as a target of attack.\nThe raw risk score that\u00e2\u0080\u0099s calculated is normalized to fall within the range of\n                    0-9,999. A risk score of zero would mean that no problems were detected for any\n                    resources. A high risk score generally means there are a larger number of\n                        problems that have higher risk levels (HIGH or CRITICAL). If the problems\n                        and the resources involved are less sensitive, a large number of problems\n                        doesn\u00e2\u0080\u0099t produce a high risk score. \nBest practice for security is to give priority to addressing the problems with\n                    the highest risk levels, that Cloud Guard\n                    detects on the most sensitive resources. Following this best practice also\n                    produces the greatest reduction in the risk score.\n\n Note\nThe risk score reflects monitoring for the past 30 days. Cloud Guard updates the risk score calculation\n                    continuously.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Accessing Partner Portal service, \n Prerequisites, \nBefore you add an Oracle Cloud Infrastructure tenancy, complete the following\n                prerequisites:\n\nYou must have subscription to the US East (Ashburn) region.\nAny custom images that you want to use in your listing must be available in the US\n                East (Ashburn) region.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Notebook Sessions to Build and Train Models service, \n Working with Existing Code Files, \nYou can create new files or work with your own existing files.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Cloud Guard service, \n No Problems Detected, Fix enablement problems that prevent Cloud Guard from detecting problems.\n\nYou have completed the steps in Enabling Cloud Guard, and no problems\n                start to appear on the Problems page after about 30-60 minutes.\n\nEnsure that a Detector Recipe Is Added to the Target\nSteps in Enabling Cloud Guard force you to define a target, by\n                specifying Compartments To Monitor in the OCI tenancy. If you\n                didn't also select either an OCI Configuration Detector Recipe or an OCI\n                    Activity Detector Recipe, then no detectors were added to the target.\n                Without adding at least one detector to the target, no problems can be reported.\nSee Modifying Recipes Added to an OCI Target.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n View Related Documentation, Use the Help menu to access documentation and support.\nThe listed documentation relates to the current Console page.\nOpen the \nHelp menu () and click the documentation link you want.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n Use a Search Engine, \nFor common issues, someone else has likely asked this question in the past. You can use\n            scoped search to look for answers in Oracle documentation and Oracle forum platforms \u00e2\u0080\u0093\n            Cloud Customer Connect and Stack Overflow. To perform a scoped search, go to your\n            favorite search engine and specify the site URLs along with your specific search terms,\n            as follows: \n<Your Search Terms> (site:docs.cloud.oracle.com/iaas OR site:cloudcustomerconnect.oracle.com OR site:stackoverflow.com)\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Copying a Conda Environment to Another Region service, \n 2. Publish a Conda Environment in Region 1, Register bucket-1 with\n            my-first-notebook-session.\n\nIn the Console's top navigation bar, select\n                    <region-1>.\n\nIn the left navigation, under List Scope, select the\n                        data-science-work compartment.\n\nOpen the navigation menu and click Analytics & AI.\n                    Under Machine Learning, click Data\n                        Science.\n\nUnder the list of projects, click Initial Project.\n\nClick my-first-notebook-session and then click\n                        Open.\n\nEnter your credentials to access the JupyterLab interactive notebook.\n\nIn the UI, if you don't have a tab called Launcher, click\n                        File, and then New\n                    Launcher.\n\nIn the Launcher, under Other, click the\n                        Terminal icon to start a new terminal session.\n\nIn the terminal, enter the following command.\n\nReplace <tenancy-namespace> with the information that\n                        you gathered in the Create Buckets section.\nodsc conda init -b bucket-1 -n <tenancy-namespace>\n\n\nGo to File, and then click Open from\n                        Path.... In the Open Path field,  enter\n                        /conda.\n\nTo confirm that the preceding command registered your bucket with your\n                    notebook, under the conda folder, click\n                        config.yaml and find bucket-1 and your\n                    namespace in the following block of code:\n\nauth_mode: resource_principal\nbucket_info:\n  name: bucket-1\n  namespace: <tenancy-namespace>\npack_prefix: conda_environments\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managed Access Overview service, \n Learn About Oracle Managed Access, Understand key concepts related to the Oracle Managed Access service.\nWorkflow\nManaged Access allows authorized operators to request\n        access to your organization's resources through a secure workflow. Operators make the\n        request when they need to troubleshoot or fix an issue with a resource. The request is sent\n        to the customer, and is displayed on the Access Requests page. Your organization's approvers\n        can approve or deny a request for access to a resource. You can choose to automatically\n        approve requests, or manually approve a request, by creating a template on the Request\n        Templates page. Managed Access allows up to three levels of\n        approvers.\n\nKey Terms\n\nLockbox\nA resource that support representatives use to request access to your organization's\n            tenancy.\nAccess request\n\nAn authorized operator's request to access a resource for troubleshooting and\n              resolving issues.\n\nTarget resource\nThe resource that support representatives want to access.\nResource type\nThe type of resource that support representatives want to access. \nRequest state\nThe access states supported for requests. For a complete list, see Request States\nAccess duration\nThe amount of time that authorized operators have to access a resource.\nApproval template\nThe rules that define how requests are processed. You can include up to three\n            approvers in the template.\nAutomatic approval\nAn approval template option that lets you automatically approve requests from\n            authorized operators. This option automates approval only for your workflow. Oracle has\n            a workflow that it follows before a request is approved and sent to you.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Notebook Sessions to Build and Train Models service, \n Using Custom Environment Variables, Use your own custom environment variables in notebook sessions.\nAfter you define your custom environment variables, access these environment variables in your notebook session with the Python os library. For example, if you define a key value pair with key of MY_CUSTOM_VAR1 and value of VALUE-1, then when you run the following code, you get VALUE-1. \nimport os \nmy_custom_var1 = os.environ[\u00e2\u0080\u0098MY_CUSTOM_VAR1\u00e2\u0080\u0099]\nprint(my_custom_var1)\n\n Note The system does not allow you to overwrite the system provided\n          environment variables with your custom ones. For example, you cannot name your\n        custom variable, USER_OCID. \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Streaming service, \n Troubleshooting Production and Consumption, \nMessages do not appear in the Console after\n                publishing them to a stream\nYou must click the Refresh button to show the first 100\n                messages. See Using the Console to show recent messages for more information.\nBecause streams using private endpoints are not accessible from the internet, their messages do not display in the Console.\n\nConsumers receive a \"The cursor is outside the\n                retention period and is now invalid\" message and a 400 error\nWhen requesting messages from a stream, a consumer might see an error message like\n                the following:\n(400, InvalidParameter, false) The cursor is outside the retention period and is now invalid\nThis error means that the offsets stored for one or more of your partitions has\n                fallen behind the trim horizon. Some data loss has occurred, and the data that was\n                produced to the stream is no longer available for consumption. Data that is outside\n                the retention period can't be recovered. At this point, the administrator must\n                decide the best course of action, given the use case. \nThis error can happen if you are not committing offsets regularly, or if your\n                consumer falls behind constantly. For more information, see Getting Messages.\nA manual call to the UpdateGroup method is required to reset the\n                cursor for the instances within a consumer group.\n\nConsumers receive a \"Trying to commit unreserved\n                partition\" message and a 400 error\nWhen requesting messages from a stream, a consumer that is part of a consumer group\n                might see an error message like the following:\n(400, InvalidParameter, false) Trying to commit unreserved partition\nThis error means that the consumer tried to commit an offset for a partition that was\n                not reserved for that particular consumer. This error can happen when the consumer\n                appears to have timed out, partitions are rebalanced to another consumer, and then\n                the consumer tries to commit offsets. The default timeout is 30 seconds for a\n                consumer. Timeouts for a consumer can be extended by sending a heartbeat. See Consuming as a Group for more\n                information.\nThis error can also occur when pipelining (commitOnGet=false) and no\n                commits occurred for a significant amount of time (more than 30 seconds).\n\nRequest fails with an \"Unable to parse JSON body\"\n                message and a 400 error\nWhen you send a request to Streaming, you might see\n                an error message similar to the following:\n(400, Unable to parse JSON body)\nThis error generally means that the JSON body contains an entry in an invalid\n                format.\n\nRuby SDK requests fail with an \"Unable to parse JSON\n                body\" message and a 400 error\nWhen you send a request to Streaming using the Ruby SDK, you might see an error message similar to the following:\nUnable to parse JSON body, 'status': 400, 'code': 'InvalidParameter'\nThe Ruby SDK doesn't do any encoding. You must use Base64 to encode\n                the strings that are sent in the key and value fields. For example:\nmsgs << OCI::Streaming::Models::PutMessagesDetailsEntry.new(key: Base64.strict_encode64(k), value: Base64.strict_encode64(record.to_json))\n \nif msgs.length > 0\n    res = @oss_client.put_messages(@stream_ocid, OCI::Streaming::Models::PutMessagesDetails.new(messages: msgs))\nend\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Updating API Gateways and API Deployments service, \n \nHaving created an API\u00c2\u00a0gateway, and deployed an API on the API\u00c2\u00a0gateway by creating an API\u00c2\u00a0deployment, you might decide to change either or both. For example, to change the API gateway's name or the tags applied to it, or to change an API deployment specification to add additional back ends to the API deployment. \nNote that there are some properties of API gateways and API deployments for which you cannot change the original values.\nYou can update API\u00c2\u00a0gateways and API deployments using the Console, the CLI, and the API.\nYou can update an API\u00c2\u00a0deployment specification by: \n\nusing dialogs in the Console\nediting a JSON file\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Service Connectors service, \n Deactivation for Unknown Reasons, Troubleshoot a deactivated service connector.\n\nA service connector's status is Deactivated and you didn\u00e2\u0080\u0099t deactivate it.\n\n\nSomeone Else Deactivated the Service Connector\nThe service connector was deactivated by someone else:\n\nAnother user at your organization\nOracle Cloud InfrastructureAny service connector that continuously fails for seven days is deactivated by the service team at Oracle Cloud Infrastructure. Such a long-term continuous failure can indicate invalid configuration of the service connector's source or target.\n\n\nReactivate the Service Connector\n\nUpdate the service connector to ensure valid configuration of its source and target.\n\nReactivate the service connector.\n\nConfirm that the service connector successfully moves data by checking for expected results at the target service.\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Service Catalog, \nFor known issues with Service Catalog, see Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Budgets Overview service, \n Creating Automation for Budgets Using the Events Service, \n\nYou can create automation based on state changes for your Oracle Cloud Infrastructure resources by using event types, rules, and actions. For more information, see Overview of Events.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Custom Logs service, \n Creating Custom Logs , \nTo create custom logs:\n\nOpen the navigation menu and click Observability & Management. Under Logging, click Logs.\nUnder List Scope, Compartment, choose\n                a compartment you have permission to work in.\nClick Create custom log. The Create custom\n                    log panel is displayed.\nIn Custom log name, enter a name for the custom log. Avoid entering confidential information.\nFrom Compartment, choose a compartment you have permission to\n                work in.\nFrom Log group, select a log group to place the custom log\n                into.\nOptionally, select a log retention value from Log Retention,\n                and add any applicable tags in Add Tags.\nClick Create custom log. The Create agent\n                    configuration panel is displayed. You can next create a new\n                configuration, to define the parameters for the associated log data (the default),\n                or add it later.\nEnter a Configuration name in the corresponding field, and\n                select a Compartment you have permissions to work in.\nIn Host Groups, which allows you to define which VMs apply to\n                this configuration, select a Group type from the list,\n                whether Dynamic group or User group.\n                    For the Dynamic group case, Dynamic Group\n                    refers to a group of instances, which you can create in the IAM feature of the Console. See About Dynamic Groups for more information. These Dynamic Groups can be selected from the\n                        Group field when setting up Dynamic Group settings.\n                For\n                the User group case, select the group from the\n                    Group field. User Groups also refer to the IAM\nGroups feature of the Console. See Managing Groups for more information.Click\n                        + Another host group to add more groups. You can add\n                    a combination of Group Types for the agent configuration, that is, both\n                        Dynamic groups and User groups\n                    can be set up in the configuration.  Note A maximum of five groups per\n                    configuration are allowed, and a host can be in a maximum of five different\n                    groups.\nNext, in the configuration, you need to define the format of the logs (that is, what\n                logs do you want to watch for) in Configure log inputs.\n                Select an Input type form the list, whether\n                    Windows event log or Log path.\nFor Windows event log, enter an Input\n                            name and select an Event channels\n                        option from the list.\nFor Log path, enter an Input\n                            name and File paths in the\n                        corresponding fields. For example,\n                            /<log_path>/<log_name>.\n                        Multiple paths can be entered. \n Note Multiple log file paths can be specified, separated by a comma (,). See\n                        https://docs.fluentd.org/input/tail#path for more\n                    information. In the configuration, you can define multiple log files separated\n                    by a comma as below:<source>\n@type tail\ntag 757261.oc_oslogs_linux\npath /var/log/.log,/var/log/.out,/var/log/dmesg,var/log/grubby,/var/log/messages*,var/log/secure,/var/log/auth,/var/log/acpid,/root/.bash_history\npos_file /etc/unifiedmonitoringagent/pos/757261-oc_oslogs_linux.pos\npath_key tailed_path\n</source>Example\n                        configuration:{{path C:\\Program Files (x86)\\<application>\\<directory>*, C:\\Program Files (x86)\\<application>\\<application_logs_directory>\\<directory>* }}Click\n                        Advanced parser options, which opens the\n                        Advanced parser options panel. This allows you to\n                    specify how to parse the log, according to the following parsers. Some of the\n                    parsers require further input and have more options, depending on the type\n                    chosen. \nAUDITD\nJSON\nTSV\nCSV\nNONE Important The NONE parser type is required, even if you\n                                do not want to specify a particular parser type.\nSYSLOG\nAPACHE2\nAPACHE_ERROR\nMSGPACK\nREGEXP\nMULTILINE\nFor example for JSON, you must select a Time\n                    type value from the list, while optionally, you can specify event\n                time and null field settings. Meanwhile for REGEXP, you specify the regular\n                expression for matching logs, along with the time format. See Log Inputs and Parsers for more\n                information.\nAfter configuring the log inputs and the parser, you can optionally specify any tag\n                settings. Click Create custom log to save your changes, and\n                create the custom log and its associated agent configuration. \n\nIn summary, the agent configuration defines what instances the configuration applies to\n                (Host groups), which log files are obtained and what parser\n            (if any) is used (Configure log inputs), and to what log object\n            in the Oracle Cloud Infrastructure system that the records are pushed to\n                (Select log destination). The latter is already set up since\n            this was set during the custom log creation step.\nThe custom log object is now created, as well as the agent configuration, which pulls\n            data from instances, and pushes into the custom log object.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Oracle Support Rewards Overview service, \n Viewing the Rewards Redemption History, Use the Rewards Redemption History page to view the redemption activity against your accrued Oracle Support Rewards. You can view the history by subscription and time period.\nThe page displays the following information:\n\nRedemption date\nInvoice number\nRedeemed amount\nExchange rate (for the particular currency)\nRedemption code\n\nTo view the rewards redemption history:\n\nOpen the navigation menu and click Billing & Cost Management. Under Programs and Rewards, click Rewards Redemption History. The Rewards Redemption History page opens.\nFrom Subscription, select a subscription to view history for. The field also shows the subscription ID in parentheses.\nSelect a time period from the corresponding Time Period field.\nAll data (the default)\nLast 12 months\nLast 6 months\nLast 3 months\nLast 1 month\n\nOptionally, click Export to CSV to download a CSV copy of the rewards redemption history.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell Limitations, \nKeep the following limitations in mind when using Cloud Shell:\n\nCloud Shell comes with 5GB\u00c2\u00a0of storage for the VM's home directory. This storage is persistent from session to session, but after 6-months of non-use, the administrator for your tenancy will receive a notification that the storage will be removed in 60 days. Starting a cloud shell session resets the storage removal timer.\nCloud Shell does not support mounting additional storage.\nCloud Shell does not scan user files for malware or viruses.\nCloud Shell sessions do not allow for any incoming connections, and there is no\n                public IP address available.\nThe OCI CLI will execute commands against the region selected in the Console's Region selection menu when the Cloud Shell was started. Changing the region selection in the console will not change the region for existing Cloud Shell instances; you will need to open a new Cloud Shell instance to change regions.\nCloud Shell sessions have a maximum length of 24 hours, and time out after 60\n                minutes of inactivity.\n\nCloud Shell uses websockets to communicate between your browser and the service.\n                    If your browser has websockets disabled or uses a corporate proxy that has\n                    websockets disabled you will see an error message (\"An unexpected error\n                    occurred\") when attempting to start Cloud Shell from the console.\n\nCloud Shell is designed for interactive use with Oracle Cloud Infrastructure resources. Users who need additional storage for Cloud Shell or want to run non-interactive long-running tasks are encouraged to use Compute and Storage resources in their tenancy.\nFor maximum compatibility, Cloud Shell includes Python version 2 and Python version\n                3. Python 2 is the default that will run when you enter 'python' at the command\n                line. To run Python 3, enter 'python3' at the command line.\nThe following reserved words can't be used as the user name for a Cloud Shell user: oci, root, bin, daemon, adm, lp, sync, shutdown, halt, mai, operator, games, ftp, nobody, oci, systemd-network, dbus, polkitd, tss, and apache. Attempting to create a Cloud Shell session when logged in with a user name (or the part of the name before the @ sign if the user name is an email address)\u00c2\u00a0that is one of these reserved words will result in an \"Unexpected Error\" message.\nEntirely numerical user names (for example, \"1234\")\u00c2\u00a0are not supported by Cloud Shell.\nThe Cloud Shell session time zone is UTC, and cannot be changed.\nCloud Shell does not allow root access or the use of sudo, so packages that require\n                root access for installation can't be installed. Many packages are available in\n                versions that do not require root for installation; you can unpack and install these\n                in your home directory. \nCloud Shell does not allow the use of ping, since ping requires root access.\nCloud Shell boots in FIPS mode, which might affect the behavior of some commands.\nCloud Shell cannot generate PKCS#1 keys when using the openssl command, because Cloud Shell boots in FIPS mode. FIPS mode requires that Cloud Shell generates PKCS#8 keys.\nFor more information on Cloud Shell limits, see the Cloud Shell section in Service Limits. \n\nCloud Shell Access and Other Restrictions\nYou can access OCI resources from Cloud Shell according to the policies granted by\n                your tenancy administrator. There is no additional access because you're using Cloud\n                Shell, and Cloud Shell does not provide any additional access to your tenancy, or\n                private resources in your tenancy VCNs. Note Cloud Shell uses websockets to\n                    communicate between your browser and the service. If your browser has websockets\n                    disabled or uses a corporate proxy that has websockets disabled you will see an\n                    error message (\"An unexpected error occurred\") when attempting to start Cloud\n                    Shell from the console.\nWhile Cloud Shell provides access to the internet, there is no ingress from the\n                outside world into Cloud Shell (for example: you cannot ssh in to Cloud Shell) and\n                no public IP address available. If your tenancy admin does not want to enable access\n                to the internet from OCI, they should not grant access to Cloud Shell with an IAM\n                policy.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Application Dependency Management Policies service, \n Resource-Types, Application Dependency Management provides both aggregate and individual resource-types for writing policies.\nYou can use aggregate resource-types to write fewer policies. For example, instead of allowing a group to manage adm-knowledge-bases, adm-vulnerability-audits, and adm-work-requests, you can write a policy that allows the group to manage the aggregate resource-type, adm-family.\n\n\nAggregate Resource-Types\nIndividual Resource-Types\n\n\n\nadm-family\n\nadm-knowledge-bases\nadm-vulnerability-audits\nadm-work-requests\n\n\n\nThe APIs provided by the aggregate adm-family resource-type cover the APIs for adm-knowledge-bases, adm-vulnerability-audits, and adm-work-requests. For example, allow group adm-admins to manage adm-family in compartment <compartment_name> is the same as writing the following three policies:allow group adm-admins to manage adm-knowledge-bases in compartment <compartment_name>\nallow group adm-admins to manage aadm-vulnerability-audits in compartment <compartment_name>\nallow group adm-admins to manage adm-work-requests in compartment <compartment_name>\nFor more information, see Permissions.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Finding Apps and Services service, \n Browsing, searching, and filtering options make it easy for you to quickly find apps or services that are listed on Oracle Cloud Marketplace. Plus, you have several options for how to sort and display the list of apps or services.\nTo find an app or a service listed on Oracle Cloud Marketplace:\n\n Go to the Oracle Cloud Marketplace website. \n\n Select the appropriate tab.\n\n\nIf you\u00e2\u0080\u0099re looking for apps, click the Applications\n              tab.\n\n\nIf you\u00e2\u0080\u0099re looking for services such as training, consulting, or integration, click\n              the Services tab.\n\n\n\n Use the browse, search, and filter options to find the app or service you want. \n\n\nTo browse by type of Oracle Cloud product, point to the\n                Products option and make a selection. For example, you can\n              select Sales Cloud or Marketing Cloud\n              from the APPLICATIONS (SaaS) products, Documents\n                Cloud from the PLATFORM (PaaS) products, or\n                Compute Cloud from the INFRASTRUCTURE\n                (IaaS) products. \nTo view all the Oracle Cloud Infrastructure applications, do one of the following:\nUnder the Oracle Cloud Infrastructure App Categories,\n                  click View all OCI Apps.\nClick the Applications tab, point to\n                    Products, point to Infrastructure\n                    (IaaS), and then click Oracle Cloud\n                    Infrastructure.\n\nThe Oracle Cloud Infrastructure page appears which lists all the\n              applications.\n\n\nTo filter Oracle Cloud Infrastructure applications listings by Install\n                Type, select either of the following:\n\n\nDeploy Now: Filters to show applications easily\n                  deployable via OCI Console. Select Deploy Now to display all available\n                  applications.\nContact Partner: Filters to show applications requiring\n                  guidance from the partner to deploy. Select Contact Partner to display those\n                  applications requiring guidance from the partner.\n\n\n\n\nTo filter Oracle Cloud Infrastructure applications listings by\n                Markets, select either of the following:\n\n\nCommercial: All the listings in public market place are\n                  deployed to commercial markets by default, and it displays those listings.\nUS Government: Selecting this shows only the US\n                  Government listings.\nUS Department of Defence: Selecting this shows only the\n                  US Department of Defence listings.\nUK Government: Selecting this shows only the UK\n                  Government listings.\n\n\n\n\nTo browse the services by industry, point to the INDUSTRIES\n              option and make a selection. For example, you can browse by\n                Healthcare, Insurance, or\n                Retail.\n\n\nTo find apps or services that match your search criteria, enter one or more\n              keywords in the Search box and click Go. The most relevant\n              results are at the top of the list.\nWhen you\u00e2\u0080\u0099re viewing the details page for an app or a service (click the name or\n              logo to open the details page), scroll the OVERVIEW tab until\n              you see the TAGS section. You can click the links in the\n                TAGS section to find other apps or services that match the\n              selected keyword or phrase. These search tags are available only if the provider\n              included them when creating the marketplace listing.\n\n\nTo refine your search, select from a set of pre-defined filters on the Search Results and product pages.\n\n\n\n\n Tip\n\n\nTo reorder your search results, point to the SORT BY option\n              and make a selection. You can reorder the list by name, rating, release date, or\n              relevance. The sorting options are available only after you search by keyword or\n              select a filter.\n\n\nTo change how the list of apps or services is displayed, click \nTile View or \nList View to toggle your display between a three-column tile\n              view and a one-column list view.\n\n\nTo view your list of favorites, sign in to the marketplace, open the user menu, and\n              select either My Favorite Apps or My Favorite\n                Services. These menu options are available only if you added apps or services to\n                your favorites.\n\n\nTo clear all search, filter, and sort by selections, and return to the home page,\n              click the Oracle Cloud Marketplace logo at the top of the\n              page.\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Securing Cloud Advisor service, \n Initial Security Tasks, \nUse this checklist to identify the tasks you perform to secure Cloud Advisor in a new Oracle Cloud Infrastructure tenancy.\n\nTask\nMore Information\n\nUse IAM policies to grant access to users\nIAM Policies\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Container Registry service, \n Required IAM Service Policy, \n\nTo use Oracle Cloud Infrastructure, you must be granted security\n                access in a policy\u00c2\u00a0 by an administrator. This access\n                is required whether you're using the Console or the\n                REST API with an SDK, CLI, or other tool. If you get a message that you don\u00e2\u0080\u0099t have\n                permission or are unauthorized, verify with your administrator what type of access\n                you have and which compartment\u00c2\u00a0 to work in.\n\nIf you're new to policies, see\u00c2\u00a0Getting Started with Policies\u00c2\u00a0and\u00c2\u00a0Common Policies. \nFor more details about policies for Container Registry, see:\n\n\nPolicies to Control Repository Access\n\n\nDetails for Container Registry\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Adding and Removing Node Pools service, \n Using the API, \n\nFor information about using\n                the API and signing requests, see REST APIs\n                and Security Credentials. For information about\n                SDKs, see Software Development Kits and Command Line Interface.\n\nUse the CreateNodePool and DeleteNodePool operations respectively to increase or decrease the number of node pools in a cluster.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Configuring Notifications service, \n Use the Events and Notifications services to send notifications, wheneverCloud Guard detects a problem for which you want to be\n        notified.\nPrerequisite: If you want to configure notifications\n            to be sent through Slack, create a Webhook for the Slack channel to receive the\n            notifications before proceeding with the steps in the \"Configure Notifications...\" that\n            follows. See Slack documentation.\n\n\n Note If you are processing problems entirely within Cloud Guard, you do not need to configure\n                    notifications.\n\nCloud Guard provides a notification responder, Cloud\n                Event, that can emit problem details to the Events service. The Cloud Event\n                responder rule is part of the Responder recipe, which needs to be attached to a\n                corresponding target or targets. The Cloud Event rule is enabled by default. The\n                Cloud Event responder does not require other IAM policies and is configured to\n                execute automatically.\nEmitting from Cloud Event to the Events service allows for integration with the\n                Notifications service, which can push notifications to:\n\nEmail\nSlack\nOracle Cloud Infrastructure Functions\n\n\n\nTo set up notifications through email or Slack, continue with Notifying through Email or Slack.\nTo use OCI Functions to relay notification information to another service, see Notifying through OCI Functions.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Started with Oracle Cloud Migrations service, \n Required IAM Policies, Each service in Oracle Cloud Infrastructure (OCI) integrates\n        with Identity and Access Management (IAM) for authentication and authorization, for all\n        interfaces (the Console, SDK and CLI, and REST API). \n\nThe Oracle Cloud Migrations service consists of multiple modules, and these modules must be able to interact with each other. For example, the discovery module stores discovered assets in the inventory module, and the migration module creates and manages volumes and temporary hydration instances during migration, and so on. The OCI security model requires you, as the tenancy owner, to grant these modules explicit permissions for the required operations. Therefore, before you begin using any of the modules, ensure that you grant proper permissions to these modules. For more information about Oracle Cloud Migrations permissions to be granted, see Oracle Cloud Migrations IAM Policies.\nOracle Cloud Migrations supports Policy Builder. To create\n                policies using policy builder, see Writing Policy Statements with the Policy\n                    Builder.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell Resource Location and Ownership, \nWhen you first start Cloud Shell, the service creates a persistent block storage volume (5GB) for your home directory. The home directory volume is located in your tenancy home region. The machine running your Cloud Shell session is also located in your tenancy home region.\n Note Cloud Shell uses your user OCID to create your home directory. If you have multiple\n            accounts in a tenancy (for example, you have a federated and a non-federated user\n            account), you will get a separate, unique Cloud Shell home directory for each account. \nChanging the Console region selection, or logging in to the Console via a different\n            regional URL will have no effect on where your Cloud Shell machine and home directory\n            volume are located. To confirm your tenancy home region, view your Tenancy Details page\n            in the Console.\n Note\nCloud Shell resources (including the VM used for your Cloud Shell session) are owned\n                by the Cloud Shell service and do not exist in your tenancy. Because of this, you\n                cannot add the Cloud Shell VM you are using to a dynamic group in your tenancy, or\n                use the instance principle of the instance used for your Cloud Shell session.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Container Engine for Kubernetes, "
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Certificates service, \n Use Certificates to create and manage digital\n        certificates.\nCertificate management tasks include the following:\n\nCreating a certificate\nViewing certificate details\nEditing a certificate's details\nEditing a certificate's rules\nRenewing a certificate to create a new certificate version\nViewing associations\nMoving a certificate to a different compartment\nDeleting a certificate\n\nEvery certificate has one or more certificate versions. As such, certificate management\n            also includes the following tasks specific to certificate versions:\n\nViewing certificate version bundles\nMaking a certificate version the current version of a certificate\nRevoking a certificate version\nDeleting a certificate version\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating Pipelines service, \n Using the CLI, \n\nThese environment variables control the pipeline run.\nYou can use the OCI CLI to create a pipeline as in this Python example:\n\n\nCreate a pipeline:\n\nThe following parameters are available to use in the payload:\n\n\nParameter name\nRequired\nDescription\n\n\n\nPipeline (top level)\n\n\nprojectId\nRequired\nThe project OCID to create the pipeline in.\n\n\ncompartmentId\nRequired\nThe compartment OCID to the create the pipeline in.\n\n\ndisplayName\nOptional\nThe name of the pipeline.\n\n\ninfrastructureConfigurationDetails\nOptional\n\nDefault infrastructure (compute) configuration to use for all the pipeline steps, see infrastructureConfigurationDetails for details on the supported parameters.\nCan be overridden by the pipeline run configuration.\n\n\n\nlogConfigurationDetails\nOptional\n\nDefault log to use for the all the pipeline steps, see logConfigurationDetails for details on the supported parameters.\nCan be overridden by the pipeline run configuration.\n\n\n\nconfigurationDetails\nOptional\n\nDefault configuration for the pipeline run, see configurationDetails for details on supported parameters.\nCan be overridden by the pipeline run configuration.\n\n\n\nfreeformTags\nOptional\nTags to add to the pipeline resource.\n\n\nstepDetails\n\n\nstepName\nRequired\nName of the step. Must be unique in the pipeline.\n\n\ndescription\nOptional\nFree text description for the step.\n\n\nstepType\nRequired\nCUSTOM_SCRIPT or ML_JOB\n\n\njobId\nRequired*\nFor ML_JOB steps, this is the job OCID to use for the step run.\n\n\nstepInfrastructureConfigurationDetails\nOptional*\n\nDefault infrastructure (Compute) configuration to use for this step, see infrastructureConfigurationDetails for details on the supported parameters.\nCan be overridden by the pipeline run configuration.\n*Must be defined on at least one level (precedence based on priority, 1 being highest):\n1 pipeline run and/or \n2 step and/or \n3 pipeline\n\n\n\nstepConfigurationDetails\nOptional*\n\nDefault configuration for the step run, see configurationDetails for details on supported parameters.\nCan be overridden by the pipeline run configuration.\n*Must be defined on at least one level (precedence based on priority, 1 being highest):\n1 pipeline run and/or \n2 step and/or \n3 pipeline\n\n\n\ndependsOn\nOptional\nList of steps that must be completed before this step begins. This creates the pipeline workflow dependencies graph.\n\n\ninfrastructureConfigurationDetails\n\n\nshapeName\nRequired\nName of the Compute shape to use. For example, VM.Standard2.4.\n\n\nblockStorageSizeInGBs\nRequired\nNumber of GBs to use as the attached storage for the VM.\n\n\nlogConfigurationDetails\n\n\nenableLogging\nRequired\nDefine to use logging.\n\n\nlogGroupId\nRequired\nLog group OCID to use for the logs. The log group must be created and available when the pipeline runs\n\n\nlogId\nOptional*\nLog OCID to use for the logs when not using the enableAutoLogCreation parameter.\n\n\nenableAutoLogCreation\nOptional\nIf set to True, a log for each pipeline run is created.\n\n\nconfigurationDetails\n\n\ntype\nRequired\nOnly DEFAULT is supported.\n\n\nmaximumRuntimeInMinutes\nOptional\nTime limit in minutes for the pipeline to run.\n\n\nenvironmentVariables\nOptional\n\nEnvironment variables to provide for the pipeline step runs.\nFor example:\n\"environmentVariables\": {\n\n \"CONDA_ENV_TYPE\": \"service\"\n\n}\nReview the list of service supported environment variables.\n\n\n\n \npipeline_payload = {\n    \"projectId\": \"<project_id>\",\n    \"compartmentId\": \"<compartment_id>\",\n    \"displayName\": \"pipeline_name\",\n    \"pipelineInfrastructureConfigurationDetails\": {\n        \"shapeName\": \"VM.Standard2.1\",\n        \"blockStorageSizeInGBs\": \"50\"\n    },\n    \"pipelineLogConfigurationDetails\": {\n        \"enableLogging\": True,\n        \"logGroupId\": \"<log_group_id>\",\n        \"logId\": \"<log_id>\"\n    },\n    \"pipelineDefaultConfigurationDetails\": {\n        \"type\": \"DEFAULT\",\n        \"maximumRuntimeInMinutes\": 30,\n        \"environmentVariables\": {\n            \"CONDA_ENV_TYPE\": \"service\",\n            \"CONDA_ENV_SLUG\": \"classic_cpu\"\n        }\n    },\n    \"stepDetails\": [\n        {\n            \"stepName\": \"preprocess\",\n            \"description\": \"Preprocess step\",\n            \"stepType\": \"CUSTOM_SCRIPT\",\n            \"stepInfrastructureConfigurationDetails\": {\n                \"shapeName\": \"VM.Standard2.4\",\n                \"blockStorageSizeInGBs\": \"100\"\n            },\n            \"stepConfigurationDetails\": {\n                \"type\": \"DEFAULT\",\n                \"maximumRuntimeInMinutes\": 90\n                \"environmentVariables\": {\n                    \"STEP_RUN_ENTRYPOINT\": \"preprocess.py\",\n                    \"CONDA_ENV_TYPE\": \"service\",\n                    \"CONDA_ENV_SLUG\": \"onnx110_p37_cpu_v1\"\n            }\n        },\n        {\n            \"stepName\": \"postprocess\",\n            \"description\": \"Postprocess step\",\n            \"stepType\": \"CUSTOM_SCRIPT\",\n            \"stepInfrastructureConfigurationDetails\": {\n                \"shapeName\": \"VM.Standard2.1\",\n                \"blockStorageSizeInGBs\": \"80\"\n            },\n            \"stepConfigurationDetails\": {\n                \"type\": \"DEFAULT\",\n                \"maximumRuntimeInMinutes\": 60\n            },\n            \"dependsOn\": [\"preprocess\"]\n        },\n    ],\n    \"freeformTags\": {\n        \"freeTags\": \"cost center\"\n    }\n}\npipeline_res = dsc.create_pipeline(pipeline_payload)\npipeline_id = pipeline_res.data.id\nUntil all pipeline steps artifacts are uploaded, the pipeline is in the CREATING state.\n\n\nUpload a step artifact:\n\nOnce an artifact is uploaded, it can't be changed.\nfstream = open(<file_name>, \"rb\")\n \ndsc.create_step_artifact(pipeline_id, step_name, fstream, content_disposition=f\"attachment; filename={<file_name>}\")\n\n\nUpdate a pipeline:\n\nYou can only update a pipeline when it is in an ACTIVE state.\nupdate_pipeline_details = {\n\"displayName\": \"pipeline-updated\"\n}\nself.dsc.update_pipeline(<pipeline_id>, <update_pipeline_details>)\n\n\nStart pipeline run:\n\npipeline_run_payload = {\n\"projectId\": project_id,\n\"displayName\": \"pipeline-run\",\n\"pipelineId\": <pipeline_id>,\n\"compartmentId\": <compartment_id>,\n}\ndsc.create_pipeline_run(pipeline_run_payload)\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview service, \n Key Terms, Review these terms used by the core Machine Learning (ML) engine in the Anomaly Detection service:\n\n\n\nTechnique\n\n\nDescription\n\n\n\n\n\nUnivariate analysis\n\n\nA pattern recognition method that learns one signal in a dataset of time series data.\n\n\n\n\nMultivariate State Estimation Technique (MSET)\n\n\nAn advanced pattern recognition method that learns the correlation between multiple signals over a large dataset of time series data. It provides accurate estimates for a specific timestamp.\n\n\n\n\nAsynchronous inferencing\n\n\nInferencing performed asynchronously, where anomalies are detected and later the detection results are retrieved. It provides accurate results over very large datasets.\n\n\n\n\nSequential Probability Ratio Test (SPRT)\n\n\nA method that takes the estimates generated by MSET and compares them\n                                against the original signal value at a particular timestamp to\n                                decide whether the signal value is an anomaly.\n\n\n\n\nIntelligent Data Preprocessing (IDP) techniques\n\n\nA combination of different data preprocessing techniques to resolve\n                                different data quality issues from the data before training the\n                                model. IDP includes the 3 methods defined in the 3 rows. For\n                                example, ARP, MVI, and UNQ.\n\n\n\n\nAnalytical Resampling Process (ARP)\n\n\nUsed for aligning the signal values in a time series dataset with multiple signals that emit data that are not synchronized. Commonly used when clock out of sync problems exist.\n\n\n\n\nMissing Value Imputation (MVI)\n\n\nUsed for deriving the missing sensor data in a dataset. Commonly used\n                                when signals are not reported because of component failures.\n\n\n\n\nUnQuantization (UnQ)\n\n\nUsed for improving the quality of low-resolution input signals to a\n                                higher resolution. Commonly used in IoT applications where sensors\n                                send low-resolution signals.\n\n\n\n\nAsynchronous Inference\n\n\nPerform inferencing asynchronously, and then retrieve inferencing results.\n\n\n\n\nOne Class Support Vector Machine (SVM)\n\n\nSVM \\is a one-class classifier is used for detecting anomalies. When SVM is used for anomaly detection, it has the classification machine learning technique but no target.\nOne Class Support Vector Machine (SVM)\n\n\n\n\nAsynchronous Detection\n\n\nDetection performed asynchronously, where anomalies are detected and later the detection results are retrieved. It provides accurate results over very large datasets.\n\n\n\n\nSynchronous Detection\n\n\nDetection performed synchronously, where anomalies are detected and the detection results are immediately retrieved. \n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Virtual Service Route Tables service, \n Getting Virtual Service Route Table Details, Get the details of a specific virtual service route table.\nUsing the Console\n\nLog in to the Oracle Cloud Infrastructure Console.\nOpen the navigation menu and click Developer\n                    Services. Under Containers & Artifacts,\n                click Service Mesh.\nUnder List Scope, choose your\n                    Compartment.\nThe mesh list appears in the main window.\nClick the name of the mesh that contains your virtual services.\nClick the name of the virtual service that contains your route table.\nClick Route Tables in the left navigation pane.\nTo see virtual service route table details, click the name of the virtual\n                    service route table.\n\n\nUsing the CLI\nTo get the details for a virtual service route table, use the\n                        service-mesh resource with the\n                        virtual-service-route-table option.\noci service-mesh virtual-service-route-table get --virtual-service-route-table-id <virtual-service-route-table-id>\nExample:\noci service-mesh virtual-service-route-table get --virtual-service-route-table-id ocid.meshvirtualserviceroutetable.oc1.iad.aaaa....\nTo see what operations are available for virtual-service-route-table\n                    get use:\noci service-mesh virtual-service-route-table get -h\n\nUsing the API\nUse the GetVirtualServiceRouteTable operation to view the details of\n                a virtual service route table.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Certificates service, \n Using the API, \nFor information about using the API and signing requests, see REST APIs and Security Credentials. For information about SDKs, see SDKs and the CLI.\nUse the following operations to manage certificates:\n\nListCertificates\nGetCertificate\nCreateCertificate\nUpdateCertificate\nChangeCertificateCompartment\nScheduleCertificateDeletion\nCancelCertificateDeletion\nListCertificateVersions\nGetCertificateVersion\nRevokeCertificateVersion\nScheduleCertificateVersionDeletion\nCancelCertificateVersionDeletion\nListCertificateBundleVersions\nGetCertificateBundle\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Data Catalog Metastore service, \n Additional Resources, \nHere are some resources that you can use to learn more about metastores:\nBlog\n\nImproving user collaboration using OCI Data Flow and Data\n        Catalog Metastore\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Tags service, \n Linking Tags to Data Objects, You link data objects to tags so that you can locate it easily at a later point in\n        time. \nYou can search tagged data objects by entering the tag name in the Search within this\n                data catalog field or you can click a tag in the Popular Data Catalog\n                Tags tile on the Home tab to fetch all data objects linked to the\n            selected tag name.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Data Science service, \n Provisioning and Pricing, \nThe Data Science service offers a serverless experience for\n   model development and deployment. When you create Data Science\n   resources, such as notebook sessions, models, model deployments, jobs, and the underlying Compute\n   and storage infrastructure is provisioned and maintained for you.\nYou pay for the use of the underlying infrastructure (Block Storage, Compute, and Object\n   Storage). Review the detailed pricing list for Data Science\n   resources.\nYou only pay for the infrastructure while you are using it with Data Science resources:\n\nNotebook Sessions\n\n\n\nNotebook sessions are serverless, and all underlying infrastructure is\n        service-managed.\n\n\nWhen creating a notebook session, you select the VM shape (the type of machine CPU or GPU,\n        and the number of OCPU or GPUs) and amount of block storage (minimum of 50 GB).\n\nWhile a notebook session is active, you pay for Compute and Block Storage at the standard\n       Oracle Cloud Infrastructure rates, see Deactivating Notebook Sessions.\n\nYou can deactivate your notebook session, which shuts down the Compute though retains the\n        Block Storage. In this case, you are no longer charged for Compute, but you continue to pay\n        for the Block Storage. This applies to notebook sessions with a GPU instance. Notebook\n        sessions with a GPU instance aren't metered for Compute when they are deactivated.\nYou can activate your notebook session to reattach this Block Storage to new Compute, see\n         Deactivating and Activating Notebook Sessions.\n\n\nWhen you delete a notebook session, you are no longer charged for Compute or Block\n        Storage, see Deleting Notebook Sessions.\n\n\n\nModels\n\n\n\nWhen you save a model to the model catalog, you are charged for the storage of the model\n        artifact at the standard Object Storage rates in terms of GB per month.\n\n\nWhen you delete a model, you are no longer charged, see Deleting Models.\n\n\n\nModel Deployments\n\n\n\nWhen you deploy a model, you select the shape type and the number of replicas hosting the\n        model servers. You can also select the load balancer bandwidth associated with your\n        deployment.\n\n\nWhen a model deployment is active, you pay for the VMs that are hosting the model servers\n        and the load balancer at the standard OCI rates.\n\n\nWhen you deactivate a model deployment, you are no longer charged for the VMs or the load\n        balancer. You can activate a model deployment and billing resumes for both VMs and the load\n        balancer.\n\n\nWhen you stop a model deployment, you are no longer charged for the infrastructure\n        associated with the model deployment.\n\n\n\nJobs\n\n\n\nJobs don't render a premium cost for using the service, you only pay for the underlining\n        used infrastructure and only during the duration of execution of the job artifact. \n\n\nMetering starts from the moment the job artifact is run, and stops with the code exit. You\n        don't pay for the infrastructure provisioning time nor for the deprovisioning of the\n        infrastructure. \nMetering includes the CPU or GPU consumption per OCPU during the duration of running the\n        job artifact  and the Block Storage size used for the job. \n\n\nUsing the Logging service with Jobs doesn't incur an extray cost.\n\n\n\nPipelines\n\n\n\nPipelines are billed by the usage of the underlying Compute and Block Storage that the pipeline uses to execute the pipeline step code.\n\n\nThere is no additional charge for the orchestration or artifact storage.\n\n\n\n\n Tip\nYou can use Checking Your Balance and Usage to review the costs\n    associated with your account. Also, you can use the Oracle Cloud Infrastructure Billing and Payment Tools to analyze your Data Science\n    usage and manage your costs.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using the Responder Activity Page service, \n Responder Execution Types and Execution Status, View the rules for how Cloud Guard resolves manual\n        and automated execution types, and the different status values that each execution type can\n        have.\n\nResponders are executed either manually or automatically. Each responder Execution\n                    Type (Manual or Automated) can be in a different Execution\n                    Status: \n\n\nExecution Type\nHow Problems Are Resolved\nPossible Execution Status\n\n\n\nManual\nProblems are resolved manually (from the Problems page,\n                                    Mark as Resolved or Dismissed).\n\n\nSucceeded\nFailed\n\n\n\n\nAutomatic\nProblems are resolved by first getting user confirmation or\n                                input. Then problems are remediated, either by Cloud Guard or directly by the\n                                user.\n\n\nAwaiting confirmation\nAwaiting input\nSkipped\nSucceeded\nFailed\n\n\n\n\nProblems are resolved immediately by Cloud Guard, with no user\n                                intervention.\n\n\nSucceeded\nFailed\n\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Differences between OCI Functions and Fn Project service, \n Use of Annotations, \nWhen you're creating and viewing OCI Functions resources using the Fn Project CLI, annotations enable you to identify and specify associated Oracle Cloud Infrastructure resources. \nFor example:\n\nWhen you're using the Fn Project CLI to create a new application, you use the --annotation parameter to specify the OCID of the subnet in which to run the function. \nWhen you're using the Fn Project CLI to view the properties of a function, the annotations element shows the OCID of the compartment that owns the function.\n\nNote that unlike other configuration parameters and environment variables, annotation values cannot be passed as arguments to running Docker containers. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Training Custom Models with the Console service, \n Getting Metrics, Obtain metrics for evaluating custom models using the Console.\n\nOpen the navigation menu and click Analytics & AI.\n                    Under AI Services, click\n                    Language.\n\nClick Projects or Create custom\n                        models on the overview page.\n\nUnder List Scope, choose a Compartment that hosts your\n                    projects.\n\nIn the listed projects, click a project to host your training model.\n\nIn the listed models, click the name of your model.\n\nClick Metrics.\n\nChoose the metrics that you want to view:\n\nModel metrics\nEntity metrics\nConfusion Matrix\n\nFor model metric explanations, see Analyzing Models.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n \n When using Oracle Cloud Infrastructure, sometimes you need to get help from the community or to talk to someone in Oracle support. This topic provides more information about accessing these tools.\n Tip Console announcements appear at the top of the Console to communicate\n            timely, important information about service status. For more information, see Console\n            Announcements.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n View Related Documentation, Use the Help menu to access documentation and support.\nThe listed documentation relates to the current Console page.\nOpen the \nHelp menu () and click the documentation link you want.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating a Discovery Work Request service, \n Using the Console, \nTo create a discovery work request, follow these steps:\n\nOpen the Oracle Cloud Console navigation menu and click\n                    Migration. Under Cloud Migrations,\n                click Discovery.\n\nFrom the list of asset sources, click an active asset source.\nThe Asset source details page opens and you can view the active connectors that connect the discovery plugin with the source environment.\n\nClick Run Discovery to start a discovery job by\n                    refreshing the asset source.\n\nUnder Resources, click Work\n                        requests and find the discovery job.\n\nWait for the Status of a work request to change to\n                        Succeeded.\n\nUnder Resources, click\n                    Assets.\n\nYou can now see a mapping between the VMs in the source environment and the discovered assets.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Service Mesh Overview service, \n Service Limits, \n\nSee Service Limits for a list of applicable\n                limits and instructions for requesting a limit increase. To set compartment-specific\n                limits on a resource or resource family, administrators can use compartment quotas.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Container Instances, \nFor known issues with Container Instances, see Known Issues for Container Instances. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Database Migration, \nFor known issues with Database Migration, see Database Migration Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Certificates service, \n Using the Console, \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Container Engine for Kubernetes service, \n \nOracle Cloud Infrastructure Container Engine for Kubernetes is a fully-managed, scalable, and\n            highly available service that you can use to deploy your containerized applications to\n            the cloud. Use Container Engine for Kubernetes (sometimes abbreviated\n            to just OKE) when your development team wants to reliably build, deploy, and manage\n            cloud-native applications. You specify the compute resources that your applications\n            require, and Container Engine for Kubernetes provisions them on Oracle Cloud Infrastructure in an existing OCI tenancy. \nContainer Engine for Kubernetes uses Kubernetes - the open-source system for automating\n            deployment, scaling, and management of containerized applications across clusters of\n            hosts. Kubernetes groups the containers that make up an application into logical units\n            (called pods) for easy management and discovery. Container Engine for Kubernetes uses versions of Kubernetes certified\n            as conformant by the Cloud Native Computing Foundation (CNCF). Container Engine for Kubernetes is itself ISO-compliant (ISO-IEC 27001,\n            27017, 27018). \nYou can access Container Engine for Kubernetes to define and create\n            Kubernetes clusters using the Console and the\n                REST\u00c2\u00a0API. You can access the clusters you create using the Kubernetes\n            command line (kubectl), the Kubernetes Dashboard, and the Kubernetes API.\nContainer Engine for Kubernetes is integrated with Oracle Cloud Infrastructure Identity and Access Management (IAM), which provides easy authentication\n            with native Oracle Cloud Infrastructure identity functionality.\nFor an introductory tutorial, see Creating a Cluster with Oracle Cloud Infrastructure\n                Container Engine for Kubernetes. A number of related Developer Tutorials are also available.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell Limitations, \nKeep the following limitations in mind when using Cloud Shell:\n\nCloud Shell comes with 5GB\u00c2\u00a0of storage for the VM's home directory. This storage is persistent from session to session, but after 6-months of non-use, the administrator for your tenancy will receive a notification that the storage will be removed in 60 days. Starting a cloud shell session resets the storage removal timer.\nCloud Shell does not support mounting additional storage.\nCloud Shell does not scan user files for malware or viruses.\nCloud Shell sessions do not allow for any incoming connections, and there is no\n                public IP address available.\nThe OCI CLI will execute commands against the region selected in the Console's Region selection menu when the Cloud Shell was started. Changing the region selection in the console will not change the region for existing Cloud Shell instances; you will need to open a new Cloud Shell instance to change regions.\nCloud Shell sessions have a maximum length of 24 hours, and time out after 60\n                minutes of inactivity.\n\nCloud Shell uses websockets to communicate between your browser and the service.\n                    If your browser has websockets disabled or uses a corporate proxy that has\n                    websockets disabled you will see an error message (\"An unexpected error\n                    occurred\") when attempting to start Cloud Shell from the console.\n\nCloud Shell is designed for interactive use with Oracle Cloud Infrastructure resources. Users who need additional storage for Cloud Shell or want to run non-interactive long-running tasks are encouraged to use Compute and Storage resources in their tenancy.\nFor maximum compatibility, Cloud Shell includes Python version 2 and Python version\n                3. Python 2 is the default that will run when you enter 'python' at the command\n                line. To run Python 3, enter 'python3' at the command line.\nThe following reserved words can't be used as the user name for a Cloud Shell user: oci, root, bin, daemon, adm, lp, sync, shutdown, halt, mai, operator, games, ftp, nobody, oci, systemd-network, dbus, polkitd, tss, and apache. Attempting to create a Cloud Shell session when logged in with a user name (or the part of the name before the @ sign if the user name is an email address)\u00c2\u00a0that is one of these reserved words will result in an \"Unexpected Error\" message.\nEntirely numerical user names (for example, \"1234\")\u00c2\u00a0are not supported by Cloud Shell.\nThe Cloud Shell session time zone is UTC, and cannot be changed.\nCloud Shell does not allow root access or the use of sudo, so packages that require\n                root access for installation can't be installed. Many packages are available in\n                versions that do not require root for installation; you can unpack and install these\n                in your home directory. \nCloud Shell does not allow the use of ping, since ping requires root access.\nCloud Shell boots in FIPS mode, which might affect the behavior of some commands.\nCloud Shell cannot generate PKCS#1 keys when using the openssl command, because Cloud Shell boots in FIPS mode. FIPS mode requires that Cloud Shell generates PKCS#8 keys.\nFor more information on Cloud Shell limits, see the Cloud Shell section in Service Limits. \n\nCloud Shell Access and Other Restrictions\nYou can access OCI resources from Cloud Shell according to the policies granted by\n                your tenancy administrator. There is no additional access because you're using Cloud\n                Shell, and Cloud Shell does not provide any additional access to your tenancy, or\n                private resources in your tenancy VCNs. Note Cloud Shell uses websockets to\n                    communicate between your browser and the service. If your browser has websockets\n                    disabled or uses a corporate proxy that has websockets disabled you will see an\n                    error message (\"An unexpected error occurred\") when attempting to start Cloud\n                    Shell from the console.\nWhile Cloud Shell provides access to the internet, there is no ingress from the\n                outside world into Cloud Shell (for example: you cannot ssh in to Cloud Shell) and\n                no public IP address available. If your tenancy admin does not want to enable access\n                to the internet from OCI, they should not grant access to Cloud Shell with an IAM\n                policy.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell Resource Location and Ownership, \nWhen you first start Cloud Shell, the service creates a persistent block storage volume (5GB) for your home directory. The home directory volume is located in your tenancy home region. The machine running your Cloud Shell session is also located in your tenancy home region.\n Note Cloud Shell uses your user OCID to create your home directory. If you have multiple\n            accounts in a tenancy (for example, you have a federated and a non-federated user\n            account), you will get a separate, unique Cloud Shell home directory for each account. \nChanging the Console region selection, or logging in to the Console via a different\n            regional URL will have no effect on where your Cloud Shell machine and home directory\n            volume are located. To confirm your tenancy home region, view your Tenancy Details page\n            in the Console.\n Note\nCloud Shell resources (including the VM used for your Cloud Shell session) are owned\n                by the Cloud Shell service and do not exist in your tenancy. Because of this, you\n                cannot add the Cloud Shell VM you are using to a dynamic group in your tenancy, or\n                use the instance principle of the instance used for your Cloud Shell session.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Configuring a Private Network service, \n Moving a Private Endpoint, You can move the private endpoint resource from the compartment you created it in to\n        a different compartment.\n\nHere's how you move a private endpoint to a different compartment:\n\n\nFrom the Data Catalog page in the Console, click Private\n                    Endpoints.\n\nFrom the Private Endpoints list, click the Actions menu for the private endpoint you want to move and select Move Resource.\n\nSelect the new compartment for the private endpoint resource.\n\nClick Move Resource.\n\nA notification displays indicating that the private endpoint resource is moved to\n            the new compartment successfully. You might notice the private endpoint status change to\n                Moving. After the move is completed successfully, the private\n            endpoint status changes back to Active.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Connecting to an Instance service, \n Troubleshooting the SSH Connection, \nIf you're unable to connect to an instance using SSH, follow the troubleshooting steps in Troubleshooting the SSH Connection.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Support Ticket Management service, \n Creating a Support Ticket for a Specific Resource, For some services, you can create support requests for individual resources while\n        viewing them in the Oracle Cloud Infrastructure\nConsole. When you create a support request from the resource\n        details page, the support ticket automatically includes relevant details about the resource\n        from the General Information section of the page.\n\nOn the resource details page, click the \nSupport button ().\n\nClick Create Support Request to open the Support Request form.\n\nEnter the following:\n\n\nIssue Summary: Enter a title that summarizes your issue. Avoid\n                            entering confidential information.\nDescribe Your Issue: Provide a brief overview of your issue.\nInclude all the information that My Oracle Support requires to\n                                    route and respond to your request. For example, \"I am\n                                    unable to connect to my compute instance.\"\nInclude troubleshooting steps taken and any available test\n                                    results.\n\nSelect the severity level for this request.\n\n\n\nOptionally, click Show the information we've gathered to\n                    display the resource details included in the support request.\n\nClick Create Request.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Data Science service, \n Limits on Data Science Resources, \nWhen you sign up for OCI, a set of service limits is configured for your tenancy. The service limit is the quota or allowance set on the resources.\nLimits by Service includes Data Science limits and other OCI services. You can request a service limit increase to change the\n      defaults.\n Tip Watch the increasing Data Science service\n        limits video for specifics.\nIn addition to these service limits, note that:\n\n\nFailed and inactive notebook sessions and models count against your service limits. Only\n          when you fully stop an instance or delete a model is it not counted toward your quota.\n\n\nGPU limits are set to zero by default so ask your system administrator to increase the\n          limits so that you can use GPUs.\n\n\nThe maximum number of jobs is 1000. By default, every tenancy can create up to 1000 jobs.\n          You can increase this limit a CAM service request ticket. \n\n\nThe number of simultaneous job runs is limited by your Data Science core count limits.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Matching Events with Filters service, \n \nThis topic describes how to match events with pattern filters in rules to build automation. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Job Metrics service, \n \nMetrics are\n            automatically available in the oci_datascience_jobrun namespace for any\n                Data Science job run. You don't need to enable\n            monitoring on OCI resources to get these metrics. \nData Science job run metrics include these\n            dimensions:\n\nresourceId\n\nThe OCID of the job run.\n\nresourceDisplayName\n\nThe user-supplied display name of the job run.\n\nshape\n\nThe Compute instance shape of the job run.\n\n\n\n\nMetric Name\nDisplay Name\nUnit\nDescription\nDimensions\n\n\n\n\nCpuUtilization\n\n\nCPU Utilization\n\n\nPercent\n\n\nActivity level from the CPU when a CPU shape is used. Expressed as a\n                                percentage of the busy time compared with the total time (busy and\n                                idle).\n\n\nresourceId\nresourceDisplayName\nshape\n\n\n\n\nGpuUtilization\n\n\nGPU Utilization\n\n\nPercent\n\n\nActivity level from the GPU when a GPU shape is used. Expressed as a\n                                percentage of the busy time compared with the total time (busy and\n                                idle).\n\n\nresourceId\nresourceDisplayName\nshape\n\n\n\n\nDiskUtilization\n\n\nMemory Utilization\n\n\nPercent\n\n\nDisk space currently in use. Expressed as a percentage of the used\n                                disk space compared with total disk space.\n\n\nresourceId\nresourceDisplayName\nshape\n\n\n\n\nMemoryUtilization\n\n\nMemory Utilization\n\n\nPercent\n\n\nMemory currently in use. Measured by pages. The percentage of RAM\n                                that is used. It's measured by the number of memory pages used\n                                relative to the total number of memory pages.\n\n\nresourceId\nresourceDisplayName\nshape\n\n\n\n\nNetworkBytesIn \n\n\nNetwork Bytes In\n\n\nByte\n\n\nNetwork receipt throughput. Expressed as bytes per second.\n\n\nresourceId\nresourceDisplayName\n\n\n\n\nNetworkBytesOut\n\n\nNetwork Bytes Out\n\n\nByte\n\n\nNetwork transmission throughput. Expressed as bytes transmitted per\n                                second.\n\n\nresourceId\nresourceDisplayName\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Load Balancer service, \n Describes how Load Balancer provides automated traffic distribution from one entry point to multiple servers reachable from your virtual cloud network.\nThe Load Balancer service provides automated traffic distribution from one entry point to multiple servers reachable from your virtual cloud network (VCN). The service offers a load balancer with your choice of a public or private IP\u00c2\u00a0address, and provisioned bandwidth.\n Note\nWatch a video introduction to the Load Balancer service.\n\nA load balancer improves resource utilization, facilitates scaling, and helps ensure high availability. You can configure multiple load balancing policies and application-specific health checks\u00c2\u00a0 to ensure that the load balancer directs traffic only to healthy instances. The load balancer can reduce your maintenance window by draining traffic from an unhealthy application server before you remove it from service for maintenance.\nThis overview contains the following separate topics:\n\n\nLoad Balancer Types\n\n\nLoad Balancer Concepts\n\n\nLoad Balancer Policies\n\n\nLoad Balancer Headers\n\n\nLoad Balancer Session Persistence\n\n\nLoad Balancer Timeout Connection Settings\n\n\nYou can also view topics on the following load balancer-related subjects:\n\n\nLoad Balancer Management\n\n\nHealth Checks\n\n\nBackend Sets\n\n\nBackend Servers\n\n\nListeners\n\n\nCipher Suites\n\n\nRequest Routing\n\n\nSSL Certificates\n\n\nWork Requests\n\n\nDiagnosing a Load Balancer Issues Using Smart Check\n\n\nLogging\n\n\nLoad Balancer Metrics\n\n\nTroubleshooting\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Key Pairs on Linux Instances service, \n \nInstances launched using Oracle Linux, CentOS, or Ubuntu images use an SSH  key pair instead of a password to authenticate a remote user (see Security Credentials). A key pair consists of a private key and public key.  You keep the private key on your computer and provide the public key when you create an instance. When you connect to the instance using SSH, you provide the path to the private key in the SSH\u00c2\u00a0command.\nYou can have as many key pairs as you want, or you can keep it simple and use one key pair for all or several of your instances. \nIf you're using OpenSSH to connect to an instance, you can use a key pair that is generated by Oracle Cloud Infrastructure at the time that you create the instance. Oracle does not store a copy of the private key generated by the Console. OpenSSH should be installed on UNIX-based systems (including Linux and OS X), Windows 10, and Windows Server 2019.\nTo create your own key pairs, you can use a third-party tool such as OpenSSH on UNIX-style systems (including Linux, Solaris, BSD, and  OS X) or PuTTY Key Generator on Windows.\n\n Caution Anyone who has access to the private key can connect to the instance. Store the private key in a secure location. \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Jobs  service, \n Job run artifact execution failed with exit code ___ Error, \nThis means that the execution of the code failed with the indicated exit code related to the code. Enable logging integration, and ensure that you have sufficient log statements in the code to debug the issue.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Scheduled Reports Overview service, \n You can generate scheduled reports based on saved reports from Cost Analysis. \nAfter you\u00e2\u0080\u0099ve created a saved report in Cost Analysis, use the Scheduled Reports page to create a scheduled report that runs a single time, or that recurs daily or monthly. Scheduled reports are saved in an Object Storage bucket, which you can access from the scheduled report details page.\nRequired IAM Policy\n\n\nTo use Oracle Cloud Infrastructure, you must be granted security\n                access in a policy\u00c2\u00a0 by an administrator. This access\n                is required whether you're using the Console or the\n                REST API with an SDK, CLI, or other tool. If you get a message that you don\u00e2\u0080\u0099t have\n                permission or are unauthorized, verify with your administrator what type of access\n                you have and which compartment\u00c2\u00a0 to work in.\n\n\nIf you're new to policies, see Getting Started with Policies and Common Policies. \n\n\nTo use Scheduled reports in the Console, the same IAM policies that grant you access to Cost Analysis also give you access to the Scheduled reports pages. See Required IAM Policy for more information. \n\n\nTo use scheduled report API operations, and to grant write permissions to the Object Storage bucket where scheduled reports are saved, the following policy is required:Allow service <SERVICE-PRINCIPAL> to manage objects in tenancy where all {target.bucket.name ='<BUCKET-NAME>', any {request.permission='OBJECT_CREATE', request.permission='OBJECT_DELETE', request.permission='OBJECT_READ'}}\nWhere <BUCKET-NAME> is the name of the Object Storage bucket that you want the scheduled report results saved to, and <SERVICE-PRINCIPAL> is metering_overlay for the commercial realm.\n\n\n\nUsing the Console\nTo create a scheduled report\nOpen the navigation menu and click Billing & Cost Management. Under Cost Management, click Scheduled reports. The Scheduled reports page opens.\nClick Create a scheduled report. The Create a scheduled report panel opens.\nIn Name, enter a name for the scheduled report.\nOptionally, enter a report description in Description.\nFrom Saved report, select the saved report you want to associate with the scheduled report.\nFrom Start date, select the date you want the scheduled report to start on.\nSelect a scheduled report output format, whether CSV or PDF.\nSelect a region from the Region list. Scheduled reports can only be saved in a given region, so this field allows selecting the region where your files are saved.\nFrom Bucket, select the Object Storage bucket you want the scheduled report results saved to. You must have the required policy to grant write permissions to the bucket. See Required IAM Policy for more information.\nClick Create. A message indicates that the scheduled report was saved successfully.\nThe new scheduled report appears on the Scheduled Reports page, which displays the following information for each scheduled report:\nJob name (the scheduled report name)\nLast run status\nLast run time\nNext run time\nReports that have not run yet have Unknown for their last run status, no value for the last run time, but the date for their next run time. Reports that have run show the associated last run status, and last run time.You can also click the Actions menu for a scheduled report to view its details, edit it, or delete it. When editing, you can only change the Description, Format, Region, and Bucket fields.\nTo view scheduled reports and details\nOpen the navigation menu and click Billing & Cost Management. Under Cost Management, click Scheduled reports. The Scheduled reports page opens.\nClick the linked report from the Job name field. The scheduled report details page opens.The following information is displayed in Report Details:\nOCID\nDescription\nSaved report\nStart date\nRecurrence\nFormat\nNamespace\nDestination (Object storage bucket)\nRegion\nUnder History, the table provides a summary of scheduled report run status:\nReport start time\nReport end time\nRun status\nMessage\n\nClick the linked name in the Report Details\nDestination field, to go to the Object Storage\nBuckets page. Additionally, under History, the Message field includes a link to the Object Storage\nBuckets page, and shows the names of your scheduled report files in the bucket.\n\n\nUsing the API\nFor information about using\n                the API and signing requests, see REST APIs\n                and Security Credentials. For information about\n                SDKs, see Software Development Kits and Command Line Interface.\nUse the following operations to manage scheduled reporting in the Usage API:\n\nCreateSchedule\nDeleteSchedule\nGetSchedule\nListSchedules\nUpdateSchedule\nGetScheduledRun\nListScheduledRuns\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Rules for Events service, \n Using the Console, "
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Queue service, \n Authentication and Authorization, Each service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nAn administrator in your organization needs to set up groups, compartments\u00c2\u00a0, and policies\u00c2\u00a0 that control which users can access which services, and which resources, and the type of access they have. For example, policies control who can create users, groups, and compartments, or who can create and manage virtual deployments.\n\nIf you're a new administrator, see Getting Started with Policies.\nFor details about writing policies for this service, see Queue Policies.\nFor details about writing policies for resources in other services, see Policy Reference.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Modifying Node Pool and Worker Node Properties service, \n Using the API, \n\nFor information about using\n                the API and signing requests, see REST APIs\n                and Security Credentials. For information about\n                SDKs, see Software Development Kits and Command Line Interface.\n\nUse the UpdateNodePool operation to modify an existing node pool. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Service Mesh Overview service, \n Authentication and Authorization, Each service in Oracle Cloud Infrastructure integrates with IAM for authentication\n        and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nAn administrator in your organization needs to set up groups, compartments\u00c2\u00a0, and policies\u00c2\u00a0 that control which users can access which services, and which\n            resources, and the type of access they have. For example, policies control who can\n            create users, groups, and compartments, or who can create and manage virtual\n            deployments.\n\nIf you're a new administrator, see Getting Started with Policies.\nFor details about writing policies for this service, see Service Mesh IAM Policies.\nFor details about writing policies for resources in other services, see Policy Reference.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Jobs  service, \n Job Run Exit Code Isn't Indicated, \nJobs indicate the exit code of a job run failure when it exits. This information is available in the job run's lifecycle detail field. This is supported for all job runs including bring your own container job runs.\nIf you are observing that the exit code you know the job run failed with isn't correctly indicated, likely the exit code isn't being propagated correctly.\nSome common mistakes are:\n\nIf you are using a shell script as an entry point start other files to run (other python files), then the shell script must capture the exit code from the internal file execution, then subsequently exit the shell script with the captured exit code.\nThrowing exceptions might not be sufficient. The file run (or container for bring your own container) must explicitly exit with an exit code. In Python, this is done using sys.exit(ERROR_CODE).\nUsing an incorrect type for the exit code value. Typically, the incorrect type used is a string. Exit codes must be Numbers or integers, and between 1-255 as described in Job with Exit Codes.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, About Document Understanding Policies service, \n Learn about Document Understanding's resource policies\n    including API permissions.\nTo control who has access to Document Understanding and the\n      type of access for each group of users, you must create policies. By default, only the users\n      in the Administrators group have access to all Document Understanding resources. For everyone else who's using\n      the service, you must create policies that assign them proper rights to Document Understanding resources. For a complete list of Oracle Cloud Infrastructure policies, see Policy Reference.\n\n Important Create all the policies at the root compartment\n        level, that is, at the tenancy level. In your tenancy Console, click Identity\n          & Security. Click Policies, and select the root\n        compartment.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Invoking a Model Deployment service, \n Invoking with the OCI Python SDK , \nThis example code is a reference to help you invoke your model deployment:\nimport requests\nimport oci\nfrom oci.signer import Signer\nimport json\n \n# model deployment endpoint. Here we assume that the notebook region is the same as the region where the model deployment occurs.\n# Alternatively you can also go in the details page of your model deployment in the OCI console. Under \"Invoke Your Model\", you will find the HTTP endpoint\n# of your model.\nendpoint = <your-model-deployment-uri>\n# your payload:\ninput_data = <your-json-payload-str>\n \nif using_rps: # using resource principal:    \n    auth = oci.auth.signers.get_resource_principals_signer()\nelse: # using config + key:\n    config = oci.config.from_file(\"~/.oci/config\") # replace with the location of your oci config file\n    auth = Signer(\n        tenancy=config['tenancy'],\n        user=config['user'],\n        fingerprint=config['fingerprint'],\n        private_key_file_location=config['key_file'],\n        pass_phrase=config['pass_phrase'])\n \n# post request to model endpoint:\nresponse = requests.post(endpoint, json=input_data, auth=auth)\n \n# Check the response status. Success should be an HTTP 200 status code\nassert response.status_code == 200, \"Request made to the model predict endpoint was unsuccessful\"\n \n# print the model predictions. Assuming the model returns a JSON object.\nprint(json.loads(response.content)) \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Application Dependency Management Policies service, \n Details for Verbs + Resource-Type Combinations, There are various Oracle Cloud Infrastructure verbs and resource-types that you can use to create a policy.\nThe following tables show thePermissions and API operations covered by each verb for Application Dependency Management. A plus sign (+) in a table cell indicates incremental access compared to the cell directly above it, whereas \"no extra\" indicates no incremental access.\nFor example, the read verb for the adm-knowledge-bases resource-type includes the same permissions and API operations as the inspect verb, plus the API_KNOWLEDGE_BASE_READ permission. The use verb covers additional permissions and API operations compared to read. Lastly, manage covers more permissions and operations compared to use.\nFor information about granting access, see Permissions.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, About Language Policies service, \n Learn about the resource policies including API permissions.\nTo control who has access to Language and the type of\n            access for each group of users, you must create policies. By default, only the users in\n            the Administrators group have access to all Language\n            resources. For everyone else who's using the service, you must create new policies that\n            assign them proper rights to Language resources. For a\n            complete list of OCI policies, see Policy Reference.\nResource Types\nLanguage offers both aggregate and individual\n                resource-types for writing policies. You can use aggregate resource types to write\n                fewer policies. For example, instead of allowing a group to manage all of the\n                individual resource types, you can  have a policy that allows the group to manage\n                the aggregate resource type, ai-service-language-family.\n\nIndividual Resource Types\n\nai-service-language-entities\n\nai-service-dominant-language\n\nai-service-language-sentiments\n\nai-service-language-keyphrases\n\nai-service-language-text-classification\n\n\nai-service-language-translation\n\nAggregate Resource Type\n\nai-service-language-family\n\nExample Policies\n\nallow group <language-group> to use ai-service-language-family in tenancy\n\n\n\nRequired IAM Policy\nTo work with Language, an administrator must grant you access in an IAM policy.\nIf you get a message that you don\u00e2\u0080\u0099t have permission or are unauthorized, verify with your administrator what type of access you have.\nCreate a policy with one of the following policies:\nallow <subject> to manage ai-service-language-family in tenancy, where subject can be:\ngroup <group-name> | group id <group-ocid> | dynamic-group <dynamic-group-name> | dynamic-group id <dynamic-group-ocid> | any-user\n\nExample Policies\nAllow users to manage all Language resources using the aggregate resource:\nallow any-user to manage ai-service-language-family in tenancy\n\nThese policies control user access by theLanguage resources:\nallow any-user to manage ai-service-language-project in tenancy\nallow any-user to manage ai-service-language-model in tenancy\nallow any-user to manage ai-service-language-data-asset in tenancy\nallow any-user to manage ai-service-language-private-endpoint in tenancy\nResource Types and Permissions\n\n\nResource Family\nResource Kind\nPermissions\n\n\n\n\nai-service-language-family\n\n\nai-service-language-entities\n\n\nAI_SERVICE_LANGUAGE_ENTITIES_USE\n\n\n\n\nai-service-dominant-language\n\n\nAI_SERVICE_DOMINANT_LANGUAGE_USE\n\n\n\n\nai-service-language-sentiments\n\n\nAI_SERVICE_LANGUAGE_SENTIMENTS_USE\n\n\n\n\nai-service-language-keyphrases\n\n\nAI_SERVICE_LANGUAGE_KEYPHRASES_USE\n\n\n\n\nai-service-language-text-classification\n\n\nAI_SERVICE_LANGUAGE_TEXT_CLASSIFICATION_USE\n\n\n\n\nai-service-language-moderation\n\n\nAI_SERVICE_LANGUAGE_MODERATION_USE\n\n\n\n\nai-service-language-translation\n\n\nAI_SERVICE_LANGUAGE_TRANSLATION_USE\n\n\n\n\nai-service-language-pii-entities\n\n\nAI_SERVICE_LANGUAGE_PII_ENTITIES_USE\n\n\n\n\nai-service-language-project\n\n\nAI_SERVICE_LANGUAGE_PROJECT_INSPECT\n\n\n\n\nAI_SERVICE_LANGUAGE_PROJECT_CREATE\n\n\n\n\nAI_SERVICE_LANGUAGE_PROJECT_READ\n\n\n\n\nAI_SERVICE_LANGUAGE_PROJECT_UPDATE\n\n\n\n\nAI_SERVICE_LANGUAGE_PROJECT_DELETE\n\n\n\n\nAI_SERVICE_LANGUAGE_PROJECT_MOVE\n\n\n\n\nai-service-language-model\n\n\nAI_SERVICE_LANGUAGE_MODEL_INSPECT\nAI_SERVICE_LANGUAGE_MODEL_CREATE\nAI_SERVICE_LANGUAGE_MODEL_READ\nAI_SERVICE_LANGUAGE_MODEL_UPDATE\nAI_SERVICE_LANGUAGE_MODEL_DELETE\nAI_SERVICE_LANGUAGE_MODEL_MOVE\n\n\n\n\nai-service-language-endpoint\n\n\nAI_SERVICE_LANGUAGE_ENDPOINT_INSPECT\nAI_SERVICE_LANGUAGE_ENDPOINT_CREATE\nAI_SERVICE_LANGUAGE_ENDPOINT_READ\nAI_SERVICE_LANGUAGE_ENDPOINT_UPDATE\nAI_SERVICE_LANGUAGE_ENDPOINT_DELETE\nAI_SERVICE_LANGUAGE_ENDPOINT_MOVE\n\n\n\n\nai-service-language-work-request\n\n\nAI_SERVICE_LANGUAGE_WORK_REQUEST_INSPECT\nAI_SERVICE_LANGUAGE_WORK_REQUEST_READ\n\n\n\n\nPermissions Required for Each API Operation\nYou can use the individual resource types with API calls to interact with the\n                service.\nThe following table lists the API operations for the Language service in a logical order, grouped by\n                resource type, and the permissions required for resource\n                types:\n\n\nAPI Operation\nPermissions\n\n\n\nBatchDetectDominantLanguage\nAI_SERVICE_DOMINANT_LANGUAGE_USE \n\n\nBatchDetectLanguageEntities\nAI_SERVICE_LANGUAGE_ENTITIES_USE\n\n\nBatchDetectLanguageKeyPhrases\nAI_SERVICE_LANGUAGE_KEYPHRASES_USE\n\n\nBatchDetectLanguageSentiments\nAI_SERVICE_LANGUAGE_SENTIMENTS_USE\n\n\nBatchLanguageTranslation\nAI_SERVICE_LANGUAGE_TRANSLATION_USE\n\n\nDetectLanguageEntities\nAI_SERVICE_LANGUAGE_ENTITIES_USE\n\n\nBatchDetectLanguageTextClassification\nAI_SERVICE_LANGUAGE_TEXT_CLASSIFICATION_USE\n\n\nDetectDominantLanguage\nAI_SERVICE_DOMINANT_LANGUAGE_USE\n\n\nDetectLanguageEntities\nAI_SERVICE_LANGUAGE_ENTITIES_USE\n\n\nDetectLanguageKeyPhrases\n                                \nAI_SERVICE_LANGUAGE_KEYPHRASES_USE\n\n\nDetectLanguageSentiments\nAI_SERVICE_LANGUAGE_SENTIMENTS_USE\n\n\nDetectLanguageTextClassification\nAI_SERVICE_LANGUAGE_TEXT_CLASSIFICATION_USE\n\n\nChangeProjectCompartment\nAI_SERVICE_LANGUAGE_PROJECT_MOVE\n\n\nCreateProject\nAI_SERVICE_LANGUAGE_PROJECT_CREATE\n\n\nListProjects\nAI_SERVICE_LANGUAGE_PROJECT_INSPECT\n\n\nGetProject\nAI_SERVICE_LANGUAGE_PROJECT_READ\n\n\nUpdateProject\nAI_SERVICE_LANGUAGE_PROJECT_UPDATE\n\n\nDeleteProject\nAI_SERVICE_LANGUAGE_PROJECT_DELETE\n\n\nChangeModelCompartment\nAI_SERVICE_LANGUAGE_MODEL_MOVE\n\n\nCreateModel\nAI_SERVICE_LANGUAGE_MODEL_CREATE\n\n\nListModels\nAI_SERVICE_LANGUAGE_MODEL_INSPECT\n\n\nGetModel\nAI_SERVICE_LANGUAGE_MODEL_READ\n\n\nUpdateModel\nAI_SERVICE_LANGUAGE_MODEL_UPDATE\n\n\nDeleteModel\nAI_SERVICE_LANGUAGE_MODEL_DELETE\n\n\nChangeEndpointCompartment\nAI_SERVICE_LANGUAGE_ENDPOINT_MOVE\n\n\nCreateEndpoint\nAI_SERVICE_LANGUAGE_ENDPOINT_CREATE\n\n\nListEndpoint\nAI_SERVICE_LANGUAGE_ENDPOINT_INSPECT\n\n\nGetEndpoint\nAI_SERVICE_LANGUAGE_ENDPOINT_READ\n\n\nUpdateEndpoint\nAI_SERVICE_LANGUAGE_ENDPOINT_UPDATE\n\n\nChangeEndpoint\nAI_SERVICE_LANGUAGE_ENDPOINT_MOVE\n\n\nListWorkRequests\n\nAI_SERVICE_LANGUAGE_PROJECT_INSPECT\nAI_SERVICE_LANGUAGE_MODEL_INSPECT\nAI_SERVICE_LANGUAGE_ENDPOINT_INSPECT\nAI_SERVICE_LANGUAGE_WORK_REQUEST_INSPECT\n\n\n\nGetWorkRequest\nAI_SERVICE_LANGUAGE_WORK_REQUEST_READ\n\n\nListWorkRequestErrors\nAI_SERVICE_LANGUAGE_WORK_REQUEST_READ\n\n\nListWorkRequestLogs\nAI_SERVICE_LANGUAGE_WORK_REQUEST_READ\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n What's Included With Cloud Shell, \nIn addition to the OCI CLI, the Cloud Shell VM\u00c2\u00a0comes with current versions of many useful\n            tools and utilities pre-installed, including:\n\nGit\nJava\nPython (2 and 3)\nGraalVM Enterprise JDK 17 and Native Image\nSQL Plus\nkubectl\nhelm\nmaven\ngradle\nterraform\nansible\nnode.js\niputils\njqmake\ntmux\nvim\nNPM\nwget\nzip/unzip\nnano\nemacs\npip\nbash\nsh\ntar\nnvm\nmysql-community-client\nDocker engine\nipython\noci-powershell-modules\nGoldenGate Admin client\nMost OCI SDKs, including:\nJava\nPython\nGo\nTypeScript and JavaScript\nRuby\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Tagging, \nFor known issues with Tagging, see Known Issues\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Big Data, \nFor known issues with Big Data Service, see  Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci,  Load Balancer service, \n Use Load Balancer to provide automated traffic distribution from one entry point to multiple servers reachable from your virtual cloud network (VCN)."
    },
    {
        "text": "oracle cloud infrastructure, oci, Enrich Metadata Using Custom Properties service, \n 6. Delete a Custom Property, \n\n\nOn the Custom Properties page, from the list of custom\n                    properties, click the Actions menu of the custom property that you want to\n                    delete, and then click Delete. \n\nIn the Delete Custom Property confirmation box that\n                    appears, type Delete to confirm the deletion. When you\n                    delete a custom property, any association of the custom property to data catalog\n                    objects are removed.\n\nClick Delete.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell and Regions, \nWhen you start Cloud Shell, the service configures your Cloud Shell session with the currently selected region in the Console so that the OCI CLI is interacting with the selected Console region.\nIn the default bash prompt in Cloud Shell, the region that the OCI CLI is interacting with is echoed in the Cloud Shell command line prompt:\n\n\n\nAny changes to the selected region in Console after you've started your Cloud Shell session will not have an effect on your active Cloud Shell session.If you want to change the region that the OCI CLI is interacting with, in Cloud Shell, you can either:\n\nExit your current Cloud Shell session, then change the selected region in the Console, then start a new Cloud Shell session.\nModify the currently selected OCI CLI profile via the OCI_CLI_PROFILE environment variable\n\nFor more information, see the \"Managing Regions\" section in Using Cloud Shell. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Started with Cloud Guard service, \n Review Oracle Cloud Guard concepts, ensure you meet prerequisites, enable Cloud Guard initially, and then access Cloud Guard routinely."
    },
    {
        "text": "oracle cloud infrastructure, oci, Connecting to an Instance service, \n Connecting to a Windows Instance, \nYou can connect to a Windows instance using a Remote Desktop connection. Most Windows systems include a Remote Desktop client by default.\nTo connect to a Windows instance from a Remote Desktop Client\n\n\nOpen the Remote Desktop client.\nIn the Computer field, enter the public IP address of the instance. You can get the instance's public IP address from the Console.\nThe User name is opc. Depending on the Remote Desktop client you are using, you might have to connect to the instance before you can enter this credential.\nClick Connect to start the session.\nAccept the certificate if you are prompted to do so. \n\nIf you are connecting to the instance for the first time, enter the initial password that was provided to you by Oracle Cloud Infrastructure when you created the instance. You can get the instance's initial password from the Console. You will be prompted to change the password as soon as you log in. Your new password must be at least 12 characters long and must comply with Microsoft's password policy.\nOtherwise, enter the password that you created. If you are using a custom image, you might need to know the password for the instance that the image was created from. For details about Windows custom images, see Creating Windows Custom Images.\n\nPress Enter.\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci,  Application Dependency Management service, \n Application Dependency Management is a developer service in Oracle Cloud Infrastructure that detects security vulnerabilities in application dependencies."
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Data Science service, \n Ways to Access Data Science, You access Data Science using the Console, REST API, SDKs, or\n    CLI. \nUse any of the following options, based on your preference and its suitability for the task\n      you want to complete:\n\nThe OCI\n        Console is an easy-to-use,\n        browser-based interface. To access the Console, you must use a supported browser.\nThe REST APIs provide the most functionality, but\n        require programming expertise. API reference and endpoints provide endpoint details and links to\n        the available API reference documents including the Data Science REST API. \nOCI provides SDKs that interact with Data Science\n        without the need to create a framework.\nThe CLI provides both quick access and full\n        functionality without the need for programming.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n IAM, \nFor IAM with Identity Domain issues, see Known Issues for IAM with Identity Domains.\nFor IAM without Identity Domain issues, see Known Issues for IAM without Identity Domains.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Harvest Oracle Database Hosted in OCI Public Subnet Using Private Endpoint service, \n Oracle Database systems are protected with network security rules that restrict the\n        network traffic to only authorized subnets and IPs. Therefore, you must create and configure\n        a private endpoint so that Data Catalog can connect to the database system.\nIn this tutorial, you do the following:\n\nCreate the policies needed to harvest from Oracle database systems using private\n                endpoint.\nObtain the Oracle database system access details.\nCreate a private endpoint in Data Catalog.\nAttach the private endpoint to your data catalog.\nCreate a data asset.\nHarvest the data asset.\n\nFor additional information, see configuring a private\n                network.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n View Related Documentation, Use the Help menu to access documentation and support.\nThe listed documentation relates to the current Console page.\nOpen the \nHelp menu () and click the documentation link you want.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Model Deployments service, \n Troubleshoot your model deployments."
    },
    {
        "text": "oracle cloud infrastructure, oci,  DevOps service, \n DevOps is a continuous integration/continuous delivery (CI/CD) service that automates\n        the delivery and deployment of software to Oracle Cloud Infrastructure (OCI) compute\n        platforms."
    },
    {
        "text": "oracle cloud infrastructure, oci, Speech Overview service, \n Service Limits, In each region that is enabled for your tenancy, these limits apply:\nFile Limits\n\n\nThe maximum file size is 2 GB.\n\n\nFile duration is a maximum of 4 hours.\n\n\nJob Limits\n\n\nEach job can have\n                    up to 100 tasks.\n\n\nJobs are retained for 90 days.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Some Common Features service, \n As you prepare to customize Oracle Cloud Guard, there\n        are several features that are common across more than one area.\nYou can preview these features in the following sections before you start customizing Cloud Guard, or you can follow links from specific tasks\n            where the information is helpful. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using the Deploy to Oracle Cloud Button service, \n Supported Providers, \nThe following providers are supported for forming package URLs to use with the Deploy to Oracle Cloud button:\nGitHubExample URL 1: Direct: https://github.com/myrepo/mydirectory/master.zipExample URL 2: Release: https://github.com/myrepo/mydirectory/0.0.1.zipTo get the .zip URL to a release in GitHub, see https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/linking-to-releases.\nGitLabExample URL 1: Direct: https://gitlab.com/myrepo/mydirectory/master.zipExample URL 2: Release: https://gitlab.com/myrepo/mydirectory/0.0.1.zip\nObject Storage (pre-authenticated request URL)Example URL: https://objectstorage.region.oraclecloud.com/p/encrypted-string/n/object-storage-namespace/b/bucket/o/filename\n\nTo troubleshoot an error code, see Error Code 400 for Deploy Button.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Scenario: Sending Streaming Data to Logging Analytics service, \n Using the API, \nUse the CreateServiceConnector operation to create the service connector. \nExample CreateServiceConnector requestPOST /20200909/serviceConnectors\nHost: service-connector-hub.us-phoenix-1.oraclecloud.com\n<authorization and other headers>\n{\n  \"compartmentId\": \"<compartment_OCID>\",\n  \"displayName\": \"Stream to Logging Analytics\",\n  \"source\": {\n    \"kind\": \"streaming\",\n    \"streamId\": \"<stream_OCID>\",\n    \"cursor\" : {\n        \"kind\": \"LATEST\"\n    }\n  },\n  \"target\": {\n   \"kind\": \"loggingAnalytics\",\n   \"logGroupId\": \"<log_group_OCID>\",\n   \"logSourceIdentifier\": \"<log_source_name>\"\n  }\n}\nFor help with troubleshooting, see Troubleshooting Service Connectors and Troubleshooting Notifications. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, About Conda Environments service, \n \nWe recommend that you use conda environments to package your Python dependencies\n            inside your notebook sessions. Each conda environment that you create in your notebook\n            session can correspond to a different notebook kernel in JupyterLab. Conda environments\n            allow you to run notebooks in different kernels. Each kernel has a set of Python\n            libraries associated with it. The base install has a very minimal set of libraries\n            installed. The service is designed to use conda environments.\nThe notebook session environment includes the odsc conda CLI tool and\n            the conda Environment Explorer. \nThe odsc conda CLI tool allows you to install, browse, search, and\n            publish conda environments. You can access the odsc conda CLI\n            documentation by executing odsc conda -h in a terminal window tab of\n            your notebook session.\nThe Environment Explorer  in JupyterLab helps you browse\n            and search conda environments. \nAlthough the conda CLI is available in a notebook session, we recommend\n            that you use odsc conda to browse, install, clone, publish, and delete\n            conda environments. It is preinstalled in notebook sessions and is available in a\n            terminal window tab. The odsc conda CLI installs the necessary\n            dependencies in your conda to make it available as a kernel in JupyterLab and creates\n            the required manifest file that is necessary for each conda environment. \nThe Python3 conda environment is preinstalled in the notebook session. This conda environment is a Python 3 based conda environment and has a minimal set of libraries installed. We recommend that you install at least one Data Science conda environment or create your own. \n Important\nTo ensure that conda environments can be listed in your notebook sessions or used in\n                your jobs:\nEither use the default networking option when you create your\n                        notebook sessions or jobs, and no other setup is needed.\n\nOr if you decide to use the custom networking option of  notebook\n                            sessions or jobs, then set up your VCN and subnet to route traffic\n                            through either the NAT gateway or the service gateway of the VCN.\nSee notebook\n                                sessions or jobs for networking options.\n\n\n\nUsing the Anaconda Technology on OCI\nTo start using Anaconda in OCI Data Science, build or customize your own conda environment. \nFollowing the partnership announcement between Oracle and Anaconda , means that while running your workloads on OCI, you can use Anaconda while running your workloads on OCI. You can use the Anaconda repository of packages without purchasing a separate license from Anaconda. Anaconda is the standard distribution channel for open source software in machine learning and AI services. \nYou can use the Anaconda repository of packages by adding anaconda or main as the first channel listed in your conda compatible environment file (environment.yaml). \nThis sample environment.yaml file prioritizes anaconda over the community driven conda-forge channel: \nchannels: \n  - anaconda\n  - conda-forge\ndependencies: \n  - keras \n  - tensorflow\n\nAfter you've created the conda environment, you can inspect the list of packages that were installed in the conda environment by running this command in a terminal window or in a notebook running inside the conda environment kernel:\nconda list \nFollowing is a sample output of the conda list command:\n\n    Name                    Version                   Build  Channel\n    absl-py                   0.15.0             pyhd3eb1b0_0    anaconda\n    aiohttp                   3.8.1            py38h7f8727e_1    anaconda\n    aiosignal                 1.2.0              pyhd3eb1b0_0    anaconda\n    argon2-cffi               21.3.0             pyhd3eb1b0_0    anaconda\n    argon2-cffi-bindings      21.2.0           py38h7f8727e_0    anaconda\n    arrow                     1.2.3                    pypi_0    pypi\n    astor                     0.8.1            py38h06a4308_0    anaconda\n\nThe channel column in the response lists the source channel of the Python library that was installed in the environment. In this example, you can see that most packages were installed from anaconda. \nFor more details about the Anaconda Repository and why Anaconda is the recommended option to download open-source packages, watch how to seamlessly leverage Anaconda on OCI presented by the Oracle Developers.\n Important\nOracle is licensed to include packages from Anaconda and make these packages available to OCI customers. Pre-installed packages that are embedded in OCI products and services that you license from Oracle may be used under the terms of the applicable Oracle OCI license agreement or terms of service.\nYou can use Oracle\u00e2\u0080\u0099s cloud-hosted products and services with a preinstalled copy of Conda to access additional packages from Anaconda\u00e2\u0080\u0099s repository. This access is under the Anaconda's Terms of Service, except that Oracle OCI customers may use the Anaconda packages for commercial purposes on the OCI platform without obtaining a separate paid license from Anaconda. The packages are only for use as part of our services and don't entitle you to download them to your own infrastructure or to use Anaconda\u00e2\u0080\u0099s trademarks. Packages may have their own licenses provided by the package authors.\nCreate an account on Anaconda Nucleus and to get started using Anaconda.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Oracle Cloud Migrations service, \n Limits and Quotas in Oracle Cloud Migrations, A service limit is the quota or allowance set on the resources that you use when\n        accessing the migration services.\n\nThe following are the resources and the Oracle Cloud Migrations service limits for your region:\n\n\nResource Group\nResource Name/Description\nLimit Name\nDefault Service Limit\nDefault Pay-as-you-go\n\n\n\nOCB Discovery\nAsset Source Count\nasset-source-count\n20\n10\n\n\nDiscovery Schedule Count\ndiscovery-schedule-count\n5\n5\n\n\n OCB Inventory\nNumber of assets that can be created in inventory\nasset-count\n5000\n1000\n\n\nOracle Cloud Migrations\nNumber of migration projects\nmigrations-count\n20\n10\n\n\nNumber of migration plans \nmigration-plans-count\n50\n25\n\n\nNumber of assets in migrations\nmigration-assets-count\n1000\n100\n\n\nNumber of target assets in migrations\nmigration-targetassets-count\n1000\n100\n\n\nNumber of replication schedules\nreplication-schedule-count\n10\n5\n\n\nMaximum Environment Count\nenvironment-count\n10\n5\n\n\nMaximum Agent Count\nagent-count\n20\n10\n\n\nMaximum Agent Dependency Count\nagent-dependency-count\n20\n10\n\n\n\n\nTo check the Oracle Cloud Migrations service limits, follow\n                the given steps:\n\nFrom the Console, open the navigation menu, and click Governance\n                        & Administration.\nUnder Governance, click Limits, Quotas, and\n                        Usage.\nFilter on the following values to view the resources and their limits:\nService: OCB Discovery, OCB Inventory, Oracle Cloud Migrations\nScope: <your region>\nCompartment: <your-tenancy-namespace >\n                                (root)\n\nTo increase the default service limits for any of the resources, click the\n                        request a service limit increase link. Note Only administrators can increase the service\n                        limit.For more information, see Service Limits.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci,  Notifications service, \n Notifications broadcasts messages to distributed\n                    components through a publish-subscribe pattern, delivering secure, highly\n                    reliable, low latency and durable messages for applications hosted on Oracle Cloud Infrastructure and externally. Use Notifications to get messages whenever alarms,\n                    service connectors, and event rules are triggered."
    },
    {
        "text": "oracle cloud infrastructure, oci, Training Custom Models with the Console service, \n Work Requests, Use the work requests created for trained models to view the log and error messages in the Console.\n\n\n\n\nOpen the navigation menu and click Analytics & AI.\n                    Under AI Services, click\n                    Language.\n\nClick Projects or Create custom models on the overview page.\n\nUnder List Scope, choose a Compartment that hosts your projects.\n\nIn the listed projects, click a project to host your training model.\n\nIn the listed models, click the name of your model.\n\nUnder Resources, click Work requests.\nThe work request table lists all of the operations created for the model\n\nClick the operation of interest from the list.\nThe log messages are displayed for the operation including timestamps.\n\nClick Error messages to view the messages.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Invoking a Model Deployment service, \n \nAfter a model deployment is in an active lifecycleState, the predict\n            endpoint can successfully receive requests made by clients. Invoking a model deployment\n            means that you can pass feature vectors or data samples to the predict endpoint, and\n            then the model returns predictions for those data samples.\nFrom your model deployment detail page, click Invoking Your Model.\n            The following details are displayed: \n\nThe model HTTP endpoint.\nSample code that enables you to invoke the model endpoint using the OCI CLI.\n                Alternatively, you could use the OCI Python, and Java SDKs to invoke the model with\n                the provide code sample. \n\nThe payload size limit is 10 MB.\n\n\nThe timeout on invoking a model is 60 seconds for HTTP calls. \n\n\nUse the sample code to invoke your model deployment.\nInvoking a model deployment calls the predict endpoint of the model deployment URI. This\n            endpoint takes sample data as input and is processed using the\n                predict() function in the score.py model artifact\n            file. The sample data is usually in JSON format though can be in other formats.\n            Processing means that the sample data could be transformed then passed to a models\n            inference method. The models can generate predictions that can be processed before being\n            returned back to the client. \nThe API responses are:\n\n\nHTTP Status Code\nError Code\nDescription\nRetry\n\n\n\n\n200\n\n\nNone\n\n\n200 Success.\n{\n  \"data\": {\n    \"prediction\": [\n      \"virginica\"\n    ]\n  },\n  \"headers\": {\n    \"content-length\": \"28\",\n    \"content-type\": \"application/json\",\n    \"opc-request-id\": \"\n  },\n  \"status\": \"200 OK\"\n}\n\n\nNone\n\n\n\n\n404\n\nNotAuthorizedOrNotFound\n\nModel deployment not found or authorization failed.\n\n\nNo\n\n\n\n\n405\n\nMethodNotAllowed\n\nMethod not allowed.\n\n\nNo\n\n\n\n\n411\n\nLengthRequired\n\nMissing content length header.\n\n\nNo\n\n\n\n\n413\n\nPayloadTooLarge\n\nThe payload size limit is 10 MB.\n\n\nNo\n\n\n\n\n429\n\nTooManyRequests\n\nToo Many Requests.\n\nLB bandwidth limit exceeded\n\nConsider increasing the provisioned load balancer bandwidth to avoid these errors by editing the model deployment.\n\nTenancy request-rate limit exceeded\n\nMaximum number of requests per second per tenancy is set to 150. \nIf you are consistently receiving error messages after increasing the LB bandwidth, use the OCI Console to submit a support ticket for your tenancy. Include the following details in the ticket.\n\n\nDescribe your issue with the error message that occurred, and indicate the new request per second needed for your tenancy.\n\nIndicate that it is a minor loss of service.\n\nIndicate Analytics & AI and Data Science.\n\n\nIndicate that the issue is creating and managing models.\n\n\n\n\n\n\nYes, with backoff\n\n\n\n\n500\n\nInternalServerError\n\nInternal Server Error.\n\n\nService Timeout. \nThere is a 60 second timeout for the /predict endpoint. This timeout value cannot be changed.\n\n\nThe score.py file returns an exception.\n\n\n\n\nYes, with backoff\n\n\n\n\n503\n\nServiceUnavailable\n\nModel server unavailable.\n\n\nYes, with backoff\n\n\n\nModel Inference Endpoint (Predict) Request Throttling\nPredict endpoint requests may be throttled based on your activity and resource consumption over time. \nThis is to maintain high availability and fair use of resources by protecting model serving application servers from being overwhelmed by too many requests, and prevent denial-of-service attacks. If you make too many requests too quickly, you might see some succeed while others fail. When a request fails because of throttling, the service returns response code 429 with one of the following error codes and description: \n { \"code\": \"TooManyRequests\", \"message\": \"Tenancy request-rate limit exceeded. \nPlease use the OCI Console to submit a support ticket for your tenancy to increase the RPS.\"} \nOr\n { \"code\": \"TooManyRequests\", \"message\": \"LB bandwidth limit exceeded. \nConsider increasing the provisioned load balancer bandwidth to avoid these errors.\" } \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Adding and Removing Node Pools service, \n \nTo optimize resource usage, you can scale a cluster up and down by changing the number of node pools in the cluster.\nFor general information about modifying clusters, see Modifying Kubernetes Cluster Properties.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Service Mesh, \nFor known issues with Service Mesh, see Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Cloud Guard, \nFor known issues with Cloud Guard, see Known Issues for Cloud Guard.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of API Gateway service, \n Ways to Access Oracle Cloud Infrastructure, \n\nYou can access Oracle Cloud Infrastructure using the Console (a browser-based interface) or the REST API.\nInstructions for the Console and API are included in topics throughout this guide.\nFor a list of available SDKs, see Software Development Kits and Command Line Interface.\nTo access the Console, you must use a supported browser. To go to the Console sign-in page, open the navigation menu at the top of this page and click Infrastructure Console. You are prompted to enter your cloud tenant, your user name, and your password.\n\n\n\nFor general information about using the API, see REST APIs.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Developer Tools, "
    },
    {
        "text": "oracle cloud infrastructure, oci, Service Logs  service, \n \nOracle Cloud Infrastructure services emit service logs. Each of these\n            supported services has a Logs resource that allows you to enable\n            or disable logging for that service.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Certificates service, \n Using the API, \nFor information about using the API and signing requests, see REST APIs and Security Credentials. For information about SDKs, see SDKs and the CLI.\nUse the following operations to manage certificates:\n\nListCertificates\nGetCertificate\nCreateCertificate\nUpdateCertificate\nChangeCertificateCompartment\nScheduleCertificateDeletion\nCancelCertificateDeletion\nListCertificateVersions\nGetCertificateVersion\nRevokeCertificateVersion\nScheduleCertificateVersionDeletion\nCancelCertificateVersionDeletion\nListCertificateBundleVersions\nGetCertificateBundle\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n View Related Documentation, Use the Help menu to access documentation and support.\nThe listed documentation relates to the current Console page.\nOpen the \nHelp menu () and click the documentation link you want.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Extend Console Pages Using Schema Documents service, \n Review requirements, supported types, and examples for schema documents used with Terraform configurations in  Resource Manager.\nSchema documents are recommended for Terraform configurations when using Resource Manager. Including a schema document allows you to extend pages in the Oracle Cloud Infrastructure\nConsole. Facilitate variable entry in the Create stack page by surfacing SSH key controls and by naming, grouping, dynamically prepopulating values, and more. Define text in the Application Information tab of the Stack details page that opens for a created stack.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Searching and Exploring service, \n Exploring the Data Catalog, \nTo explore all the data assets\u00c2\u00a0 you create in a data\n      catalog, click Data Assets on the Home tab. You can also click + from tabs and\n      select Data Assets.\nThe Data Asset tab displays a list of all data assets in your data catalog instance. Details for the data asset are listed, such as path, description, and so on. Use sort to specify how you want the results to be displayed.\n\n      You can search for a specific data asset by name. In the Search within data assets box,\n      enter a complete or partial data asset name and click the search icon or press enter. The list\n      is refreshed to display data assets that match your search string.\nUsing the available filters in the Filters section, you refine the report. As you\n      apply each filter, the list refreshes automatically. To refresh the Data Assets list at any\n      time, click Refresh.\nIn the Data Assets list, click a data asset name to view details for the data asset.\nClick the Actions menu for a data asset to perform other actions on the data asset.\n\n\nSelect View Details to modify data asset and connection details.\n\n\nSelect Harvest to harvest the data asset.\n\n\nSelect Delete to delete the data asset. A confirmation window displays. Type\n            Delete to confirm you want to delete the data asset and then click Delete.\n          Any harvested data entities or attributes in the data asset are also deleted.\n\nSelect Copy Data Asset Key to copy the unique key for a data asset. You can use\n        this key to provide granular access to users in your data catalog policies.\n\nOn the Data Assets tab, you can also create data assets and browse data assets.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating an API Deployment Specification service, \n \nBefore you can deploy an API\u00c2\u00a0on an API\u00c2\u00a0gateway, you have to create an API deployment specification. Every API\u00c2\u00a0deployment has an API deployment specification.\nEach API deployment specification describes a set of resources, and the methods (for\n            example, GET, PUT) that can be performed on each resource.\nYou can use a single API\u00c2\u00a0gateway  as the front end for multiple back-end services by:\n\nCreating a single API deployment  on the API gateway, with an API deployment specification that defines multiple back-end services.\nCreating multiple API deployments on the same API gateway, each with an API deployment specification that defines one (or more) back-end services.\n\nTypically, back-end services will be in the same VCN as the API\u00c2\u00a0gateway on which you\n            deploy an API. However, they don't have to be. In the API deployment specification, you\n            can describe back-end services that are on a private or public subnet in your tenancy,\n            as well as services outside your tenancy (including on the public internet). Wherever\n            they are located, the back-end services must be routable from the subnet containing the\n            API\u00c2\u00a0gateway on which the API\u00c2\u00a0is deployed. For example, if the back-end service is on the\n            public internet, the VCN must have an internet gateway to enable the API gateway to\n            route requests to the back-end service.\n  You can create an API\u00c2\u00a0deployment specification:\n\nUsing dialogs in the Console whilst creating an API\n                deployment.\nUsing your preferred JSON editor to create a separate JSON file. You can then\n                specify the JSON file when using the Console, the\n                CLI, or the API\u00c2\u00a0to create an API\u00c2\u00a0deployment.\nUsing an API description file you upload for an API resource. The API description\n                file provides some initial values for the API deployment specification, which you\n                can modify and extend when deploying the API resource on an API gateway. See Creating an API Resource with an API Description.\n\nThe instructions in this topic show a basic API deployment specification with a single backend, only one route, and no request or response policies. See Example API Deployment Specification with Multiple Back Ends for a more typical  API deployment specification that includes multiple back ends, each with one or more routes.\nIn addition, you can add request and response policies that apply to routes in an API deployment specification (see Adding Request Policies and Response Policies to API Deployment Specifications). \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Started with Service Mesh service, \n To set up Service Mesh, several steps need to be performed. The following sections\n        describe the prerequisites, requirements, and steps needed.\nService Mesh Prerequisites\nBefore you add Service Mesh to your application, ensure you have the following setup\n                or installed.\n\nInstall the following on Oracle Cloud Infrastructure. \nAn existing Oracle Container Engine Kubernetes cluster running a\n                            supported Kubernetes version. See Supported Versions of\n                                Kubernetes for version details.\nSee Create a Cluster with the\n                                        Quick Create Workflow for default cluster\n                                    installation.\nSee Developer Tutorials for\n                                    detailed installation instructions for several development\n                                    frameworks.\n\n\nAn application deployed to the previous created cluster.\n\n\nInstall the following on a laptop, personal computer, or virtual machine that\n                    manages your Kubernetes application. \nOracle OCI CLI 3.8.0 or later. See Working with OCI CLI for\n                            installation instructions.\nThe Kubernetes CLI tool kubectl. See Install Kubernetes Tools for details.\nEnsure you can access the OKE cluster from the command line\n                                    using kubectl by setting up the\n                                        kube-config file. For detailed steps, see:\n                                        Setting Up Local Access to Clusters\n\nDocker, see Getting Started with Docker for\n                            details.\nInstall the following to accumulate and graph service mesh data: \nPrometheus for collecting data. See the Prometheus installation\n                                        instructions here.\nGrafana for graphing your data. See the Grafana installation\n                                        instructions here\n\n\n\n\n Important Currently, Service Mesh only supports Flannel overlay networking.\nNext: Install OCI Service Operator for Kubernetes for Service Mesh\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Function Development Kits (FDKs) service, \n How to find out the latest FDK build-time and runtime base image versions for a\n        particular supported language version, \nTo find out the latest FDK build-time and runtime base image versions that the Fn Project\n            CLI is currently using to build executables, and to provide the runtime environment, for\n            functions in a particular version of a given language.\n\nIf it hasn't already been upgraded, upgrade the Fn Project CLI to the most recent\n                version (version 0.6.7 or later). See Upgrading the Fn Project CLI.\n\nTo see the supported language versions available, run:\nfn init --help | grep runtime\nFor example:\nfn init --help | grep runtime\n\n--runtime value Choose an existing runtime - dotnet, dotnet3.1, dotnet6.0, go, go1.15, java, java11, java17, java8, kotlin, node, node11, node14, python, python3.6, python3.7, python3.8, python3.9, ruby, ruby2.7\nNote the valid values of the --runtime command option for the particular language you're interested in, which include the numbers of supported versions. For example, java17, java11, java8, python3.9, python3.8, python3.7, python3.6, node14, node11, ruby2.7, go1.15, or dotnet3.1 and dotnet6.0 (for C#).\n\nIn a terminal window, create a new helloworld function by\n                    entering:fn init --runtime <language-version> hello-funcwhere\n                        <language-version> is the particular language and\n                    version you're interested in.For\n                example:fn init --runtime java8 hello-func\nChange to the /hello-func directory created for the new function,\n                and open the func.yaml file in a text editor.The latest supported FDK build-time\n                    and runtime base image versions for the language version you specified are shown\n                    as values of the build_image: and run_image:\n                    parameters.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating Applications service, \n Using the API, \nFor information about using\n                the API and signing requests, see REST APIs\n                and Security Credentials. For information about\n                SDKs, see Software Development Kits and Command Line Interface.\n\nUse these API operations to manage applications:\n\nCreateApplication\n\nDeleteApplication\n\nGetApplication\n\nUpdateApplication\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n Use Support Chat in the Console, \nUse Support Chat to get immediate help with common issues. To connect to the Oracle Support Digital Assistant: Open the \nHelp menu () and click Chat with us.\nA chat window opens that connects you to My Oracle Support.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Software Development Kits and Command Line Interface service, \n \nOracle Cloud Infrastructure provides a number of Software Development Kits (SDKs) and a Command Line Interface (CLI) to facilitate  development of custom solutions.\n\nSoftware Development Kits (SDKs) \nBuild and deploy apps that integrate with Oracle Cloud Infrastructure services. Each SDK provides the tools you need to develop an app, including code samples and documentation to create, test, and troubleshoot. In addition, if you want to contribute to the development of the SDKs, they are all open source and available on GitHub.\nSDK for Java\nSDK for Python\nSDK for TypeScript and JavaScript\nSDK for .NET\nSDK for Go\nSDK for Ruby\n\nCommand Line Interface (CLI)\n                \nThe CLI provides the same core capabilities as the Oracle Cloud Infrastructure Console and provides additional commands that can extend the Console's functionality. The CLI\u00c2\u00a0is convenient for developers or anyone who prefers the command line to a GUI.\nPL/SQL SDK The Oracle Cloud\n                Infrastructure SDK for PL/SQL enables you to write code to manage Oracle Cloud\n                Infrastructure resources. The latest version of the PL/SQL SDK is pre-installed by\n                Oracle for all Autonomous Databases using shared Exadata infrastructure.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell Resource Location and Ownership, \nWhen you first start Cloud Shell, the service creates a persistent block storage volume (5GB) for your home directory. The home directory volume is located in your tenancy home region. The machine running your Cloud Shell session is also located in your tenancy home region.\n Note Cloud Shell uses your user OCID to create your home directory. If you have multiple\n            accounts in a tenancy (for example, you have a federated and a non-federated user\n            account), you will get a separate, unique Cloud Shell home directory for each account. \nChanging the Console region selection, or logging in to the Console via a different\n            regional URL will have no effect on where your Cloud Shell machine and home directory\n            volume are located. To confirm your tenancy home region, view your Tenancy Details page\n            in the Console.\n Note\nCloud Shell resources (including the VM used for your Cloud Shell session) are owned\n                by the Cloud Shell service and do not exist in your tenancy. Because of this, you\n                cannot add the Cloud Shell VM you are using to a dynamic group in your tenancy, or\n                use the instance principle of the instance used for your Cloud Shell session.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Harvest from Autonomous Databases with Private Access service, \n Before You Begin, \nTo successfully perform this tutorial, you must have the following:\n\nAn Oracle Cloud Infrastructure account. See signing up for Oracle Cloud Infrastructure.\nAccess to use the Data Catalog resources. See prerequisites and policy examples.\nA created data catalog instance. See creating a data catalog instance.\n\nIf you already have the autonomous database you want to harvest from, you can use the details\n      for that database to complete this tutorial. If you don't have an existing autonomous database\n      with private access and want to try this tutorial, you can follow the following instructions\n      to set up the resources needed to perform this tutorial.\nSetting up the Resources Needed for this Tutorial\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Differences between OCI Functions and Fn Project service, \n Additional Context Configuration Parameters in OCI Functions, \nAs well as supporting  Fn Project context configuration parameters, OCI Functions also has some additional parameters, as shown in the following table.\n\n\nAdditional Parameter\nSet in\nValue\nNotes\n\n\n\nprovider\n\nA context configuration .yaml file in ~/.fn/contexts\noracle\n\n\nEnables OCI Functions rather than Fn Project functionality. When provider is set to oracle, the following parameters are valid:\n\noracle.compartment-id\n\noracle.profile\n\nSee Creating an Fn Project CLI Context to Connect to Oracle Cloud Infrastructure.\n\n\n\n\noracle.compartment-id\n\nA\u00c2\u00a0context configuration .yaml file in ~/.fn/contexts\n<compartment -ocid>\n\n\nSpecifies the OCID of the Oracle Cloud Infrastructure compartment that owns function-related resources. \nSee Creating an Fn Project CLI Context to Connect to Oracle Cloud Infrastructure.\n\n\n\noracle.profile\n\nA\u00c2\u00a0context configuration .yaml file in ~/.fn/contexts\n<profile-name>\n\n\nSpecifies which profile to use from the ~/.oci/config file. If not set, the profile named default is used.\nSee Setting the Context for the Fn Project CLI Using the oracle.profile Parameter\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Speech Overview service, \n Key Concepts, These are the key Speech service\n        concepts:\n\nTranscription Jobs\n\nA job is a single asynchronous request from the Console or the Speech API. Each job is uniquely identified\n                        by an id, which you can use to retrieve job status and results.\nA job in a tenant is processed in a strict first in first out manner. Each\n                        job can contain up to 100 tasks. If you submit a job that exceeds the\n                        maximum tasks, that job fails. Jobs are retained for 90 days.\n\nTasks\n\nA task is the result of a single file processed in a job. Jobs can have\n                        multiple tasks based on what's stored in your Object Storage bucket that you\n                        specify for a job.\n\nModels\n\nPretrained acoustic and language models power the job transcription\n                        process.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n View Related Documentation, Use the Help menu to access documentation and support.\nThe listed documentation relates to the current Console page.\nOpen the \nHelp menu () and click the documentation link you want.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Container Engine for Kubernetes Metrics service, \n \nYou can monitor the health, capacity, and performance of Kubernetes clusters managed by\n                Container Engine for Kubernetes using metrics\u00c2\u00a0, alarms\u00c2\u00a0, and notifications. \nThis topic describes the metrics emitted by Container Engine for Kubernetes in the oci_oke metric namespace.\nResources: clusters, worker nodes\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, OCI Functions Concepts service, \n Invocations, \nIn OCI Functions, a function's code is run (or executed) when the function is called (or invoked). You can invoke a function that you've deployed to OCI Functions from:\n\n The Fn Project CLI.\nThe Oracle Cloud Infrastructure SDKs.\nSigned HTTP requests to the function's invoke endpoint. Every function has an invoke endpoint.\nOther Oracle Cloud services (for example,  triggered by an event in the Events service) or from external services.\n\nWhen a function is invoked for the first time, OCI Functions pulls the function's Docker image from the specified Docker registry, runs it as a Docker container, and executes the function. If there are subsequent requests to the same function, OCI Functions directs those requests to the same container. After a period  being idle, the Docker container is removed.\nOCI Functions shows information about function invocations in metric charts.\nSee Invoking Functions.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Listeners for Load Balancers service, \n Describes how to use listeners to check for incoming traffic on the load balancer's\n        IP\u00c2\u00a0address.\nA listener is a logical entity that checks for incoming traffic on the load balancer's IP\u00c2\u00a0address. To handle TCP, HTTP,\u00c2\u00a0and HTTPS traffic, you must configure at least one listener per traffic type. When you create a listener, you must ensure that your VCN's security rules allow the listener to accept traffic.\n\n Tip\nTo accommodate high-volume traffic, Oracle strongly recommends that you use stateless security rules for your load balancer subnets. See Stateful Versus Stateless Rules for more information.\n\n\nYou can have one SSL certificate bundle per listener. You can configure two listeners,\n            one each for ports 443 and 8443, and associate SSL certificate bundles with each\n            listener. For more information about SSL certificates for load balancers, see SSL Certificates.\nClick Listeners under Resources in the Load Balancer Details page to\n            display the Listeners page. This page contains a button for creating listeners.\nYou can perform the following listener management tasks:\n\n\nCreating a Listener\n\n\nListing the Listeners\n\n\nGetting a Listener's Details\n\n\nEditing a Listener\n\n\nEnabling a Listener to Accept Traffic\n\n\nDeleting a Listener\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Key Concepts service, \n \n\nThe analytics reports and historical data in Oracle Pulse are based on business\n                metrics and key performance indicators (KPIs) from different areas of service\n                delivery, as follows:\n\nBusiness metrics are measurements that allow you to analyze\n                            business performance. Typically they are numeric values, as simple as\n                            the sum of values in a fact column or a complex calculation involving\n                            mathematical operators.\n\n\nKey performance indicators (KPIs) are specific measurements to\n                            define and track objectives. KPIs have measurable values that usually\n                            vary with time, and can be compared over time for trending and\n                            performance patterns. KPI evaluation is determined by comparing the\n                            actual value against a defined threshold.\n\nOracle Pulse covers six important areas of service delivery: availability,\n                    storage, incidents, changes, and (where enabled) Business Transaction Monitoring\n                    and Business Insight. Oracle Pulse also covers host and database metrics. This\n                    chapter explains the conceptual basis for Oracle Pulse business metrics and key\n                    performance indicators in each area, as explained in the following sections:\nAvailability Metrics\nStorage Metrics\nIncident Metrics\nChange Metrics\nSelf Healing Metrics\nBusiness Transaction Monitoring Metrics\nBusiness Insight Metrics\nHost and Database Metrics\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Detecting Anomalies for Large Datasets service, \n Using the Console, \n\nPrerequisites:\nYou must have a project that contains a trained model for use in an asynchronous anomaly detection job.\n\n\n\nOpen the navigation menu and click Analytics & AI. Under AI Services, click Anomaly Detection. \n\nSelect the project you want to use.\n\nClick Jobs.\n\nClick Create job.\n\nSelect a compartment for the resource.\nYou can select a different compartment to store the resource instead of the default.\n\nEnter a unique name (255 character limit) for the resource. If you don't provide a name, a name is automatically generated for you using the format aianomalydetectionprojectYYYYNNDDHHMMSS. For example, aianomalydetectionproject20221125155844.\n\nEnter a description (400 character limit) for the resource. If you don't add a description, it remains empty.\n\nSelect the model you want to run in this job.\n\nSelect the input request type that you want to use for the job.\n\nInlineDrop a JSON or CSV file into the File box, or use Select File to locate and select it from a local drive.\nObject storeSelect the Object Storage bucket that contains the detection data file, then select file you want to use for this job. Only CSV files are supported.You can use multiple input buckets and detection data files by clicking Additional input bucket and making further selections.\n\n\nSelect an output bucket to store the output files in.\n\nThe namespace shows you the tenancy the job is being created in.\n\n(Optional) \n                Use prefix's are used to easily identify the results.\n\nFor example, if myModel is the prefix, then the result file is myModel/results-file.json.\n\n\nClick Create job.\n\nThe asynchronous job Status is initially Accepted until the job starts running, then it is In Progress, and finally when the job finishes the status changes to Succeeded. The time it takes to run the job is dependent on the size of the detection datasets.\n\n\nClick the completed asynchronous job to view its details and review the job results.\n\nThe anomaly detection results file is saved in a separate folder in the selected Object Storage output bucket. The file name use the <model-OCID>/<output_bucket_name> naming convention.\n\n\n<model-OCID> is the OCID of the Anomaly Detection\nModel\n\n\n<output_bucket_name> is the Object Store bucket name. \n\n\nThe anomaly detection results file name is the same as the detection dataset file name suffixed with -results.\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Java Management, \nFor details about known issues in the Java Management service, see Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Service Logs  service, \n Supported Services, \nYou can enable service logs for the following Oracle Cloud Infrastructure services:\n\nAnalytics Cloud\nAPI Gateway\nDevOps\nEmail Delivery\nEvents\nFunctions\nIntegration Generation 2\nLoad Balancing\nMedia Flow\nObject Storage\nSite-to-Site VPN Note Site-to-Site VPN logs are only supported with v2 IPSec connections. v1 connections are not supported.\nVCN Flow\n                Logs\nWeb Application Firewall\n\n Note This list of Oracle Cloud Infrastructure services is updated as supported services are added.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Resource Discovery service, \n Output File Contents, \n Note Attributes are missing from some supported resources captured using resource\n            discovery. For more information, see Missing attributes in some discovered resources.\nResource discovery discovers resources that are in an\n                active or usable state. Resources that have been terminated or otherwise made\n                inactive are generally excluded from the generated configuration.\n\nBy default, the Terraform names of the discovered resources share the same name\n                    as the display name for that resource, if one exists.\nThe attributes of the resources are populated with the values that are returned\n                    by the OCI services.\n\n\nIn some cases, a required or optional attribute may not be discoverable from the\n                        OCI services and may be omitted\n                    from the generated Terraform configuration. This omission may be expected\n                    behavior from the service, which may prevent discovery of certain sensitive\n                    attributes or secrets. In such cases, a placeholder value will be set along with\n                    a comment like this:\nadmin_password = \"<placeholder for missing required attribute>\" #Required attribute not found in discovery, placeholder value set to avoid plan failure\nThe missing required attributes are also added to lifecycle\n                        ignore_changes. This addition is done to avoid Terraform\n                    plan failure when moving manually-managed infrastructure to Terraform-managed\n                    infrastructure. Any changes made to such fields are not reflected in the\n                    Terraform plan. If you want to update these fields, remove them from\n                        ignore_changes.\n\n\nResources that are dependent on availability domains will be generated under\n                        availability_domain.tf file. These include:\n\noci_core_boot_volume\noci_file_storage_file_system\noci_file_storage_mount_target\noci_file_storage_snapshot\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n Use Support Chat in the Console, \nUse Support Chat to get immediate help with common issues. To connect to the Oracle Support Digital Assistant: Open the \nHelp menu () and click Chat with us.\nA chat window opens that connects you to My Oracle Support.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Resource Discovery service, \n Supported Resources, \n\nEach supported service has one or more discoverable resources.\n\nSupported resources by service\nadm\n\noci_adm_vulnerability_audit\noci_adm_knowledge_base\n\nai_anomaly_detection\n\noci_ai_anomaly_detection_ai_private_endpoint\noci_ai_anomaly_detection_data_asset\noci_ai_anomaly_detection_detect_anomaly_job\noci_ai_anomaly_detection_model\noci_ai_anomaly_detection_project\n\nai_vision\n\noci_ai_vision_project\noci_ai_vision_model\n\nanalytics\n\noci_analytics_analytics_instance\n\nannouncements_service\n\noci_announcements_service_announcement_subscription\noci_announcements_service_announcement_subscriptions_actions_change_compartment\noci_announcements_service_announcement_subscriptions_filter_group\n\napigateway\n\noci_apigateway_api\noci_apigateway_gateway\noci_apigateway_deployment\noci_apigateway_certificate\noci_apigateway_subscriber\noci_apigateway_usage_plan\n\napm\n\noci_apm_apm_domain\n\napm_config\n\noci_apm_config_config\n\napm_synthetics\n\noci_apm_synthetics_script\noci_apm_synthetics_monitor\noci_apm_synthetics_dedicated_vantage_point\n\nartifacts\n\noci_artifacts_container_configuration\noci_artifacts_container_repository\noci_artifacts_container_image_signature\noci_artifacts_generic_artifact\noci_artifacts_repository\n\nauto_scaling\n\noci_autoscaling_auto_scaling_configuration\n\nbastion\n\noci_bastion_bastion\noci_bastion_session\n\nbds\n\noci_bds_bds_instance\noci_bds_auto_scaling_configuration\noci_bds_bds_instance_api_key\noci_bds_bds_instance_metastore_config\n\nblockchain\n\noci_blockchain_blockchain_platform\noci_blockchain_peer\noci_blockchain_osn\n\nbudget\n\noci_budget_budget\noci_budget_alert_rule\n\ncertificates_management\n\noci_certificates_management_ca_bundle\noci_certificates_management_certificate_authority\noci_certificates_management_certificate\n\ncloud_bridge\n\noci_cloud_bridge_agent_plugin\noci_cloud_bridge_agent_dependency\noci_cloud_bridge_environment\noci_cloud_bridge_agent\noci_cloud_bridge_asset_source\noci_cloud_bridge_discovery_schedule\noci_cloud_bridge_asset\noci_cloud_bridge_inventory\n\ncloud_guard\n\noci_cloud_guard_target\noci_cloud_guard_managed_list\noci_cloud_guard_responder_recipe\noci_cloud_guard_data_mask_rule\noci_cloud_guard_detector_recipe\noci_cloud_guard_security_recipe\noci_cloud_guard_security_zone\noci_cloud_guard_data_source\n\ncloud_migrations\n\noci_cloud_migrations_migration_asset\noci_cloud_migrations_migration_plan\noci_cloud_migrations_target_asset\noci_cloud_migrations_migration\noci_cloud_migrations_replication_schedule\n\ncontainerengine\n\noci_containerengine_cluster\noci_containerengine_node_pool\n\ncore\n\noci_core_boot_volume_backup\noci_core_boot_volume\noci_core_console_history\noci_core_cluster_network\noci_core_compute_image_capability_schema\noci_core_cpe\noci_core_cross_connect_group\noci_core_cross_connect\noci_core_dhcp_options\noci_core_drg_attachment\noci_core_drg\noci_core_dedicated_vm_host\noci_core_image\noci_core_instance_configuration\noci_core_instance_console_connection\noci_core_instance_pool_instance\noci_core_instance_pool\noci_core_instance\noci_core_internet_gateway\noci_core_ipsec\noci_core_local_peering_gateway\noci_core_nat_gateway\noci_core_network_security_group\noci_core_network_security_group_security_rule\noci_core_private_ip\noci_core_public_ip\noci_core_remote_peering_connection\noci_core_route_table\noci_core_security_list\noci_core_service_gateway\noci_core_subnet\noci_core_vcn\noci_core_vlan\noci_core_virtual_circuit\noci_core_vnic_attachment\noci_core_volume_attachment\noci_core_volume_backup\noci_core_volume_backup_policy\noci_core_volume_backup_policy_assignment\noci_core_volume_group\noci_core_volume_group_backup\noci_core_volume\noci_core_public_ip_pool\noci_core_ipv6\noci_core_drg_route_table\noci_core_drg_route_distribution\noci_core_drg_route_table_route_rule\noci_core_capture_filter\noci_core_vtap\n\ndata_connectivity\n\noci_data_connectivity_registry\noci_data_connectivity_registry_connection\noci_data_connectivity_registry_data_asset\noci_data_connectivity_registry_folder\n\ndata_flow\n\noci_dataflow_application\noci_dataflow_private_endpoint\noci_dataflow_run_statement\n\ndata_labeling_service\n\noci_data_labeling_service_dataset\n\ndata_safe\n\noci_data_safe_data_safe_private_endpoint\noci_data_safe_on_prem_connector\noci_data_safe_target_database\noci_data_safe_security_assessment\noci_data_safe_user_assessment\noci_data_safe_unset_security_assessment_baseline\noci_data_safe_report_definition\noci_data_safe_audit_trail\noci_data_safe_alert\noci_data_safe_audit_archive_retrieval\noci_data_safe_audit_profile\noci_data_safe_audit_policy\noci_data_safe_target_alert_policy_association\noci_data_safe_sensitive_type\noci_data_safe_masking_policy\noci_data_safe_masking_policies_masking_column\noci_data_safe_library_masking_format\noci_data_safe_sensitive_data_model\noci_data_safe_sensitive_data_models_sensitive_column\noci_data_safe_discovery_jobs_result\noci_data_safe_discovery_job\n\ndatabase\n\noci_database_autonomous_container_database\noci_database_autonomous_container_database_dataguard_association\noci_database_autonomous_database\noci_database_autonomous_exadata_infrastructure\noci_database_autonomous_vm_cluster\noci_database_backup_destination\noci_database_backup\noci_database_database\noci_database_db_home\noci_database_db_system\noci_database_exadata_infrastructure\noci_database_vm_cluster_network\noci_database_vm_cluster\noci_database_database_software_image\noci_database_cloud_exadata_infrastructure\noci_database_cloud_vm_cluster\noci_database_key_store\noci_database_external_container_database\noci_database_external_pluggable_database\noci_database_external_non_container_database\noci_database_external_database_connector\noci_database_pluggable_database\noci_database_vm_cluster_add_virtual_machine\noci_database_vm_cluster_remove_virtual_machine\noci_database_cloud_autonomous_vm_cluster\n\ndatabase_migration\n\noci_database_migration_connection\noci_database_migration_migration\n\ndatabase_tools\n\noci_database_tools_database_tools_private_endpoint\noci_database_tools_database_tools_connection\n\ndatacatalog\n\noci_datacatalog_catalog\noci_datacatalog_data_asset\noci_datacatalog_connection\noci_datacatalog_catalog_private_endpoint\noci_datacatalog_metastore\n\ndataflow\n\noci_dataflow_application\noci_dataflow_private_endpoint\n\ndataintegration\n\noci_dataintegration_workspace\n\ndatascience\n\noci_datascience_job\noci_datascience_job_run\noci_datascience_model\noci_datascience_model_provenance\noci_datascience_model_deployment\noci_datascience_notebook_session\noci_datascience_pipeline\noci_datascience_pipeline_run\noci_datascience_project\n\ndevops\n\noci_devops_project\noci_devops_deploy_environment\noci_devops_deploy_artifact\noci_devops_deploy_pipeline\noci_devops_deploy_stage\noci_devops_deployment\noci_devops_repository\noci_devops_repository_ref\noci_devops_build_pipeline\noci_devops_build_run\noci_devops_connection\noci_devops_build_pipeline_stage\noci_devops_trigger\noci_devops_repository_mirror\n\ndisaster_recovery\n\noci_disaster_recovery_dr_protection_group\noci_disaster_recovery_dr_plan_execution\noci_disaster_recovery_dr_plan\n\ndns\n\noci_dns_zone\noci_dns_steering_policy\noci_dns_steering_policy_attachment\noci_dns_tsig_key\noci_dns_rrset\noci_dns_resolver \noci_dns_resolver_endpoint\noci_dns_view\n\nem_warehouse\n\noci_em_warehouse_em_warehouse\n\nemail\n\noci_email_suppression\noci_email_sender\noci_email_email_domain\noci_email_dkim\n\nevents\n\noci_events_rule\n\nfile_storage\n\noci_file_storage_export\noci_file_storage_file_system\noci_file_storage_mount_target\noci_file_storage_replication\noci_file_storage_snapshot\n\nfunctions\n\noci_functions_application\noci_functions_function\n\nfusion_apps\n\noci_fusion_apps_fusion_environment_refresh_activity\noci_fusion_apps_fusion_environment_admin_user\noci_fusion_apps_fusion_environment_family\noci_fusion_apps_fusion_environment\noci_fusion_apps_fusion_environment_data_masking_activity\n\ngolden_gate\n\noci_golden_gate_connection\noci_golden_gate_connection_assignment\noci_golden_gate_database_registration\noci_golden_gate_deployment\noci_golden_gate_deployment_backup\n\nhealth_checks\n\noci_health_checks_http_monitor\noci_health_checks_ping_monitor\n\nidentity\n\noci_identity_api_key\noci_identity_authentication_policy\noci_identity_auth_token\noci_identity_compartment\noci_identity_customer_secret_key\noci_identity_dynamic_group\noci_identity_group\noci_identity_identity_provider\noci_identity_idp_group_mapping\noci_identity_policy\noci_identity_smtp_credential\noci_identity_swift_password\noci_identity_ui_password\noci_identity_user_group_membership\noci_identity_user\noci_identity_tag_default\noci_identity_tag_namespace\noci_identity_tag\noci_identity_network_source\noci_identity_domain\noci_identity_db_credential\noci_identity_import_standard_tags_management\n\nidentity_data_plane\n\noci_identity_data_plane_generate_scoped_access_token\n\nintegration\n\noci_integration_integration_instance\n\njms\n\noci_jms_fleet\n\nkms\n\noci_kms_key\noci_kms_key_version\noci_kms_vault\noci_kms_sign\noci_kms_verify\n\nlicense_manager\n\noci_license_manager_configuration\noci_license_manager_product_license\noci_license_manager_license_record\n\nlimits\n\noci_limits_quota\n\nload_balancer\n\noci_load_balancer_backend\noci_load_balancer_backend_set\noci_load_balancer_certificate\noci_load_balancer_hostname\noci_load_balancer_listener\noci_load_balancer_load_balancer\noci_load_balancer_path_route_set\noci_load_balancer_load_balancer_routing_policy\noci_load_balancer_rule_set\n\nlog_analytics\n\noci_log_analytics_log_analytics_object_collection_rule\noci_log_analytics_log_analytics_import_custom_content\noci_log_analytics_namespace_scheduled_task\noci_log_analytics_log_analytics_preferences_management\noci_log_analytics_log_analytics_unprocessed_data_bucket_management\noci_log_analytics_log_analytics_resource_categories_management\noci_log_analytics_namespace_ingest_time_rule\n\nlogging\n\noci_logging_log_group\noci_logging_log\noci_logging_unified_agent_configuration\n\nmanagement_agent\n\noci_management_agent_management_agent\noci_management_agent_management_agent_install_key\n\nmarketplace\n\noci_marketplace_accepted_agreement\noci_marketplace_publication\n\nmedia_services\n\noci_media_services_stream_packaging_config\noci_media_services_media_workflow\noci_media_services_stream_distribution_channel\noci_media_services_media_workflow_job\noci_media_services_stream_cdn_config\noci_media_services_media_asset\noci_media_services_media_workflow_configuration\n\nmetering_computation\n\noci_metering_computation_query\noci_metering_computation_custom_table\noci_metering_computation_schedule\n\nmonitoring\n\noci_monitoring_alarm\n\nmysql\n\noci_mysql_mysql_configuration\noci_mysql_heat_wave_cluster\noci_mysql_mysql_backup\noci_mysql_mysql_db_system\noci_mysql_channel\n\nnetwork_firewall\n\noci_network_firewall_network_firewall_policy\noci_network_firewall_network_firewall\n\nnetwork_load_balancer\n\noci_network_load_balancer_network_load_balancer\noci_network_load_balancer_backend_set\noci_network_load_balancer_backend_sets_health_checker\noci_network_load_balancer_backend\noci_network_load_balancer_listener\n\nnosql\n\noci_nosql_table\noci_nosql_index\n\nobject_storage\n\noci_objectstorage_bucket\noci_objectstorage_object_lifecycle_policy\noci_objectstorage_object\noci_objectstorage_preauthrequest\noci_objectstorage_replication_policy\n\noce\n\noci_oce_oce_instance\n\nocvp\n\noci_ocvp_sddc\noci_ocvp_esxi_host\n\noda\n\noci_oda_oda_instance\n\nons\n\noci_ons_notification_topic\noci_ons_subscription\n\nopa\n\noci_opa_opa_instance\n\nopensearch\n\noci_opensearch_opensearch_cluster\n\noperator_access_control\n\noci_operator_access_control_operator_control\noci_operator_access_control_operator_control_assignment\n\nopsi\n\noci_opsi_enterprise_manager_bridge\noci_opsi_operations_insights_private_endpoint\noci_opsi_operations_insights_warehouse\noci_opsi_operations_insights_warehouse_download_warehouse_wallet\noci_opsi_operations_insights_warehouse_rotate_warehouse_wallet\noci_opsi_operations_insights_warehouse_user\noci_opsi_awr_hub\noci_opsi_database_insight\noci_opsi_exadata_insight\noci_opsi_host_insight\noci_opsi_opsi_configuration\n\noptimizer\n\noci_optimizer_profile\n\nosmanagement\n\noci_osmanagement_managed_instance\noci_osmanagement_managed_instance_group\noci_osmanagement_software_source\n\nosp_gateway\n\noci_osp_gateway_subscription\n\nqueue\n\noci_queue_queue\n\nrecovery\n\noci_recovery_protected_database\noci_recovery_protection_policy \noci_recovery_recovery_service_subnet\n\nresourcemanager\n\noci_resourcemanager_private_endpoint\n\nsch\n\noci_sch_service_connector\n\nservice_mesh\n\noci_service_mesh_virtual_service\noci_service_mesh_access_policy\noci_service_mesh_mesh\noci_service_mesh_ingress_gateway_route_table\noci_service_mesh_virtual_service_route_table\noci_service_mesh_virtual_deployment\noci_service_mesh_ingress_gateway\n\nstack_monitoring\n\noci_stack_monitoring_monitored_resource\noci_stack_monitoring_discovery_job\noci_stack_monitoring_monitored_resources_list_member\noci_stack_monitoring_monitored_resources_search_association\noci_stack_monitoring_monitored_resources_search\noci_stack_monitoring_monitored_resources_associate_monitored_resource\n\nstreaming\n\noci_streaming_connect_harness\noci_streaming_stream_pool\noci_streaming_stream\n\nusage_proxy\n\noci_usage_proxy_subscription_redeemable_user\n\nvault\n\noci_vault_secret\n\nvbs_inst\n\noci_vbs_inst_vbs_instance\n\nvisual_builder\n\noci_visual_builder_vb_instance\n\nvn_monitoring\n\noci_vn_monitoring_path_analyzer_test\noci_vn_monitoring_path_analysi\n\nvulnerability_scanning\n\noci_vulnerability_scanning_host_scan_recipe\noci_vulnerability_scanning_host_scan_target\noci_vulnerability_scanning_container_scan_recipe\noci_vulnerability_scanning_container_scan_target\n\nwaa\n\noci_waa_web_app_acceleration_policy\noci_waa_web_app_acceleration\n\nwaas\n\noci_waas_address_list\noci_waas_custom_protection_rule\noci_waas_http_redirect\noci_waas_waas_policy\n\nwaf\n\noci_waf_web_app_firewall_policy\noci_waf_web_app_firewall\noci_waf_network_address_list\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n Post a Question to Oracle Forums, \nIf you cannot find an answer to your question through search, submit a new question to\n            one of the forums that Oracle supports. This option is available to all customers.\nCloud Customer Connect\nFor any issue related to Oracle Cloud Infrastructure, including provisioning of new resources, Console issues, identity, networking, documentation, storage, database, Edge services, or other solutions, you can post a question to Cloud Customer Connect at:\nhttps://community.oracle.com/customerconnect/categories/oracle-cloud-infrastructure-and-platform\nIf you are using only Always Free resources or using a Free Tier account, then use\n                Cloud Customer Connect for support queries.\n\nStack Overflow\nIf you are creating an application that integrates with Oracle Cloud Infrastructure APIs, endpoints, or services, then you\n                can also use Stack Overflow forums for development-related questions. Tag your\n                questions with oracle-cloud-infrastructure, as\n                follows:\nhttps://stackoverflow.com/questions/tagged/oracle-cloud-infrastructure\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Certificate Authorities service, \n Using the Command Line Interface (CLI), \nFor Certificates, you must use version 3.2.1 of the CLI or\n      later. For information about using the CLI, see Command Line Interface\n        (CLI). For a complete list of flags and options available for CLI commands, see the\n        Command Line Reference.\nSome of the following commands require complex input. For example, updating the revocation\n      configuration of a certificate authority (CA) requires providing the revocation configuration\n      details in JSON format. You can see the expected format of the input by opening a command\n      prompt and running the command with the --generate-full-command-json-input\n      option. For example, to generate the JSON for updating the revocation configuration for a\n      certificate authority (that you issued and manage internally), run the following command:\noci certs-mgmt certificate-authority update-subordinate-ca-issued-by-internal-ca --generate-full-command-json-input\nIn the output, the following shows how to input the revocation details specifically:\n{\n  \"customFormattedUrls\": [\n    \"string\",\n    \"string\"\n  ],\n  \"objectStorageConfig\": {\n    \"objectStorageBucketName\": \"string\",\n    \"objectStorageNamespace\": \"string\",\n    \"objectStorageObjectNameFormat\": \"string\"\n  }\n}\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Support Ticket Management service, \n Creating a Support Ticket, To create a support ticket:\n\nOpen the \nHelp menu () and click\n                        Create Support Request.\n\nEnter the following:\n\n\nIssue Summary: Enter a title that summarizes your issue. Avoid\n                            entering confidential information.\nDescribe Your Issue: Provide a brief overview of your issue.\nInclude all the information that support needs to route and\n                                    respond to your request. For example, \"I am unable to\n                                    connect to my compute instance.\"\nInclude troubleshooting steps taken and any available test\n                                    results.\n\nSelect the severity level for this request. \n\n\n\nOptionally, you can include the following details under Optional\n                        Information.\n\n\nService: Select the service that this support\n                            request is for.\nService category: Select the service\n                            category.\nIssue type: Select the type of issue you are\n                            experiencing.\nResource OCID: Select the resource OCID.\n\n\n\nClick Create Support Request.\n\nAfter you submit the request, My Oracle Support reviews the\n            request and, if your request is awarded, sends a confirmation email the address provided\n            in the primary contact details. If Oracle requires more information about your request,\n            then a follow-up email is sent to the address provided in the primary contact\n            details.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Logging service, \n Linux Unified Monitoring Agent, \n\nsystemd Units\nThe Unified Monitoring Agent is based on systemd units, and is composed of the following components:\n\nunified-monitoring-agent.service: The main Unified Monitoring Agent service.\nunified-monitoring-agent_config_downloader.service: The configuration automatic updater service.\nunified-monitoring-agent_config_downloader.timer: The timer unit, which triggers the automatic downloader service on specified, randomized, intervals.\nunified-monitoring-agent_restarter.path: The path unit, which triggers the reload of the configuration by the Unified Monitoring Agent, if a change is detected (because of a new configuration being downloaded by the automatic updater service).\n\n Note Most of the systemctl or journalctl commands must be run with super user privileges (either as root, or through sudo).\nTo verify the correct operation of these systemd units, you can use the systemctl command like the following:\nsystemctl status <unit_name>\nWhere <unit_name> must be replaced with one of the following values:\n\nunified-monitoring-agent.service\nunified-monitoring-agent_config_downloader.service\nunified-monitoring-agent_config_downloader.timer\nunified-monitoring-agent_restarter.path\n\nTypically these systemctl commands show output similar to the following:\nsystemctl status unified-monitoring-agent.service\n   unified-monitoring-agent.service - unified-monitoring-agent: Fluentd based data collector for Oracle Cloud Infrastructure\n   Loaded: loaded (/usr/lib/systemd/system/unified-monitoring-agent.service; enabled; vendor preset: disabled)\n   Active: active (running) since Tue 2020-09-29 13:54:03 UTC; 1min 37s ago\n     Docs: https://docs.cloud.oracle.com/\n  Process: 2337 ExecReload=/bin/kill -USR2 ${MAINPID} (code=exited, status=0/SUCCESS)\n  Process: 2321 ExecStart=/opt/unified-monitoring-agent/embedded/bin/fluentd --log /var/log/unified-monitoring-agent/unified-monitoring-agent.log --daemon /var/run/unified-monitoring-agent/unified-monitoring-agent.pid --log-rotate-size 1048576 --log-rotate-age 10 $EXTRA_OPTIONS (code=exited, status=0/SUCCESS)\n Main PID: 2327 (fluentd)\n   Memory: 66.3M (limit: 5.0G)\n   CGroup: /system.slice/unified-monitoring-agent.service\n           \u00e2\u0094\u009c\u00e2\u0094\u00802327 /opt/unified-monitoring-agent/embedded/bin/ruby /opt/unified-monitoring-agent/embedded/bin/fluentd --log /var/log/unified-monitoring-agent/unified-monitoring-agent.log --daemon /var/run/unif...\n           \u00e2\u0094\u0094\u00e2\u0094\u00802330 /opt/unified-monitoring-agent/embedded/bin/ruby -Eascii-8bit:ascii-8bit /opt/unified-monitoring-agent/embedded/bin/fluentd --log /var/log/unified-monitoring-agent/unified-monitoring-agent.lo...\nsystemctl status unified-monitoring-agent_config_downloader.service\n  unified-monitoring-agent_config_downloader.service - unified-monitoring-agent Fluentd configuration downloader.\n  Loaded: loaded (/usr/lib/systemd/system/unified-monitoring-agent_config_downloader.service; enabled; vendor preset: disabled)\n  Active: inactive (dead) since Tue 2020-09-29 13:54:38 UTC; 1min 30s ago\n Process: 2333 ExecStart=/opt/unified-monitoring-agent/embedded/bin/ruby /opt/unified-monitoring-agent/embedded/bin/fluent_config_updater.rb -c /etc/unified-monitoring-agent/conf.d/ -b 10 (code=exited, status=0/SUCCESS)\nMain PID: 2333 (code=exited, status=0/SUCCESS) \nsystemctl status unified-monitoring-agent_config_downloader.timer\n  unified-monitoring-agent_config_downloader.timer - Run unified-monitoring-agent configuration automatic updater.\n   Loaded: loaded (/usr/lib/systemd/system/unified-monitoring-agent_config_downloader.timer; enabled; vendor preset: disabled)\n   Active: active (waiting) since Tue 2020-09-29 13:54:03 UTC; 3min 57s ago \nsystemctl status unified-monitoring-agent_restarter.path\n  unified-monitoring-agent_restarter.path - \"Monitor the /etc/unified-monitoring-agent/conf.d/ directory for changes\"\n   Loaded: loaded (/usr/lib/systemd/system/unified-monitoring-agent_restarter.path; enabled; vendor preset: disabled)\n   Active: active (waiting) since Tue 2020-09-29 13:54:03 UTC; 4min 9s ago \nThe most important parts of the systemctl command output are the Loaded and Active fields. The Loaded field has the value loaded for all system units. The Active field has the following values:\n\nactive (running) for the unified-monitoring-agent.service unit.\nactive (waiting) or active (running) for the unified-monitoring-agent_restarter.path and the unified-monitoring-agent_config_downloader.timer units.\nactive (running) or inactive (dead) for the unified-monitoring-agent_config_downloader.service unit. For the latter value, the field Main PID includes the value code=exited, status=0/SUCCESS).\n\n\n\n\nCheck Running Processes\nAnother way to further verify the correct operation of the Unified Monitoring Agent, is to check the system\u00e2\u0080\u0099s running processes. When operating correctly, the Unified Monitoring Agent runs two processes: one supervisor process, and one worker process. You can verify their existence by running the following command in a terminal (sample output included):\nps aux | grep unified-monitoring-agen[t]\nroot      2327  0.0  2.3 307704 40864 ?        Sl   13:54   0:00 /opt/unified-monitoring-agent/embedded/bin/ruby /opt/unified-monitoring-agent/embedded/bin/fluentd --log /var/log/unified-monitoring-agent/unified-monitoring-agent.log --daemon /var/run/unified-monitoring-agent/unified-monitoring-agent.pid --log-rotate-size 1048576 --log-rotate-age 10\nroot      2330  0.2  2.1 297456 38192 ?        S    13:54   0:03 /opt/unified-monitoring-agent/embedded/bin/ruby -Eascii-8bit:ascii-8bit /opt/unified-monitoring-agent/embedded/bin/fluentd --log /var/log/unified-monitoring-agent/unified-monitoring-agent.log --daemon /var/run/unified-monitoring-agent/unified-monitoring-agent.pid --log-rotate-size 1048576 --log-rotate-age 10 --under-supervisor\nAs shown in the preceding sample, there are two processes running, with the same arguments, except for the extra \u00e2\u0080\u0093under-supervisor added to the second one. This denotes the worker process, thus making the process without this parameter the supervisor.\n\n\n\nUnified Monitoring Agent Log Location\n Note Most of the systemctl or journalctl commands must be run with super user privileges (either as root, or through sudo).\nThe Unified Monitoring Agent logs are available at /var/log/unified-monitoring-agent/unified-monitoring-agent.log. This file includes logs from the Unified Monitoring Agent itself.\nBesides the agent's logs, which do not contain system-related events (for example, service start, service stop, and so on), you can also view the logs from journald, systemd's system logging service. To view the system logs specific to a unit, you can use the journalctl command like the following:\njournalctl -u <unit_name>\nWhere <unit_name> must be replaced with one of the following values:\n\nunified-monitoring-agent.service\nunified-monitoring-agent_config_downloader.service\nunified-monitoring-agent_config_downloader.timer\nunified-monitoring-agent_restarter.path\n\nWhen querying journald logs through journalctl, you can also define specific time ranges: journalctl --since \"2020-12-30 00:00:01\" --until \"2020-12-31 23:59:59\"The date format used is YYYY-MM-DD HH:MM:SS.\nYou can also tail the journal logs, by adding the -f parameter: journalctl -f\n\n\n\nThe Unified Monitoring Agent is Not Installed\n\nFor newly created instances, it can take up to 25 minutes for the automatic installation of the agent. If it is not installed after this time period, check the following:\n\nThe network connectivity of the instance.\nWhether monitoring is enabled in the Console.\n\nYou can also check the log file /var/log/oracle-cloud-agent/plugins/unifiedmonitoring/unifiedmonitoring.log for information regarding the installation of the Unified Monitoring Agent by the Oracle Cloud Agent.\n\n\n\n\nThe Unified Monitoring Agent is Not Running\n\nIf the status is not loaded or active, nor are both supervisor and worker processes running, restart the Unified Monitoring Agent and check the logs for any problems: \nsystemctl restart unified-monitoring-agent\n\n\n\n\nConfiguration Not Automatically Downloaded\n\nEnsure you have followed the steps in Installing the Agent and Verify Agent Installation. Consult the journal of the automatic configuration updater service by running: \njournalctl -u unified-monitoring-agent_config_downloader.service\n\n\n\n\nConfiguration Not Automatically Reloaded\n\nEnsure you have followed the steps in Installing the Agent and Verify Agent Installation. Consult the journal of all the units:\n\nThe timer unit must have run at least one time.\nThe automatic configuration download service must have run after the relevant time unit has triggered it. You can verify from its logs that the configuration has been downloaded and extracted to the Unified Monitoring Agent's configuration directory. You can also verify this by listing the files in that directory: ls -lhatR /etc/unified-monitoring-agent.\nVerify that the path unit is active by checking its status: systemctl status unified-monitoring-agent_restarter.path.\nVerify that a reload signal has been received by the Unified Monitoring Agent, by inspecting its journal: journalctl -u unified-monitoring-agent_config_downloader.service. \"Reloading unified-monitoring-agent\" appears in the output of this command.\n\n\n\n\n\nTest Parsing Pattern and Force Agent to Immediately Download the Configuration\n\nRun the following command:\nsystemctl restart unified-monitoring-agent_config_downloader\n Note Automatic update of the configuration on the agent side can take up to 30 minutes.\n\n\n\n\nAgent Configuration for Linux Instance Fails\n\nFailure can occur if the configuration using the Windows endpoint appears in a Linux instance, since Fluentd on Linux does not support the Windows plugin, and will fail upon initialization. The cause of this is usually that the customer configured a Windows agent configuration, and assigned it to the same dynamic group that also has a Linux instance configuration. Such a setup is not supported. Linux and Windows instances require their own dynamic groups.\n\n\n\n\nCreate a Custom Log to View the Contents of an Alert Log of a Database System Using OCI\nThe Unified Monitoring Agent does not support the database system.\n\n\n\nData Collection\nIf you want to open a ticket so an engineer can help you with your problem regarding the Unified Monitoring Agent, include the output of the following commands. Super user privileges might be required for some of them.\nyum info unified-monitoring-agent\nrpm -ql unified-monitoring-agent |  xargs sha512sum\nsystemctl status --full unified-monitoring-agent.service\nsystemctl status --full unified-monitoring-agent_config_downloader.service\nsystemctl status --full unified-monitoring-agent_config_downloader.timer\nsystemctl status --full unified-monitoring-agent_restarter.path\njournalctl -a --no-pager -u unified-monitoring-agent.service\njournalctl -a --no-pager -u unified-monitoring-agent_config_downloader.service\njournalctl -a --no-pager -u unified-monitoring-agent_config_downloader.timer\njournalctl -a --no-pager -u unified-monitoring-agent_restarter.path\nFor Ubuntu use a command like the following:\napt show unified-monitoring-agent\ndpkg -L unified-monitoring-agent | xargs sha512sum\nAlso include an archive of the files under /var/log/unified-monitoring-agent/ and /var/log/oracle-cloud-agent/. You can create a gzipped tar archive of these directories with the command:\ntar cvzf agent_logs_$(date +%s).tar.gz /var/log/unified-monitoring-agent/ /var/log/oracle-cloud-agent/\nIf the Unified Monitoring Agent is running but has erratic behavior, you can also include backtrace and memory profile information, by running the following command and including the files /tmp/sigdump-<integer>.log in your report (where <integer> is an integer with 1\u00e2\u0080\u00936 digits, even though in rare cases it might have more than that).\nps aux | grep unified-monitoring-agen[t] | grep ruby | awk '{print $2}' | xargs kill -SIGCONT\nWhat this command does is to find the Unified Monitoring Agent process PIDs, and send them the SIGCONT signal, which causes a dump to be generated in /tmp/sigdump-<integer>.log.\n\n\n\nUninstall and Reinstall\nYou can remove the Unified Monitoring Agent, without removing the agent's configuration, by running the following command:\nyum -y remove unified-monitoring-agent\nFor Ubuntu:\napt -y remove unified-monitoring-agent\nThe agent's configuration remains under the /etc/unified-monitoring-agent/ directory. If you do not want to keep the configuration for a future (re)installation of the Unified Monitoring Agent package, you need to remove it manually:\n# use the following command to print the contents of the agent's configuration directory\nfind /etc/unified-monitoring-agent/\n# use the following command to remove the directory and all of its contents (this step cannot be undone)\nrm -rf /etc/unified-monitoring-agent/\nThe agent is automatically reinstalled by the Oracle Cloud Agent, at most 25 minutes. You need to have monitoring enabled for your instance in the Console for this to occur. See Oracle Cloud Agent for more information.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Retaining and Deleting Images Using Retention Policies service, \n Using the Console to Add a Repository to a Custom Image Retention Policy, \n Provided  you have manage permission on a repository, you can add a repository to an existing custom image retention policy.\n Note that if a custom image retention policy already applies to the repository, you'll have to remove the repository from the current policy before adding it to a different policy. Note also that  a custom image retention policy is specific to the region in which it was created.\nTo  add a repository to an existing custom image retention policy:\n\nIn the Console, open the navigation menu and click Developer Services. Under Containers, click Container Registry.\nChoose the registry's region.\n\nClick Settings, and then select Image retention policies.\nYou see the current selection criteria   of the region's global image retention policy, along with the custom image retention policies that have been defined to override the global image retention policy for specific repositories.\n\nLocate the custom image retention policy to which you want to add the repository. \n\nClick Add Repository and select from the list the repository you want to add to the custom image retention policy.\nNote that the repository list includes all repositories in the region, regardless\n                    of whether you have permission to add them to a retention policy. You can only\n                    add a repository to a retention policy if you have manage\n                    permission on that repository.\nIf a repository in the list has a policy name beside it, the repository has already been added to a policy. Before you can add the repository to a different policy, you'll have to remove it from the first policy.\n\n\nGoing forward, the custom retention policy to which you added the repository will override the region's global image retention policy. The images in the repository  will be deleted from Container Registry if they meet the criteria specified in the custom retention policy. \nWhen you create or update an image retention policy, the hourly process that checks images for deletion will ignore the new or updated policy for several hours. This cooling-off period enables you to refine the policy criteria to select only the images you want to delete, and thus reduces the chance of images being deleted unexpectedly. After this period, the policy is included in the hourly process and images are checked and deleted accordingly.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Adding Logging to API Deployments service, \n Editing a JSON File to Add Logging, \nEditing a JSON File to Set Execution Log Level for Logs Stored in Oracle Cloud Infrastructure Logging\nTo edit the API\u00c2\u00a0deployment specification in a JSON file to set the log level for execution\n        logs stored in Oracle Cloud Infrastructure Logging: \n\n\nUsing your preferred JSON editor, edit the existing API deployment specification in\n            which you want to set the log level for execution logs stored in Oracle Cloud Infrastructure Logging, or create a new API deployment specification\n            (see Creating an API Deployment Specification).\nAt a minimum, the API deployment specification will include a routes\n            section containing:\n\nA path. For example, /hello\nOne or more methods. For example, GET\nA definition of a back end. For example, a\u00c2\u00a0URL, or the OCID\u00c2\u00a0of a function in OCI Functions.\n\nFor example, the following basic API deployment specification defines a simple Hello World serverless function in OCI Functions as a single back end:\n{\n  \"routes\": [\n    {\n      \"path\": \"/hello\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n        \"type\": \"ORACLE_FUNCTIONS_BACKEND\",\n        \"functionId\": \"ocid1.fnfunc.oc1.phx.aaaaaaaaab______xmq\"\n      }\n    }\n  ]\n}\n\n\n(Optional) To set the log level for execution logs that applies globally to all routes\n            in the API deployment specification: \n\n\nInsert a loggingPolicies section before the\n                  routes section. For example:\n\n{\n  \"loggingPolicies\": {},\n  \"routes\": [\n    {\n      \"path\": \"/hello\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n         \"type\": \"ORACLE_FUNCTIONS_BACKEND\",\n         \"functionId\": \"ocid1.fnfunc.oc1.phx.aaaaaaaaab______xmq\"\n      }\n    }\n  ]\n}\n\n\nSpecify the level of detail to record about processing within the API gateway for\n                all routes by including the executionLog policy in the\n                  loggingPolicies section, and setting the\n                  logLevel property to one of the following:\n\nINFO to record a summary of every processing stage.\nWARN to record only transient errors that occur during\n                  processing. For example, a connection reset.\nERROR to record only persistent errors that occur during\n                  processing. For example, an internal error, or a call to a function that returns a\n                  404 message. \n\nFor example:\n\n{\n  \"loggingPolicies\": {\n    \"executionLog\": {\n      \"logLevel\": \"INFO\"\n    }\n  },\n  \"routes\": [\n    {\n      \"path\": \"/hello\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n         \"type\": \"ORACLE_FUNCTIONS_BACKEND\",\n         \"functionId\": \"ocid1.fnfunc.oc1.phx.aaaaaaaaab______xmq\"\n      }\n    }\n  ]\n}\n\n\n\n\n(Optional) To set the log level for execution logs for a particular route (overriding\n            the global execution log level inherited from the API deployment):\n\n\nInsert a loggingPolicies section\u00c2\u00a0after the route's\n                  backend section. For example:\n\n{\n  \"loggingPolicies\": {\n    \"executionLog\": {\n      \"logLevel\": \"INFO\"\n    }\n  },\n  \"routes\": [\n    {\n      \"path\": \"/hello\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n         \"type\": \"ORACLE_FUNCTIONS_BACKEND\",\n         \"functionId\": \"ocid1.fnfunc.oc1.phx.aaaaaaaaab______xmq\"\n      },\n      \"loggingPolicies\": {}\n    }\n  ]\n}\n\n\nSpecify the level of detail to record about processing within the API gateway for\n                the route by including the executionLog policy in the\n                  loggingPolicies section, and setting the\n                  logLevel property to one of the following:\n\nINFO to record a summary of every processing stage.\nWARN to record only transient errors that occur during\n                  processing. For example, a connection reset.\nERROR to record only persistent errors that occur during\n                  processing. For example, an internal error, or a call to a function that returns a\n                  404 message. \n\nFor example:\n\n{\n  \"loggingPolicies\": {\n    \"executionLog\": {\n      \"logLevel\": \"INFO\"\n    }\n  },\n  \"routes\": [\n    {\n      \"path\": \"/hello\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n         \"type\": \"ORACLE_FUNCTIONS_BACKEND\",\n         \"functionId\": \"ocid1.fnfunc.oc1.phx.aaaaaaaaab______xmq\"\n      },\n      \"loggingPolicies\": {\n        \"executionLog\": {\n          \"logLevel\": \"ERROR\"\n        }\n      }\n    }\n  ]\n}\n\n\n\n\nSave the JSON\u00c2\u00a0file containing the API deployment specification.\n\n\nUse the API deployment specification when you create or update an API deployment in the\n            following ways:\n\nby specifying the JSON file in the Console when you\n              select the Upload an existing API option\nby specifying the JSON file in a request to the API Gateway REST\u00c2\u00a0API\n\nFor more information, see Deploying an API on an API Gateway by Creating an API Deployment.\n\nHaving set the log level for execution logs, follow the instructions in Enabling Logging for a Resource to create and enable a new API\n          deployment log in the Oracle Cloud Infrastructure Logging service.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Streaming with Apache Kafka service, \n Kafka API Support, \nStreaming is fully upstream compatible with the latest\n            versions of Kafka APIs. Streaming supports the following\n            Kafka APIs:\n\n\nProducer (v0.10.0 and later)\nConsumer (v0.10.0 and later)\nConnect (v0.10.0.0 and later)\nAdmin (v0.10.1.0 and later)\n\nGroup Management (v0.10.0 and later)\n\nThe following Kafka APIs and features are not yet implemented in the Streaming service:\n\nKafka Streams\nCompaction\nTransactions\n\nDynamic Partition Addition\n\nIdempotent production\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cost and Usage Reports Overview service, \n Using the API, \n\nFor information about using\n                the API and signing requests, see REST APIs\n                and Security Credentials. For information about\n                SDKs, see Software Development Kits and Command Line Interface.\n\nTo download a cost or usage report, use the Object Storage APIs. The reports are stored in the tenancy's home region. The Object Storage namespace used for the reports is\n                bling; the bucket name is the tenancy OCID.\nThe following example shows how to download a cost report, usage report (or both) using a Python script:\n Note This example has a specific tenancy OCID, because the reports are stored in an Oracle-owned Object Storage bucket hosted by Oracle Cloud Infrastructure, and not a customer's tenancy.\nimport oci\nimport os\n                               \n# This script downloads all of the cost, usage, (or both) reports for a tenancy (specified in the config file).\n#\n# Pre-requisites: Create an IAM policy to endorse users in your tenancy to read cost reports from the OCI tenancy.\n#\n# Example policy:\n# define tenancy reporting as ocid1.tenancy.oc1..aaaaaaaaned4fkpkisbwjlr56u7cj63lf3wffbilvqknstgtvzub7vhqkggq\n# endorse group <group_name> to read objects in tenancy reporting\n#\n# Note - The only value you need to change is the <group_name> with your own value. Do not change the OCID in the first statement.\n                               \nreporting_namespace = 'bling'\n                               \n# Download all usage and cost files. You can comment out based on the specific need:\nprefix_file = \"\"                     #  For cost and usage files\n# prefix_file = \"reports/cost-csv\"   #  For cost\n# prefix_file = \"reports/usage-csv\"  #  For usage\n                               \n# Update these values\ndestintation_path = 'downloaded_reports'\n                               \n# Make a directory to receive reports\nif not os.path.exists(destintation_path):\n    os.mkdir(destintation_path)\n                               \n# Get the list of reports\nconfig = oci.config.from_file(oci.config.DEFAULT_LOCATION, oci.config.DEFAULT_PROFILE)\nreporting_bucket = config['tenancy']\nobject_storage = oci.object_storage.ObjectStorageClient(config)\nreport_bucket_objects = oci.pagination.list_call_get_all_results(object_storage.list_objects, reporting_namespace, reporting_bucket, prefix=prefix_file)                          \nfor o in report_bucket_objects.data.objects:\n    print('Found file ' + o.name)\n    object_details = object_storage.get_object(reporting_namespace, reporting_bucket, o.name)\n    filename = o.name.rsplit('/', 1)[-1]\n                               \n    with open(destintation_path + '/' + filename, 'wb') as f:\n        for chunk in object_details.data.raw.stream(1024 * 1024, decode_content=False):\n            f.write(chunk)\n                               \n    print('----> File ' + o.name + ' Downloaded')\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Resource Discovery service, \n Discover already deployed Oracle Cloud Infrastructure resources using Resource Manager.\nYou can use Oracle Cloud Infrastructure\n                    (OCI) Resource Manager to search for deployed resources in\n                your compartment and export them to Terraform configuration and state files.\n\nResource discovery simplifies the move from manually managed infrastructure to\n                    Terraform-managed infrastructure. With a single command, you can generate a file\n                    that captures your existing compartment's baseline configuration and state.\n Important Resource discovery is not a migration tool. When cloning or\n                    migrating resources, configurations generated by resource discovery are a\n                    starting point. They may require changes.\n\n\nCommon uses cases for your new Terraform configuration and state files\n                    include:\n\nLearn how Terraform uses HashiCorp Configuration Language (HCL) syntax to\n                        represent Oracle Cloud Infrastructure resources. \nDuplication or rebuild of your existing infrastructure architecture in a new\n                        tenancy or region.\nDetection of state drift. Run reports to see if the state of your\n                        Terraform-managed resources has changed and differs from your base\n                        configuration.\n\n\nTo discover resources, follow the steps at To see how Terraform represents your resources. The created stack includes a generated Terraform configuration and state file corresponding to the supported resources in the source compartment.\n\nA stack created from a compartment represents all supported resources in the entire compartment, at the appropriate scope. If you select the root compartment for your tenancy, then the scope is the tenancy level, such as users and groups. If you select a non-root compartment, then the scope is compartment level, such as compute instances.\nStack creation is supported from a single compartment only. Stacks cannot be created\n                from nested compartments.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Matching Events with Filters service, \n Examples of Simple Filters, \nThe following filter  matches every event in the compartment and any child compartments where you create the rule.\u00c2\u00a0\n{\n... \n\n\t\"condition\": \"{ }\"\n\n}\nWhen you add fields to the filter, you limit the events that the filter can match. For example, the following filter matches only deletebucket events.\u00c2\u00a0\n{\n...\n\n\t\"condition\": \"{\n\t\t\"eventType\": \"com.oraclecloud.objectstorage.deletebucket\"\n\t}\"\n}\nTo create a filter for more than one event type, use an array in eventType. The following filter matches  deletebucket and createbucket events.\u00c2\u00a0\n{\n...\n\n\t\"condition\": \"{\n\t\t\"eventType\": [\n\t\t\t\"com.oraclecloud.objectstorage.deletebucket\",\n\t\t\t\"com.oraclecloud.objectstorage.createbucket\"\n\t\t]\n\t}\"\n}\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Network Firewall service, \n Use troubleshooting information to identify and address common issues that can occur while working with Network Firewall.\n\nFirewall Creation Fails\nTraffic is Not Reaching the Firewall\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Invoke Anomaly Detection with OCI Streaming service, \n Detect Anomalies in Streaming Data with Anomaly Detection, \n\nBefore you begin, you must have:\n\n\nA trained model ready to use for this process. Change the\n                        following properties in the sample code to create your FaaS\n                        application.\n\n\nendpoint\n\n\nmodel_id\n\n\nstream_id\n\n\nmessage_endpoint\n\n\npartition_id\n\n\n\n\nEnsure that you have set up the Anomaly Detection\n                            service policies.\n\n\nSet these polices so that the Functions\n                        service can call the Anomaly Detection service:\n\n\nCreate a dynamic group for the function:\nAll {resource.compartment.id = <compartment_id>, resource.type = 'fnfunc' }\n\n\n\nAdd these permissions for the dynamic\n                                group:DEFINE dynamic-group AD_SERVICE_CALLING_FUNC as <function_dynamic_group>\nALLOW dynamic-group AD_SERVICE_CALLING_FUNC to use ai-service-anomaly-detection-model in compartment <compartment_name>\n\n\n\n\n\nUse this solution to detect anomalies in streaming\n            data:\n\nCreate both an input and an output\n                        stream in the Streaming service using\n                    one of the various methods.\n\nCreate an application in the Functions service to use to create the\n                    FaaS.\n\nAfter the application is active, you can add a function to it.\n\n\nClick the application name from the list.\n\nClick Getting Started to begin creating your FaaS.\n\nClick Local Setup.\n\nFollow the instructions to set up your FaaS and use this to invoke it by\n                    replacing the environment values with your own.\n\nEnsure that the FaaS is active before continuing.\n\n(Optional) \n                You have to enable logging if you want to use logs to help you debug your FaaS,\n                    click Logs, click the Actions icon, and then click Enable Log and\n                    specify:\n\n\n\n\nCompartment: The compartment in which to create the log.\n                                    By default, the current compartment.\nLog Group: The log group in which to create the log.\n                                    Select an existing log group, or select:\nAuto-create a default log group to create a\n                                            default log group with a default name, if one doesn't\n                                            exist already.\nCreate a new log group to create a log group with\n                                            a name and description that you provide.\n\nLog Name: The name of the new log. By default,\n                                            <application-name>_invoke.\nLog Retention: The length of time to retain log\n                                    data.\n\n\nClick Enable Log to create the log (and the new log group, if you\n                            specified one).\n\n\n\nCreate a service connector in the Service Connector Hub service using the\n                        Use Manual Settings option to configure the\n                    task.\n\n Note\nIf you don't have the required policies configured to create service\n                            connectors, this creation step helps you to configure them.\n\n\n\nSpecify your input and output streams with the task being the FaaS that you\n                    created.\n\nClick Create to complete the setup.\n\n\nNow, any messages that are sent to the input stream are passed on to the Anomaly Detection service. The results from the\n                    Anomaly Detection service are sent to the output\n                stream.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n What's Included With Cloud Shell, \nIn addition to the OCI CLI, the Cloud Shell VM\u00c2\u00a0comes with current versions of many useful\n            tools and utilities pre-installed, including:\n\nGit\nJava\nPython (2 and 3)\nGraalVM Enterprise JDK 17 and Native Image\nSQL Plus\nkubectl\nhelm\nmaven\ngradle\nterraform\nansible\nnode.js\niputils\njqmake\ntmux\nvim\nNPM\nwget\nzip/unzip\nnano\nemacs\npip\nbash\nsh\ntar\nnvm\nmysql-community-client\nDocker engine\nipython\noci-powershell-modules\nGoldenGate Admin client\nMost OCI SDKs, including:\nJava\nPython\nGo\nTypeScript and JavaScript\nRuby\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Service Connectors service, \n Use troubleshooting information to identify and address common issues that can occur while working with Service Connector Hub."
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Leads service, \n Viewing Leads, You'll get a lead whenever someone expresses interest in your app or service that you have published to Oracle Cloud Marketplace. When a lead is generated in Oracle Cloud Marketplace, you won't receive an email. You have to view the list of leads generated in Oracle Cloud Marketplace Partner Portal.To view the leads generated by Oracle Cloud Marketplace, do the following:\nSign in to Partner Portal.\nClick .Review the information on the page. By default, the leads display as cards. Click List to view the leads as a list. Each lead includes:Scroll the page, search, or use the filter and sort options to reorder the list or find a set of leads. For example, you might want to show only leads that are new.You can view the following information for each lead:\n\nThe current status of the lead.\n\n\nThe lead name, company, and contact information.\n\n\nThe name of your app or service the customer is interested in.\n\nYou can export all your leads or a subset of your leads to a comma-separated values (CSV) file for use in presentations and reports. See Exporting Leads Data"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Notebook Sessions to Build and Train Models service, \n Using a Git Repository in Notebook Sessions, Clone your Git repositories and use Git commands in your notebook session.\nYou can have Data Science clone your Git repository into your notebook session. When you create a notebook session, add your Git repository URL to the Runtime Configuration section. \n\nGit Constraints\n\n\n\nThe notebook must have internet access for Git repository to clone. \n\n\nOnly public Git repositories are supported.\n\n\nMaximum of three Git repositories URLs are allowed.\n\n\nMaximum length of a URL is 256 characters.\n\n\n\n\n\nGit-Related Directories in the Notebook Sessions\n\n\nFind the clones of your Git repositories in your notebook session's /home/datascience/repos directory.\nFor clone status such as success, failure, or in-progress, go to\n                  /opt/log/odsc.log.\nFor verbose logs, go to\n                /var/log/jupyterlab/runtime_config.log.\n\nAccess the logs from a terminal in your notebook session.\n\n\nFor existing notebook session, deactivate the notebook sessions. Then when you activate the notebook, add the Git repository URL in the Runtime Configuration section.\nWhen you activate a notebook session, any previously saved data or files on the block volume of that deactivated notebook session are available in the activated notebook session. If you activate a notebook session with new Git repository URLs, any listed URL in the Runtime Configuration section, including previous URLs from the deactivated notebook sessions are also cloned to the notebook's /home/datascience/repos directory.\nTo remove a cloned repository from a notebook session, you can delete it from the notebook session's /home/datascience/repos directory.\nIf you want to replace an old clone from a deactivated notebook with a new one, delete the unwanted Git repository URL listed in the Runtime Configuration section, add the new URL, and then activate the notebook session. \nUsing Git Repositories in Notebook Sessions\nYou can use the file browser in JupyterLab to view the Git repository and a terminal window to execute Git commands as you would with any Git repository.\nAlternatively, you can use the Git interface by clicking Git in the navigation panel to make authenticating users, creating branches, committing and pushing changes, and cloning easier. \nYou have to first initialize a new repository by clicking Initialize. The repository is displayed showing you the current branch, changes (staged, changed, and untracked), and history. When you make changes to the repository, you can add your comments and commit your changes using the dialogs. Next, you'll want to push your changes by clicking the push button at the top of the panel and supplying your Git credentials. \nYou can use the pull and refresh buttons to make sure that the repository is up to date. If errors occur, they appear in the lower right corner and you can click the error to get more information.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Changing the Shape of an Instance service, \n Limitations and Considerations, \nBe aware of the following information:\n\nThe image that was used to create the instance must be compatible with the new shape. To see which shapes are compatible, do either of the following things:\nIn the Console, on the Instance Details page, click the name of the image. Then, refer to the list of compatible shapes.\nUsing the API, call the ListShapes operation and pass the image OCID as a parameter.\n\nSome Marketplace images\u00c2\u00a0cannot be resized because of\n                licensing constraints. If you want to resize a Microsoft SQL Server image, contact support.\nYou must have sufficient service limits for the new shape. If you don't have service limits, the\n                instance will remain with the original shape.\nDifferent shapes are billed at different rates. When you change the shape of an instance, you are billed to the nearest second of usage for each shape that you use. For more information, see Compute Pricing and Resource Billing for Stopped Instances.\nIf the instance has secondary VNICs configured, you might need to reconfigure them after the instance is rebooted. For more information, see Virtual Network Interface Cards (VNICs).\nIf the instance is running when you change the shape, it is rebooted as part of the change shape operation. If the applications that run on the instance take a long time to shut down, they could be improperly stopped, resulting in data corruption. To avoid this, shut down the instance using the commands available in the OS before you change the shape.\nWhen you change the shape from one hardware series to a different series, some hardware details such as the network interface name might change. This might cause problems for some guest OSs, particularly if the OS has been customized. If the OS fails to boot after you change the shape, then you should change the instance back to the original shape.\nIf you created a regular instance using SR-IOV networking (the default for some regular instances), and want to change the instance to a burstable instance, you must also change the networking type to paravirtualized.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Service Mesh with Kubernetes service, \n With the Oracle Cloud Infrastructure Service Mesh\n        service, you can manage Service Mesh components using the\n        OCI Console, OCI CLI, or Kubernetes tools. This section focuses on managing your Service Mesh with Kubernetes tools.\nManaging Service Mesh Resources with\n                kubectl\nThe kubectl command line tool is the primary way to communicate with\n                a Kubernetes cluster's control plane using the Kubernetes API. For more information\n                on kubectl, see Command line tool (kubectl). Service Mesh with kubectl\n                allows:\n\nManaging Meshes with kubectl\nManaging Virtual Services with kubectl\nManaging Virtual Service Route Tables with kubectl\nManaging Virtual Deployments with kubectl\nManaging Virtual Deployment Bindings with kubectl\nManaging Ingress Gateways with kubectl\nManaging Ingress Gateway Route Tables with kubectl\nManaging Ingress Gateway Deployment Bindings with kubectl\nManaging Access Policies with kubectl\n\n Important When using kubectl with Service Mesh, read Managing Service Mesh with OCI APIs vs kubectl to understand how kubectl\n                interacts with the OCI CLI and OCI console.\n Note With kubectl commands, use both plural and singular versions of\n                resource names interchangeably. For example, to get a list of virtual services\n                either of the following commands works. \n\nkubectl get virtualservices -n <NAMESPACE>\n\n\nkubectl get virtualservice -n <NAMESPACE>\n\n\n\n\nManaging Service Mesh with Helm\nService Mesh supports Helm Kubernetes management\n                tool. Using Helm Charts, you define, install, and upgrade Kubernetes applications.\n                For information on installing Helm, see Installing Helm.\nFor detailed information on Service Mesh Helm\n                support, see Service Mesh Helm Support on GitHub.\nUsing Helm with Service Mesh\nThe following high-level steps describe how to use Helm with Service Mesh and Kubernetes.\n\nCreate a Helm chart. helm create <CHART_NAME>\nThe command creates a sample chart with the folder structure shown here:\n                            Helm Create.\nChange into the generated folder.\nModify the templates folder to include the Service Mesh resources in the YAML files.\nGenerate the template files for preview.\n                    helm template .\n\nInstall the Helm chart on the Kubernetes cluster.\n                    helm install <CHART_NAME> -n <NAMESPACE> \nHelm deploys the Service Mesh resources to your\n                    Kubernetes cluster. \n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Publishing Custom Metrics service, \n Publish custom metrics to the Monitoring service.\nTo walk through common use cases with custom metrics, see Custom Metrics Walkthrough. For query troubleshooting, see Troubleshooting Queries.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Working with Instances service, \n \n\nThis section describes how to use the Instances tab to add new instances, edit\n                existing instances, and select an instance to associate your CEMLIs with.The\n                    following topics are covered in this chapter:\n\nSelecting an\n                            Instance\n\n\nViewing Instance Details\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Harvest On-Premises Data Sources service, \n 2. Obtain Data Source Details, You need the private network and database connection information for the on-premises\n        Oracle Database you want to harvest.\n\nObtain the following details for the on-premises Oracle Database from your\n                administrator:\n\nFor configuring the private network, you need the VCN and subnet name and the\n                    URL for the Oracle Database.\nFor creating the data asset, you need the Oracle Database host, port, and\n                    database service name or SID.\nFor adding a connection, you need the database login credentials.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Publishing a Conda Environment to an Object Storage Bucket in Your Tenancy service, \n \nBefore you can publish a conda environment or install a published conda environment, you\n            need to configure odsc conda to use an Object Storage bucket using this\n            command:\nodsc conda init -b <your-bucket-name> -n <your-tenancy-namespace> -a <api_key or resource_principal>\nChange these values in the command:\n\n<your-bucket-name>: is the name of the\n                        object storage bucket in your tenancy containing Published Conda\n                        Environments.\n\n\n<your-tenancy-namespace>: is the namespace\n                        of your tenancy. \n\n\n<api_key or resource_principal>: provide\n                        either an API key or a resource principal. If you are using the API key\n                        option, you must have a valid API keys configuration. The default directory\n                        for the key is /home/datascience/.oci. If you want to use\n                        an alternate directory for API key, run the odsc conda init\n                            -a command and specify either an api_key or\n                             resource_principal name. \nYou can run odsc conda init -h for more information about\n                        the options.\n\n\nYou only need to run the odsc conda init command once per notebook\n            session. Your bucket and namespace values persist through deactivation and activation of\n            the notebook session.You can publish a conda environment that you have installed in a notebook session. Publishing a\n            conda environment consists of creating a pack of a conda environment and uploading it to a specified Object Storage.\n            This allows conda environments to be shared among colleagues or to persist them across\n            notebook sessions. We recommend that you publish conda environments to ensure that a\n            model training environment can be reproduced.\nYou can publish a conda by clicking Publish in an installed\n            environment card. Copy the code snippet, and then run it in a terminal window tab: \nodsc conda publish -s <slug>\nThe <slug> is the slug of the environment you want\n            to publish.\n Important\nADS warns you when you create the model artifact to publish your conda environment before saving the model to the model catalog. If you have already published the conda environment, you can provide ADS with the path on Object Storage to that conda environment when you save the model. References to training environments are stored in the runtime.yaml file that is part of the model artifact, see managing models.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Container Instances service, \n Resource Billing for Stopped Instances, \nFor container instances, billing depends on the shape that you use to create the container instance. Container instances use standard shapes which pause billing when a container instance stops. However, stopped and failed instances continue to count toward your service limits.\nContainer instance states and billing\n\n\nContainer Instance States\n\n\nDescription\n\n\nBilling\n\n\n\n\nCreating\n\nThe container instance is being created.\n\n\nNo\n\n\n\nActive\nThe container instance is active, the container images are being pulled, or the containers are running.\nYes\n\n\n\nUpdating\n\n\nYou change the configuration of the container instance. For example:\n\nName\nContainer Image\nAuto-restart policy\nTags\n\nAttributes such as the container image or the auto-restart policy become effective after a container instance restart.\nContainer instances are in \"Updating\" state after a restart, start, stop.\n\n\nYes\n\n\n\nFailed\nThe container instance is no longer functional and cannot be recovered. The \"Failed\" state is permanent.\nNo\n\n\nInactive\n\nYou stopped the container instance and it will not start again without user input.\nor\nAll containers in the container instance stopped and the auto-restart policy is disabled.\nThe container instance infrastructure is removed. Billing is stopped.\n\nNo\n\n\nDeleting\nContainer instance goes into a \"Deleting\" state when you request the container instance deletion by using the DeleteContainerInstance API call.The container instance infrastructure is being removed.\nNo\n\n\nDeleted\nThe container instance is deleted. DeleteContainerInstance is complete.\nNo\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Support Ticket Management service, \n Viewing Support Tickets, \nOpen the \nHelp menu ()\n      and click Visit Support Center.\nClick Technical Support Requests in the Support\n      section to display a list of technical support requests. To display billing support requests,\n      click Billing Support Requests.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Deleting an Environment service, \n Learn how to delete an environment.\nFor accessing DevOps using the Oracle Cloud\n                        Console, REST API, and CLI, see Accessing DevOps.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Certificates service, \n Using the Console, \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n View Related Documentation, Use the Help menu to access documentation and support.\nThe listed documentation relates to the current Console page.\nOpen the \nHelp menu () and click the documentation link you want.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Services that Produce Events service, \n Functions, \nFunctions resources that emit events:\n\n\nApplication Event Types\n\nFunction Event Types\n\nApplication Event Types \nThese are the event types that applications emit:\n\n\nFriendly Name\nEvent Type\n\n\n\nChange Application Compartment\ncom.oraclecloud.functions.changeapplicationcompartment\n\n\n\nCreate Application\ncom.oraclecloud.functions.createapplication\n\n\n\nDelete Application\ncom.oraclecloud.functions.deleteapplication\n\n\n\nUpdate Application\ncom.oraclecloud.functions.updateapplication\n\n\n\nApplication Example\n\nThis is an example event for applications:\n{\n  \"eventType\": \"com.oraclecloud.functions.createapplication\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"functions\",\n  \"eventTime\": \"2019-07-22T09:33:44.754Z\",\n  \"contentType\": \"application/json\",\n  \"data\":{\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"my_compartment\",\n    \"resourceName\": \"my-application\",\n    \"resourceId\": \"ocid1.fnapp.oc1.phx.<unique_ID>\",\n    \"availabilityDomain\": \"AD3\"\n  },\n  \"eventID\": \"<unique_ID>\",\n  \"extensions\":{\n    \"compartmentId\":\"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nFunction Event Types\nThese are the event types that functions emit:\n\n\nFriendly Name\nEvent Type\n\n\n\nCreate Function\ncom.oraclecloud.functions.createfunction\n\n\n\nDelete Function\ncom.oraclecloud.functions.deletefunction\n\n\n\nUpdate Function\ncom.oraclecloud.functions.updatefunction\n\n\n\nFunction Example\n\nThis is an example event for functions:\n{\n  \"eventType\": \"com.oraclecloud.functions.createfunction\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"functions\",\n  \"eventTime\": \"2019-07-22T09:33:44.754Z\",\n  \"contentType\": \"application/json\",\n  \"data\":{\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"my_compartment\",\n    \"resourceName\": \"my-function\",\n    \"resourceId\": \"ocid1.fnfunc.oc1.phx.<unique_ID>\",\n    \"availabilityDomain\": \"AD3\"\n  },\n  \"eventID\": \"<unique_ID>\",\n  \"extensions\":{\n    \"compartmentId\":\"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Services that Produce Events service, \n Notifications, \nNotifications resources that emit events:\n\nSubscriptions Event Types\n\nTopics Event Types\n\n\nSubscriptions Event Types\nThese are the event types that subscriptions emit:\u00c2\u00a0\n\n\nFriendly Name\nEvent Type\n\n\n\nCreate Subscription\ncom.oraclecloud.notification.createsubscription\n\n\n\nDelete Subscription\ncom.oraclecloud.notification.deletesubscription\n\n\n\nGet Unsubscription\ncom.oraclecloud.notification.getunsubscription\n\n\n\nMove Subscription\ncom.oraclecloud.notification.movesubscription\n\n\n\nResend Subscription Confirmation\ncom.oraclecloud.notification.resendsubscriptionconfirmation\n\n\n\nUpdate Subscription\ncom.oraclecloud.notification.updatesubscription\n\n\n\nSubscription Example\n\nThis is a reference event for subscriptions:\n{\n  \"eventType\": \"com.oraclecloud.notification.createsubscription\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"notification\",\n  \"eventTime\": \"2019-01-10T21:19:24Z\",\n  \"contentType\": \"application/json\",\n  \"data\":{\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"my_compartment\",\n    \"resourceName\": \"ons-subscription\",\n    \"resourceId\": \"ocid1.onssubscription.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"AD3\"\n  },\n  \"eventID\": \"<unique_ID>\",\n  \"extensions\":{\n    \"compartmentId\":\"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nTopics Event Types\nThese are the event types that topics emit:\u00c2\u00a0\n\n\nFriendly Name\nEvent Type\n\n\n\nCreate Topic\ncom.oraclecloud.notification.createtopic\n\n\n\nDelete Topic\ncom.oraclecloud.notification.deletetopic\n\n\n\nMove Topic\ncom.oraclecloud.notification.movetopic\n\n\n\nUpdate Topic\ncom.oraclecloud.notification.updatetopic\n\n\n\nTopic Example\n\nThis is a reference event for topics:\n{\n  \"eventType\": \"com.oraclecloud.notification.createtopic\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"notification\",\n  \"eventTime\": \"2019-01-10T21:19:24Z\",\n  \"contentType\": \"application/json\",\n  \"data\":{\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"my_compartment\",\n    \"resourceName\": \"my_topic\",\n    \"resourceId\": \"ocid1.onstopic.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"AD3\"\n  },\n  \"eventID\": \"<unique_ID>\",\n  \"extensions\":{\n    \"compartmentId\":\"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Configuring a Private Network service, \n Prerequisites, \nOne of the ways Oracle Cloud Infrastructure lets you configure private access for your resources is using\n            private endpoints. \nData Catalog uses private endpoints to access the private network where your data sources\n            are hosted. You must have the required data catalog permissions to\n            use the Data Catalog private endpoints.\nAdditionally, to create, update, or delete private endpoints in Oracle Cloud\n            Infrastructure, you need to obtain certain permissions in Oracle Cloud Infrastructure\n            Identity and Access Management (IAM) for the relevant compartments in your tenancy. The\n            following table lists the required permissions for virtual networking resources in\n            Oracle Cloud Infrastructure for the private endpoint operations.\n\n\nOperation\nRequired Access on Underlying Resources\n\n\n\nCreate a private endpoint\n\nFor the private endpoint compartment:\n\nCreate VNIC (VNIC_CREATE)\nDelete VNIC (VNIC_DELETE)\nUpdate members in a network security group\n                                        (NETWORK_SECURITY_GROUP_UPDATE_MEMBERS)\nAssociate a network security group\n                                        (VNIC_ASSOCIATE_NETWORK_SECURITY_GROUP)\n\nFor the subnet compartment:\n\nAttach subnet (SUBNET_ATTACH)\nDetach subnet (SUBNET_DETACH)\n\n\n\n\nUpdate a private endpoint\n\nFor the private endpoint compartment:\n\nUpdate VNIC (VNIC_UPDATE)\nUpdate members in a network security group\n                                        (NETWORK_SECURITY_GROUP_UPDATE_MEMBERS)\nAssociate a network security group\n                                        (VNIC_ASSOCIATE_NETWORK_SECURITY_GROUP)\n\n\n\n\nDelete a private endpoint\n\nFor the private endpoint compartment:\n\nDelete VNIC (VNIC_DELETE)\nUpdate members in a network security group\n                                        (NETWORK_SECURITY_GROUP_UPDATE_MEMBERS)\n\nFor the subnet compartment:\n\nDetach subnet (SUBNET_DETACH)\n\n\n\n\n Note\nIf you are managing the data catalog private endpoints resource, we recommend that\n                you also have the manage work requests permission. This ensures\n                that you are able to view the logs and error messages that are encountered while\n                working with private endpoints.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Summary Information on the Overview Page service, \n Processing Responder Status Problems, Review recent remediations that have been performed through Cloud Guard responders.From the Cloud Guard options panel on the left, select Overview.In the Responder Status tile, view: Total Pending - the total number of responder actions that are on hold, pending\n                            administrative approval. Recently Performed Remediations - summary information about remediations that have been\n                            performed through Cloud Guard responders in the past 30\n                                days.\nTo process responder actions on the Responder Activity page, when the\n                        Total Pending number is greater than zero, click the Total\n                        Pending link.\n\nThe Responder Activity page opens, showing the list of pending\n                        recommendations.\n\nWhat's Next\nContinue with Using the Responder Activity Page.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting ADM service, \n Use troubleshooting information to identify and address common issues that can occur while working with ADM.\n\n Tip If the problem still persists or if the problem you're facing isn't listed, refer to the Getting Help section.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using the Console service, \n Visualizing Search Results, You can visualize your Logging Search page results, for both\n      Basic and Advanced Mode searches.\n\nTo visualize log data as a chart in Basic SearchYou can view log data graphically as a chart in Basic Mode search, along with\n            accompanying tabular data. Select from the following chart\n            settings:\nVisualization Type: Select from Stacked\n                Bar, Pie, Donut, or\n                Line. The Stacked Bar and\n                Line charts are organized by default in terms of time (UTC)\n              on the X-axis (datetime), and the chosen Group\n                By logging field. You can hover the mouse over the chart data, which\n              both highlights the area of interest, and displays the data in a tool tip. The\n                Legend in all four chart types also provides an orientation\n              to the displayed chart data.\nX Axis (stacked bar and line charts only): Select a logging\n              field of interest to replace the default Time in UTC X-axis.\n            \nInterval (only for stacked bar and line charts, and when\n                datetime is the X Axis): Select from\n                1 minute, 5 minutes, 15 minutes,\n                30 minutes, or 1 hour.\nGroup By: Select a logging field to group the results by.\nFor any chart type being viewed, you can click to expand the\n                <number of> records found list below\n            the chart, which lists the total record sum, and the number of records at each time\n            interval.\nTo visualize log data as a chart in Advanced SearchSearches can also be visualized during Advanced Mode search. When an\n            advanced query is formulated according to a specific syntax format, the\n              Visualize tab is also available in Advanced\n              Mode, allowing you to view stacked bar, pie, donut, and line charts. To view charts in Advanced Mode, create your queries using the\n            following syntax:\nStacked Bar:\n                summarize count() by <user_selected_field1>,<user_selected_field2(optional)>This\n                query returns a table with three columns:\n                    <user_selected_field1>,<user_selected_field2>,\n                and count. The chart uses\n                    <user_selected_field1> as the x-axis,\n                  count for the y-axis, and\n                    <user_selected_field2> for the stacked\n                bar group by dimension.\nPie:\n                select <log_source> | summarize count() by <user_selected_field>This\n                query returns a table with two columns: <user_selected_field>\n                and count. The chart uses\n                  <user_selected_field> as the legend, and\n                  count for the distribution of the pie chart.\nDonut:\n                summarize count() by <user_selected_field>This\n                query returns a table with two columns:\n                    <user_selected_field> and\n                  count. The chart uses\n                    <user_selected_field> as the legend, and\n                  count for the distribution of the donut chart.\nLine:\n                summarize count() by <user_selected_field1>,<user_selected_field2(optional)>The\n                query returns a table with three columns:\n                    <user_selected_field1>,<user_selected_field2>,\n                and count. The chart uses\n                    <user_selected_field1> as the x-axis,\n                  count for the y-axis, and\n                    <user_selected_field2> for multiple lines\n                group by dimension.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Marketplace, \nFor known issues with Marketplace, see Known issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Contents of an Audit Log Event service, \n Payload, \nThe data in these fields depends on which service produced the event log and the event type it defines. \nData\nThe data object contains the following attributes. \n\n\nProperty\nDescription\n\n\n\ndata.additionalDetails\n\nA container object for attributes unique to the resource emitting the event. \n\n\ndata.availabilityDomain\n\nThe availability domain where the resource resides. \n\n\ndata.compartmentId\n\nThe OCID of the compartment of the resource emitting the event.\n\n\ndata.compartmentName\n\nThe name of the compartment of the resource emitting the event.\n\n\ndata.definedTags\n\nDefined tags added to the resource emitting the event.\n\n\ndata.eventGroupingId\n\n\nThis value links multiple audit events that are part of the same API\u00c2\u00a0operation. For example, a long running API\u00c2\u00a0operation that emits an event at the start and the end of the operation.\n\n\n\ndata.eventName\n\n\nName of the API\u00c2\u00a0operation that generated this event.\nExample:\u00c2\u00a0LaunchInstance\n\n\n\ndata.freeformTags\n\nFree-form tags added to the resource emitting the event.\n\n\ndata.identity\n\nA container object for identity attributes. See Identity. \n\n\ndata.request\n\nA container object for request attributes. See Request. \n\n\ndata.resourceId\n\nAn OCID or an ID for the resource emitting the event.\n\n\ndata.resourceName\n\nThe name of the resource emitting the event.\n\n\ndata.response\n\nA container object for response attributes. See Response.\n\n\ndata.stateChange\n\nA container object for state change attributes. See State Change. \n\n\n\nIdentity\nThe identity object contains the following attributes. \n\n\nProperty\nDescription\n\n\n\ndata.identity.authType\n\nThe type of authentication used. \n\n\ndata.identity.callerId\n\nThe OCID of the caller. The caller that made a request on behalf\n                                of the principal.\n\n\ndata.identity.callerName\n\nThe name of the user or service issuing the request. This value\n                                is the friendly name associated with\n                                callerId.\n\n\ndata.identity.consoleSessionId\n\nThis value identifies any Console\n                                session associated with this request.\n\n\ndata.identity.credentials\n\nThe credential ID of the user.\n\n\ndata.identity.ipAddress\n\nThe IP address of the source of the request.\n\n\ndata.identity.principalId\n\nThe OCID of the principal.\n\n\ndata.identity.principalName\n\nThe name of the user or service. This value is the friendly name\n                                associated with principalId.\n\n\ndata.identity.tenantId\n\nThe OCID of the tenant.\n\n\ndata.identity.userAgent\n\nThe user agent of the client that made the request.\n\n\n\nRequest\nThe request object contains the following attributes. \n\n\nProperty\nDescription\n\n\n\ndata.request.action\n\n\nThe HTTP method of the request.\nExample: GET\n\n\n\ndata.request.headers\n\nThe HTTP header fields and values in the request.\n\n\ndata.request.id\n\nThe unique identifier of a request. \n\n\ndata.request.parameters\n\nAll the parameters supplied by the caller during this operation.\n                            \n\n\ndata.request.path\n\n\nThe full path of the API\u00c2\u00a0request. \nExample:\u00c2\u00a0/20160918/instances/ocid1.instance.oc1.phx.<unique_ID>\n\n\n\n\nResponse\nThe response object contains the following attributes. \n\n\nProperty\nDescription\n\n\n\ndata.response.headers\n\nThe headers of the response.\n\n\ndata.response.message\n\nA friendly description of what happened during the operation.\n                            \n\n\ndata.response.payload\n\nThis value is included for backward compatibility with the Audit version 1 schema, where it\n                                contained metadata of interest from the response payload. \n\n\ndata.response.responseTime\n\nThe time of the response to the audited request, expressed in\n                                    RFC 3339 timestamp\n                                format.\n\n\ndata.response.status\n\nThe status code of the response.\n\n\n\nState Change\nThe state change object contains the following attributes. \n\n\nProperty\nDescription\n\n\n\ndata.stateChange.current\n\nProvides the current state of fields that may have changed during\n                                an operation. To determine how the current operation changed a\n                                resource, compare the information in this attribute to\n                                    data.stateChange.previous. \n\n\ndata.stateChange.previous\n\nProvides the previous state of fields that may have changed\n                                during an operation. To determine how the current operation changed\n                                a resource, compare the information in this attribute to\n                                    data.stateChange.current. \n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Data Catalog Policies service, \n Supported Variables, To add conditions to your policies, you can either use Oracle Cloud Infrastructure general or service-specific variables.\n\n\n\n\nOperations for This Resource Type...\n\n\nCan Use These Variables...\n\n\nVariable Type\n\n\nComments\n\n\n\n\n\ndata-catalog-family\n\n\ntarget.catalog.id\n\n\nEntity (OCID)\n\n\nNot available to use with CreateCatalog or work request operations.\n\n\n\n\ndata-catalogs\n\n\ntarget.catalog.id\n\n\nEntity (OCID)\n\n\nNot available to use with CreateCatalog or work request operations.\n\n\n\n\ndata-catalog-data-assets\n\n\ntarget.catalog.id\n\n\nEntity (OCID)\n\n\nNot available to use with work request operations.\n\n\n\n\ntarget.data-asset.key\n\n\nThe key is the Universally Unique Identifier (UUID) for the data asset, in a string\n         format. This ID is not an OCID.\n\n\nAvailable to use only with data asset operations except for\n          CreateDataAsset.\n\n\n\n\ndata-catalog-glossaries\n\n\ntarget.catalog.id\n\n\nEntity (OCID)\n\n\nNot available to use with work request operations.\n\n\n\n\ntarget.glossary.key\n\n\nString\nThe key is the Universally Unique Identifier (UUID) for the glossary, in a string format.\n         This ID is not an OCID.\n\n\nAvailable to use only with glossary operations except for\n         CreateGlossary.\n\n\n\n\ndata-catalog-namespaces\n\n\ntarget.catalog.id\n\n\nEntity (OCID)\n\n\nNot available to use with work request operations.\n\n\n\n\ntarget.namespace.key\n\n\nThe key is the Universally Unique Identifier (UUID) for the namespace, in a string\n         format. This ID is not an OCID.\n\n\nAvailable to use only with namespace operations.\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Monitoring Threats service, \n Cloud Guard can detect patterns of activity that indicate possible malicious attempts\n    to gain access to resources in your environment and use them for corrupt purposes.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Logging Overview service, \n Logging Concepts, \nThe following concepts are essential to working with Logging.\n\nService Logs\nCritical diagnostic information from supported Oracle Cloud Infrastructure\n                    services. See Supported Services.\nCustom Logs\nDiagnostic information from custom applications, other cloud providers, or an\n                    on-premise environment. To ingest custom logs, call the API directly or\n                    configure the unified monitoring agent.\nAudit Logs\nRead-only logs from the Audit service, provided for you to analyze and search.\n                    Audit logs capture the information about API calls made to public endpoints\n                    throughout your tenancy. These include API calls made by the Console, Command Line Interface (CLI), Software\n                    Development Kits (SDK), your own custom clients, or other Oracle Cloud Infrastructure services. \nLog Groups\nLog groups are logical containers for logs. Use log groups to streamline log\n                    management, including applying IAM policy or searching sets of logs. You can\n                    move log groups from one compartment to another and all the logs contained in\n                    the log group moves with it. \nService Log Category\nServices provide log categories for the different types of logs available for\n                    resources. For example, the Object Storage\n                    service supports the following log categories for storage buckets: read and\n                    write access events. Read access events capture download events, while write\n                    access events capture write events. Each service can have different log\n                    categories for resources. The log categories for one service have no\n                    relationship to the log categories of another service.\nService Connector Hub\n\nService Connector Hub moves logging data to other services in Oracle Cloud Infrastructure. For example, use Service\n                        Connector Hub to alarm on log data, send log data to\n                            databases, and archive log data to\n                            Object Storage. For more information, see Service Connector Hub.\n\nUnified Monitoring Agent\nThe fluentd-based agent that runs on customer machines (OCI instances), to help customers\n                    ingest custom logs.\nAgent Configuration\nA configuration of the Unified Monitoring Agent\n                    that specifies how custom logs are ingested.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating an Agent Dependency for an Environment service, \n Using the Console, \nTo create an agent dependency for an environment, perform the following\n            steps:\n\nOpen the Oracle Cloud Console navigation menu and click\n                    Migration. Under Cloud Migrations,\n                click Remote Connections.\n\nFrom the list of environments, click the active environment name link to which\n                    you can add the agent dependency. \nYou are redirected to the agent information\n                page.\n\nUnder Resources, click Agent\n                        dependencies.\n\nPerform Steps 3\u00e2\u0080\u00934 of Configuring Agent Dependency for VMware vSphere Using VDDK.\n\nYou can now proceed with asset discovery. See Managing External Asset Discovery.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n What's Included With Cloud Shell, \nIn addition to the OCI CLI, the Cloud Shell VM\u00c2\u00a0comes with current versions of many useful\n            tools and utilities pre-installed, including:\n\nGit\nJava\nPython (2 and 3)\nGraalVM Enterprise JDK 17 and Native Image\nSQL Plus\nkubectl\nhelm\nmaven\ngradle\nterraform\nansible\nnode.js\niputils\njqmake\ntmux\nvim\nNPM\nwget\nzip/unzip\nnano\nemacs\npip\nbash\nsh\ntar\nnvm\nmysql-community-client\nDocker engine\nipython\noci-powershell-modules\nGoldenGate Admin client\nMost OCI SDKs, including:\nJava\nPython\nGo\nTypeScript and JavaScript\nRuby\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Agent Management service, \n Managing Agent Configurations, \nTo use agent configurations, you must be running an Oracle Cloud Infrastructure instance with the supported operating system\n            (see Agent Management). Agent configurations give you a central\n            experience to easily configure what custom logs you want to ingest across your fleet of\n            hosts. A configuration allows you to select:\nWhich hosts you want to collect logs from.\nExactly which logs you want to ingest from those hosts.\nA log group/log destination.\nConfigurations are managed through the Console and Logging API. In addition, since\n            you can choose to create an agent configuration later after creating a custom log, you\n            can use the Agent Configurations page to set up the agent\n            configuration and point it to your custom log. \nThe Agent Configurations page is organized in\n            terms of the following:\n\nName\nConfig OCID\nStatus\nCreated\n\nTo create a new agent configuration\nOpen the navigation menu and click Observability & Management. Under Logging, click Agent Configurations.\n                        The Agent Configurations page is\n                        displayed.\nUnder List Scope, Compartment,\n                        choose a compartment you have permission to work in.\nClick Create agent config. The Create\n                            agent configuration panel is displayed.\nEnter a Configuration name and\n                            Description in the corresponding fields, and\n                        select a Compartment you have permissions to work in.\n                            Avoid entering confidential information.\nIn Host Groups, select a Group\n                            type from the list, whether Dynamic\n                            group or User group. Click\n                            + Another host group to add more groups.\nIn Configure log inputs, select an Input\n                            type form the list, whether Windows event\n                            log or Log path.\nFor Windows event log, enter an\n                                    Input name and select an Event\n                                    channels option from the list.\nFor Log path, enter an Input\n                                    Name and File paths in the\n                                corresponding\n                                fields.\n\nIn Select log destination, the User group or Dynamic\n                        group in the configuration that you select in Compartment needs to have\n                        permission to work in the compartment. Select the Log\n                            Group, and the Log name from the\n                        corresponding drop-down lists. The Log name can only\n                        point to a custom log and the custom log must exist in the chosen log group\n                        for the configuration to work.\nOptionally, after clicking Show Additional Options,\n                        specify any preferred tag settings.\nClick Create. The agent configuration is created and\n                        appears in the Agent Configurations page.\n\nTo view an agent configuration\nOpen the navigation menu and click Observability & Management. Under Logging, click Agent Configurations.\n                        The Agent Configurations page is\n                        displayed.\nUnder List Scope, Compartment,\n                        choose a compartment you have permission to work in.\nClick the linked agent configuration name under Name\n                        in the table. The agent configuration detail page is displayed. This page\n                        displays the following on the Log\n                            information tab: \nOCID\nCompartment\nCreated date and time in UTC format\nStatus (Creating, Active, Updating, Inactive,\n                                Deleting, Deleted)\nThe Tags tab shows associated tags for this\n                                log.\nUnder Log Details the following is displayed:\n                                the compartment, the linked log group and log name.In the\n                                        Configuration resource, the\n                                        Host group and Log\n                                        input configuration settings are listed in\n                                    corresponding tables. Under Host group\n                                    you can view the Group type, Group name, and the\n                                        OCID. Click the linked Group name (whether a User\n                                    Group or Dynamic Group), which opens the IAM\nGroups or Dynamic\n                                        Groups section of the Console, respectively. See\n                                        Managing Groups and\n                                        About Dynamic Groups for more information.Under Log\n                                        input you can view the Input\n                                        type, Input name,\n                                        Event channels, File\n                                        paths, Parser, and\n                                        Parser parameters (if applicable for\n                                    the chosen parser). In the Explore\n                                        log resource, log data is displayed in a similar\n                                    manner as the Log Data on the\n                                        Search page. You can apply some\n                                    simple filters, such as sorting by newest or oldest from the\n                                        Sort field, or filtering by time from\n                                    the corresponding Filter by time\n                                    field.Clicking Explore with Log\n                                        Search allows you to view this log on the\n                                        Search page directly. After clicking\n                                    this link, the Search page opens with the\n                                        Select Logs to Search field populated\n                                    with the log in the filter settings. At this point, you can\n                                    perform more analysis and investigation related to this log\n                                    directly on the Search page. For more\n                                    information, see Searching Logs.\n\n\nTo edit an agent configuration\nOpen the navigation menu and click Observability & Management. Under Logging, click Agent Configurations.\n                        The Agent Configurations page is\n                        displayed.\nUnder List Scope, Compartment,\n                        choose a compartment you have permission to work in.\nClick the linked agent configuration name under Name\n                        in the table. The agent configuration detail page is displayed.\nClick Edit. The Agent\n                            Configurations panel is displayed.From the main\n                                Agent Configurations page, for the agent\n                            configuration you want to edit, you can also click the the Actions menu, and\n                            then click Edit to access the Agent\n                                Configurations panel.\nMake your changes and click Save Changes.\n\nTo enable or disable an existing agent configuration\nOpen the navigation menu and click Observability & Management. Under Logging, click Agent Configurations.\n                        The Agent Configurations page is\n                        displayed.\nUnder List Scope, Compartment,\n                        choose a compartment you have permission to work in.\nClick the linked agent configuration name under Name\n                        in the table. The agent configuration detail page is displayed.\nClick Disable/Enable. A\n                        confirmation dialog is displayed regarding the disabling or enabling of the\n                        agent configuration.\nConfirm by clicking\n                            Disable/Enable. The agent\n                        configuration detail page changes its status and displays Inactive\n                        (for a disabled configuration), or Active (for an enabled\n                        configuration) in the status field, both on the agent configuration detail\n                        page and the Agent Configurations page.From the\n                            main Agent Configurations page, for the agent\n                            configuration you want to disable/enable, you can also click the the Actions menu, and\n                            then click Disable/Enable.\n\nTo delete an agent configuration\nOpen the navigation menu and click Observability & Management. Under Logging, click Agent Configurations.\n                        The Agent Configurations page is\n                        displayed.\nUnder List Scope, Compartment,\n                        choose a compartment you have permission to work in.\nClick the linked agent configuration name under Name\n                        in the table. The agent configuration detail page is displayed.\nClick Delete. A confirmation dialog is displayed\n                        regarding the delete operation.\nConfirm by clicking Delete. The agent configuration\n                        is removed from the Agent Configurations page.From\n                            the main Agent Configurations page, for the agent\n                            configuration you want to delete, you can also click the the Actions menu, and\n                            then click Delete.\n\nTo move an agent configuration to a different compartment\nOpen the navigation menu and click Observability & Management. Under Logging, click Agent Configurations.\n                        The Agent Configurations page is\n                        displayed.\nUnder List Scope, Compartment,\n                        choose a compartment you have permission to work in.\nClick the linked agent configuration name under Name\n                        in the table. The agent configuration detail page is displayed.\nClick Move Resource. The Move Resource to\n                            a Different Compartment dialog is displayed.\nChoose the new compartment and then click Move Resource.From the\n                            main Agent Configurations page, for the agent\n                            configuration you want to move to a new compartment, you can also click\n                            the the Actions menu,\n                            and then click Move Resource.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Oracle Support Rewards Overview service, \n Using the API, \nFor information about using\n                the API and signing requests, see REST APIs\n                and Security Credentials. For information about\n                SDKs, see Software Development Kits and Command Line Interface.\nThe Usage Proxy API allows you to list Oracle Support Rewards, view related detailed usage information, and manage users who redeem rewards. See the following operations for more information:\n\nListRewards\nListProducts\nListRedeemableUsers\nCreateRedeemableUser\nDeleteRedeemableUser\n\n\nFor monthly reward details and the corresponding redemptionCode attribute\n      related to viewing the redemption code, see\n        RewardDetails.\nTo manage the rewards redemption history, see the ListRedemptions operation.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell and Regions, \nWhen you start Cloud Shell, the service configures your Cloud Shell session with the currently selected region in the Console so that the OCI CLI is interacting with the selected Console region.\nIn the default bash prompt in Cloud Shell, the region that the OCI CLI is interacting with is echoed in the Cloud Shell command line prompt:\n\n\n\nAny changes to the selected region in Console after you've started your Cloud Shell session will not have an effect on your active Cloud Shell session.If you want to change the region that the OCI CLI is interacting with, in Cloud Shell, you can either:\n\nExit your current Cloud Shell session, then change the selected region in the Console, then start a new Cloud Shell session.\nModify the currently selected OCI CLI profile via the OCI_CLI_PROFILE environment variable\n\nFor more information, see the \"Managing Regions\" section in Using Cloud Shell. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Detecting Anomalies for Large Datasets service, \n Using the Console, \n\nPrerequisites:\nYou must have a project that contains a trained model for use in an asynchronous anomaly detection job.\n\n\n\nOpen the navigation menu and click Analytics & AI. Under AI Services, click Anomaly Detection. \n\nSelect the project you want to use.\n\nClick Jobs.\n\nClick Create job.\n\nSelect a compartment for the resource.\nYou can select a different compartment to store the resource instead of the default.\n\nEnter a unique name (255 character limit) for the resource. If you don't provide a name, a name is automatically generated for you using the format aianomalydetectionprojectYYYYNNDDHHMMSS. For example, aianomalydetectionproject20221125155844.\n\nEnter a description (400 character limit) for the resource. If you don't add a description, it remains empty.\n\nSelect the model you want to run in this job.\n\nSelect the input request type that you want to use for the job.\n\nInlineDrop a JSON or CSV file into the File box, or use Select File to locate and select it from a local drive.\nObject storeSelect the Object Storage bucket that contains the detection data file, then select file you want to use for this job. Only CSV files are supported.You can use multiple input buckets and detection data files by clicking Additional input bucket and making further selections.\n\n\nSelect an output bucket to store the output files in.\n\nThe namespace shows you the tenancy the job is being created in.\n\n(Optional) \n                Use prefix's are used to easily identify the results.\n\nFor example, if myModel is the prefix, then the result file is myModel/results-file.json.\n\n\nClick Create job.\n\nThe asynchronous job Status is initially Accepted until the job starts running, then it is In Progress, and finally when the job finishes the status changes to Succeeded. The time it takes to run the job is dependent on the size of the detection datasets.\n\n\nClick the completed asynchronous job to view its details and review the job results.\n\nThe anomaly detection results file is saved in a separate folder in the selected Object Storage output bucket. The file name use the <model-OCID>/<output_bucket_name> naming convention.\n\n\n<model-OCID> is the OCID of the Anomaly Detection\nModel\n\n\n<output_bucket_name> is the Object Store bucket name. \n\n\nThe anomaly detection results file name is the same as the detection dataset file name suffixed with -results.\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating Pipelines service, \n Using the Console, \n\n\n\nLog into your tenancy using the Console with the necessary policies.\n\nOpen the navigation menu and click Analytics & AI. Under Machine Learning, click Data Science.\nSelect the compartment that contains the project you want to use. \nClick the name of a project. \nClick Pipelines. \nClick Create pipeline. \n\n                Select a different compartment for the pipeline. \n            \n\n                Enter a name and description for the pipeline (limit of 255 characters). If you don't provide a name, a name is automatically generated for you. \n                For example:pipeline2022808222435\n\nClick Add pipeline steps to start defining the workflow for the pipeline. \nUse one of the following options:\n\nBuild by jobs\nThe step uses an existing job. You can select one of the jobs in your tenancy.\n\nEnter a unique step name. You can't repeat a step name in a pipeline. \n Enter a step description. This helps in determining step dependencies. \n If this step depends on another step, you can select one or more steps to be run before this step. \n Select the job for the step to run. \n Enter or select any of the following to control this pipeline step: \n                        \nCustom environment variable key and value\n\nEnvironment variables for this pipeline step. \n\nValue\n\nValue for your custom environment variable key.\nYou can click Additional custom environment variables to specify more variables.\n\nCommand line arguments\n\nThe command line arguments that you want to use for running the pipeline step. \n\nMaximum runtime (in minutes)\n\nThe maximum number of minutes that the pipeline step is allowed to run. The service cancels the pipeline run if its runtime exceeds the specified value. The maximum runtime is 30 days. We recommend that you configure a maximum runtime on all pipeline runs to prevent runaway pipeline runs.\n\n\n\nClick Save to add the step and return to the pipelines creation page. \n Use Add pipeline steps to add more steps to complete your workflow by repeating the preceding steps. \n You can create a default pipeline configuration that is used when the pipeline is run using environment variable, command line arguments, and maximum runtime options. \n Logging is enabled by default. You can disable logging or change the log group by clicking Select. Click Enable logging to turn logging off or select a different log group, and then click Select to save your changes. \n\nTagging describes the various tags that you can use organize and find resources including cost-tracking tags.\n\nClick Create. After the pipeline is in an active state, you can use pipeline runs  to repeatedly run the pipeline. \n\n\nBuild by script\nThe step uses a script to run. You need to upload the artifact containing all the code for the step to run.\n\nEnter a unique step name. You can't repeat a step name in a pipeline. \n Enter a step description. This helps in determining step dependencies. \n If this step depends on another step, select one or more steps to be run before this step. \nDrag and drop your job step file into the box, or click select a file to navigate to it for selection. \n When you have multiple files, you can select one file to be the entry run point of the step. \n Enter or select any of the following to control this pipeline step: \n                        \nCustom environment variable key and value\n\nEnvironment variables for this pipeline step. \n\nValue\n\nValue for your custom environment variable key.\nYou can click Additional custom environment variables to specify more variables.\n\nCommand line arguments\n\nThe command line arguments that you want to use for running the pipeline step. \n\nMaximum runtime (in minutes)\n\nThe maximum number of minutes that the pipeline step is allowed to run. The service cancels the pipeline run if its runtime exceeds the specified value. The maximum runtime is 30 days. We recommend that you configure a maximum runtime on all pipeline runs to prevent runaway pipeline runs.\n\n\n\nSelect one of the supported Compute shape series, and then select a shape. \nEnter the Block Storage size you want to use between 50 GB and 10,240 GB (10 TB). You can change the value by 1 GB increments. \nClick Save to add the step and return to the pipelines creation page. \n Use Add pipeline steps to add more steps to complete your workflow by repeating the preceding steps. \n You can create a default pipeline configuration that is used when the pipeline is run using environment variable, command line arguments, and maximum runtime options. \n Logging is enabled by default. You can disable logging or change the log group by clicking Select. Click Enable logging to turn logging off or select a different log group, and then click Select to save your changes. \n\nTagging describes the various tags that you can use organize and find resources including cost-tracking tags.\n\nClick Create. \n                        After the pipeline is in an active state, you can use pipeline runs  to repeatedly run the pipeline. \n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell and Regions, \nWhen you start Cloud Shell, the service configures your Cloud Shell session with the currently selected region in the Console so that the OCI CLI is interacting with the selected Console region.\nIn the default bash prompt in Cloud Shell, the region that the OCI CLI is interacting with is echoed in the Cloud Shell command line prompt:\n\n\n\nAny changes to the selected region in Console after you've started your Cloud Shell session will not have an effect on your active Cloud Shell session.If you want to change the region that the OCI CLI is interacting with, in Cloud Shell, you can either:\n\nExit your current Cloud Shell session, then change the selected region in the Console, then start a new Cloud Shell session.\nModify the currently selected OCI CLI profile via the OCI_CLI_PROFILE environment variable\n\nFor more information, see the \"Managing Regions\" section in Using Cloud Shell. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell Limitations, \nKeep the following limitations in mind when using Cloud Shell:\n\nCloud Shell comes with 5GB\u00c2\u00a0of storage for the VM's home directory. This storage is persistent from session to session, but after 6-months of non-use, the administrator for your tenancy will receive a notification that the storage will be removed in 60 days. Starting a cloud shell session resets the storage removal timer.\nCloud Shell does not support mounting additional storage.\nCloud Shell does not scan user files for malware or viruses.\nCloud Shell sessions do not allow for any incoming connections, and there is no\n                public IP address available.\nThe OCI CLI will execute commands against the region selected in the Console's Region selection menu when the Cloud Shell was started. Changing the region selection in the console will not change the region for existing Cloud Shell instances; you will need to open a new Cloud Shell instance to change regions.\nCloud Shell sessions have a maximum length of 24 hours, and time out after 60\n                minutes of inactivity.\n\nCloud Shell uses websockets to communicate between your browser and the service.\n                    If your browser has websockets disabled or uses a corporate proxy that has\n                    websockets disabled you will see an error message (\"An unexpected error\n                    occurred\") when attempting to start Cloud Shell from the console.\n\nCloud Shell is designed for interactive use with Oracle Cloud Infrastructure resources. Users who need additional storage for Cloud Shell or want to run non-interactive long-running tasks are encouraged to use Compute and Storage resources in their tenancy.\nFor maximum compatibility, Cloud Shell includes Python version 2 and Python version\n                3. Python 2 is the default that will run when you enter 'python' at the command\n                line. To run Python 3, enter 'python3' at the command line.\nThe following reserved words can't be used as the user name for a Cloud Shell user: oci, root, bin, daemon, adm, lp, sync, shutdown, halt, mai, operator, games, ftp, nobody, oci, systemd-network, dbus, polkitd, tss, and apache. Attempting to create a Cloud Shell session when logged in with a user name (or the part of the name before the @ sign if the user name is an email address)\u00c2\u00a0that is one of these reserved words will result in an \"Unexpected Error\" message.\nEntirely numerical user names (for example, \"1234\")\u00c2\u00a0are not supported by Cloud Shell.\nThe Cloud Shell session time zone is UTC, and cannot be changed.\nCloud Shell does not allow root access or the use of sudo, so packages that require\n                root access for installation can't be installed. Many packages are available in\n                versions that do not require root for installation; you can unpack and install these\n                in your home directory. \nCloud Shell does not allow the use of ping, since ping requires root access.\nCloud Shell boots in FIPS mode, which might affect the behavior of some commands.\nCloud Shell cannot generate PKCS#1 keys when using the openssl command, because Cloud Shell boots in FIPS mode. FIPS mode requires that Cloud Shell generates PKCS#8 keys.\nFor more information on Cloud Shell limits, see the Cloud Shell section in Service Limits. \n\nCloud Shell Access and Other Restrictions\nYou can access OCI resources from Cloud Shell according to the policies granted by\n                your tenancy administrator. There is no additional access because you're using Cloud\n                Shell, and Cloud Shell does not provide any additional access to your tenancy, or\n                private resources in your tenancy VCNs. Note Cloud Shell uses websockets to\n                    communicate between your browser and the service. If your browser has websockets\n                    disabled or uses a corporate proxy that has websockets disabled you will see an\n                    error message (\"An unexpected error occurred\") when attempting to start Cloud\n                    Shell from the console.\nWhile Cloud Shell provides access to the internet, there is no ingress from the\n                outside world into Cloud Shell (for example: you cannot ssh in to Cloud Shell) and\n                no public IP address available. If your tenancy admin does not want to enable access\n                to the internet from OCI, they should not grant access to Cloud Shell with an IAM\n                policy.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Resource Discovery service, \n Using the CLI, \n Note For information about using the CLI, see Command Line Interface (CLI). For a complete list of flags and\n            options available for CLI commands, see CLI\n                Help.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Service Mesh Overview Tutorial service, \n What's Next, \nCongratulations! You have successfully deployed the Bookinfo app to a Kubernetes cluster and\n            added Service Mesh to your app.\nTo explore more information about development with Oracle products, check out these\n      sites:\n\nOracle Developers Portal\nOracle Cloud Infrastructure\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Data Catalog Metastore service, \n Using Metastore in OCI Big Data Service, \nYou can configure a Data Catalog metastore as an external metastore for your Big Data Service cluster. \nFor more information about using metastore in Big Data Service, see Configuring an External Metastore.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Oracle Cloud Migrations service, \n Tenancy Resources Used in Migration, During the migration process, Oracle Cloud Migrations creates\n    temporary resources in your tenancy. Although there is no cost for using the service, temporary\n    resources are billed at the normal rate for the tenancy.\nYou can set a limit to the resources and to know about the limit that you can set, see Service Limits. These limits can be increased for you automatically\n      based on your Oracle Cloud Infrastructure resource usage and account\n      standing.\n\n Note Ensure that you don't modify the following temporary resources.\n        Modifying temporary resources created by Oracle Cloud Migrations\n        might cause pending operations to fail. \n\nCompute: Oracle Cloud Migrations launches compute\n          instances to run hydration agents during data replication. The hydration agents are pooled\n          together based on the replication location. To load balance the replication process based\n          on the object pool, the hydration agents start automatically. These agents are\n          automatically terminated after they are idle and no pending replication jobs exist. To\n          familiarize yourself with the compute services, see Overview of the compute service.\nObject Storage: During the replication workflow, the volume snapshots of your VMs\n          are stored in the Object Storage. The snapshot data is deleted from object storage after\n          hydration agents write the data to a block volume. To familiarize yourself with object\n          storage, see Overview of Object Storage.\nVirtual Cloud Network (VCN): During the replication workflow, a temporary VCN is\n          created to provide hydration agents with connectivity to object storage. The VCN is\n          stopped after all hydration agents are no longer active. To familiarize yourself with VCN,\n          see Networking Overview.\nBlock Storage: A set of block volumes exists in your tenancy for the entire\n          lifespan of a migration asset. A golden volume is created for each boot and data volume\n          that is attached to the source virtual machine. The golden volume is kept in\n          synchronization with snapshots created in the source environment. As part of each\n          replication update, a new set of volumes is created and used for launching compute\n          instances on OCI. To familiarize yourself with Block Volume, see Overview of Block Volume.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Notebook Sessions to Build and Train Models service, \n Working with Existing Code Files, \nYou can create new files or work with your own existing files.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Moving API Gateways and API Deployments Between Compartments service, \n Using the API, \n\nFor information about using\n                the API and signing requests, see REST APIs\n                and Security Credentials. For information about\n                SDKs, see Software Development Kits and Command Line Interface.\n\nUse the:\n\nChangeGatewayCompartment operation to move an API gateway to a different compartment.\nChangeDeploymentCompartment operation to move an API\u00c2\u00a0deployment to a different compartment.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Notebook Sessions to Build and Train Models service, \n Using the Oracle Accelerated Data Science SDK, \nOracle Accelerated Data Science (ADS) SDK speeds up common data science activities by providing tools that automate and simplify common data science tasks. Additionally, it provides data scientists a friendly Python interface to OCI services including Data Science including jobs, Big Data, Data Flow, Object Storage, Streaming, and Vault, and to Oracle Database. ADS gives you an interface to manage the life cycle of machine learning models, from data acquisition to model evaluation, interpretation, and model deployment.\nWith ADS you can:\n\nRead datasets from Object Storage, Oracle Database (ATP, ADW, and On-premise), AWS S3, and other sources into Pandas data frames.\nTune models using hyperparameter optimization with the ADSTuner module.\nGenerate detailed evaluation reports of your model candidates with the ADSEvaluator module.\nSave machine learning models to the Data Science model catalog.\nDeploy models as HTTP requests with model deployment.\nLaunch distributed ETL, data processing, and model training jobs in Spark using Data Flow.\n\nconnect to the BDS from the notebook session, the cluster created must have Kerberos enabled.\nUse Kerberos enabled clusters to connect to Big Data from a notebook session.\n\nUse feature types to characterize your data, create meaning summary statistics, and plot. Use the warning and validation system to test the quality of your data.\nTrain machine learning models using Data Science jobs.\nManage the life cycle of conda environments using the ads conda CLI.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Data Catalog Metastore service, \n Editing the Metastore, \nYou can edit only the name of the metastore.  Note Before you edit the name, review its\n                    usage in other services. The new metastore name must be available to the service\n                    accessing this metastore.\nHere's how you edit the name of a metastore:\n\n\nOn the metastore details page, click Edit. The Edit Metastore panel opens.\nAlternatively, from the Data Catalog service page, click Metastores. On the Metastores page, click the the Actions menu for the metastore and select Edit. \n\nIn the Name field, enter the new name for the metastore.\n\nClick Save Changes.\nThe name of the metastore gets updated.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using the Console service, \n Viewing and Working with Search Results, \nAfter you get an initial set of results, you can view more details, whether in terms of\n            the log fields, JSON, or before and after states, and visually as a chart. On the\n                Explore tab, a Number of log events per\n                minute bar graph displays the number of log events, according to your\n            filter settings. The Explore tab displays a maximum of 100 search\n            results.\n Note To see the latest logs, ensure you click Search after time has\n            passed while on the Search page. \n Note For any actions taken on the Explore and\n                Visualize tabs, you can define how often to refresh the data\n            on the Search page by selecting a value from the\n                Autorefresh list (choose from OFF,\n                5 Minutes, or 15 Minutes). The default\n            is OFF.\nYour search results can also be visualized. See Visualizing Search Results for more information.\nTo search with Quick Start QueriesYou can quickly search according to several predetermined queries. From\n                        Quick Start Queries, select a query from the list.\n                    The Search page displays the results for the chosen\n                    query.\nTo examine a single log entryOn the Explore tab, click\n                the down arrow () to expand the log\n            entry in\n                        JSON view. The JSON view is displayed. In JSON view you can view the\n                    log data fields and values, collapse and expand nodes, or click the copy icon to\n                    copy the log entry to the clipboard.\nTo view all log dataFrom the Explore tab's Actions\n                    menu, select Expand log data. All the log entries from\n                    your search are fully expanded, without having to click the down arrow () for each one. To reverse\n                    this state, select Collapse log data to close every entry\n                    simultaneously.\nTo wrap or unwrap linesFrom the Explore tab's Actions\n                    menu, select Wrap lines. The Wrap\n                        lines option allows you to view each entry's data with line\n                    wrapping. Select Unwrap lines to undo. The\n                        Wrap lines feature also works when you are viewing an\n                    expanded log entry in JSON view.\nTo switch between JSON and Before & After viewOn the Explore tab, click\n                the down arrow () to expand the log\n            entry and\n                    click JSON.The JSON view is displayed. Click the Before & After\n                    tab to switch to its view.\nTo examine Before & After viewOn the Explore tab, click\n                the down arrow () to expand the log\n            entry and\n                    click Before & After.The Before & After view is displayed. In contrast to\n                    the entry labeled as Current, this view displays the\n                    preceding and successive logging lines in the log object. Click Show\n                        newer entries or Show older entries to\n                    view extra corresponding newer or older entries in the Before &\n                        After view.\nView more options for log entry rows and fields in JSON\n                viewOn the Explore tab, each entry has three interactive\n                    header columns, which correspond to: the log timestamp\n                        (datetime), the plugin where the log occurred\n                        (type), and the log message\n                        (data.message).You can interact with and customize the log entry view whether a log entry is\n                    collapsed or expanded. When clicking a collapsed entry, click one of the log entry columns to open a\n                    context-sensitive menu for that entry and the column header. The following\n                    options are shown:\nCopy value\nFilter matching Note Not available for the\n                                data.message column of an open or closed log\n                            entry.\nFilter not matching Note Not available for the\n                                data.message column of an open or closed log\n                            entry.\nRemove from summary view Note This option does not\n                            apply to the first default column (datetime). It\n                            is only available for new fields you add to the\n                                Explore tab's summary view, or the\n                                type and data.message\n                            columns which you can also remove.\nFor an expanded log entry with the JSON view visible, you can click a log field\n                    to access the following options:\nCopy value\nFilter matching\nFilter not matching\nAdd to summary view\n Note These options are also available on the JSON tab of an\n                    opened Before & After view.When selecting Add to summary view for a particular field,\n                    the field is added to the Explore tab view, to the right\n                    of the first three default columns (datetime,\n                        type, data.message). For\n                    example, if you click \"logContent\" and select Add to\n                        summary view, a new logContent column is\n                    added, just after data.message. \nTo manage and add log fieldsFrom the Explore tab's Actions\n                    menu, select Manage log fields. The Manage log\n                        fields panel opens. Select the fields you want to add to the\n                        Explore tab and click Apply.\n                    The Explore tab reloads and appends the new fields to the\n                    right of the first three default fields (datetime,\n                        type, data.message). You can\n                    remove any added fields by clicking the X icon in the\n                    column header, which reloads the tab to display the results without the\n                    additional fields. The type and\n                        data.message columns can also be removed, so you can\n                    potentially add nine other log fields of interest, for a total of 10 columns\n                    that can be displayed in the Explore tab results. The\n                        datetime column cannot be removed. Note If you are\n                        managing and adding log fields in Basic Mode search and\n                        then switch to Advanced Mode, column header selections are still maintained,\n                        even as you type an advanced query.\nTo export log dataFrom the Explore tab's Actions\n                    menu, select Export log data (JSON). This feature allows\n                    you to export the log data to a JSON file that you can save to your system.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Vision, \nFor known issues with Vision, see Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Agent Management service, \n Log Destination, \nYou can choose the exact log group and log object where you want your log events to be\n            indexed. All incoming log events from your hosts are ingested and indexed in your\n            selected log object. After they are ingested, you can view and search your log events on\n            the Search page (see Searching Logs). All\n            existing Oracle Cloud Infrastructure Identity and Access Management policies in both the log group\n            and compartment apply both during ingestion and search. So, only authorized users\n            can view and ingest logs in your tenancy.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Policies service, \n Permissions Required for Each API Operation, The following table lists the Managed Access API operations in a logical order, grouped by resource type.\nFor more information about permissions, see Managed Access policies.\n\n\nOperations\nPermissions\n\n\n\nListLockboxes\n\nLOCKBOX_INSPECT\n\n\n\nCreateLockbox\n\nLOCKBOX-CREATE\n\n\n\nGetLockbox\n\nLOCKBOX_READ\n\n\n\nUpdateLockbox\n\nLOCKBOX_UPDATE\nLOCKBOX_UPDATE & APPROVAL_TEMPLATE_ATTACH\n\n\n\nDeleteLockbox\n\nLOCKBOX_DELETE\n\n\n\nChangeLockboxCompartment\n\nLOCKBOX_MOVE\n\n\n\nListApprovalTemplates\n\nAPPROVAL_TEMPLATE_INSPECT\n\n\n\nCreateApprovalTemplate\n\nAPPROVAL_TEMPLATE_CREATE\n\n\n\nGetApprovalTemplate\n\nAPPROVAL_TEMPLATE_READ\n\n\n\nUpdateApprovalTemplate\n\nAPPROVAL_TEMPLATE_UPDATE\n\n\n\nDeleteApprovalTemplate\n\nAPPROVAL_TEMPLATE_DELETE\n\n\n\nChangeApprovalTemplateCompartment\n\nAPPROVAL_TEMPLATE_MOVE\n\n\n\nListAccessRequests\n\nACCESS_REQUEST_INSPECT\n\n\n\nCreateAccessRequest\n\nACCESS_REQUEST_CREATE\n\n\n\nGetAccessRequest\n\nACCESS_REQUEST_READ\n\n\n\nHandleAccessRequest\n\nACCESS_REQUEST_CREATE\nACCESS_REQUEST_ACTION_HANDLE \n\n\n\nGetAccessMaterials\n\nACCESS_REQUEST_CREATE\n\n\n\nListAccessApproval\n\nACCESS_APPROVAL_INSPECT\n\n\n\nGetAccessApproval\n\nACCESS_APPROVAL_READ\n\n\n\nCreateAccessApproval\n\nACCESS_APPROVAL_CREATE\n\n\n\nGetAccessMaterials\n\nACCESS_APPROVAL_RETRIEVE\n\n\n\nRevokeAccessApproval\n\nACCESS_APPROVAL_ACTION_REVOKE\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Configuring a Target Asset service, \n Using the CLI, \n\nTo create a target asset and configure it, use the create command.\n\noci cloud-migrations target-asset create --is-excluded-from-execution yes|no --migration-plan-id migration_plan_ID --type asset_type [OPTIONS]\n\nThe required parameters for the create command are:\n--is-excluded-from-execution: Specifies whether an asset\n                        can be migrated.\n--migration-plan-id: Specifies the OCID of the migration\n                        plan.\n--type: Specifies the type of the target asset. The\n                        accepted value is, INSTANCE.\n\nTo get all the commands for target-asset, run:\noci cloud-migrations target-asset -h\nTo get help for the create command, run:\noci cloud-migrations target-asset create -h\nFor a complete list of flags and\n                variable options for CLI commands, see the Command Line Reference.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Searching Inventory Assets service, \n Using inventory, you can search discovered assets easily in Oracle Cloud Migrations. \nPerform the following steps:\n\nOpen the Oracle Cloud Console navigation menu and click\n                    Migration. Under Cloud Migrations,\n                click Inventory, and then click Inventory\n                    assets.\nThe Inventory assets page lists all the external\n                    assets discovered by the asset discovery from the source environment. The listed\n                    assets contain metadata that the discovery plugin collects from the assets on\n                    the source environment.\n\nIn the Search box, choose a compartment or compartments\n                    and the type of resource.\n\nTo extract the list of all assets based on the compartment ID, click\n                        Search.\n\nTo provide a query for searching, do one of the following:\n\nUse the Quick start query option. \nTo choose a query string, click Quick start\n                                    query, and choose the required field name to query\n                                    with.You can see the query field name under Custom\n                                        filters.\nIn the Custom filters box, choose a value and\n                                complete the query condition.\n\nUse the Switch to query editor mode option.\nClick Switch to query editor mode.\nIn the query editor, specify the required conditions. See About Conditions for\n                                reference.\nClick Switch to basic mode.\n\n\nYou can now view the list of assets based on the query that you\n                    set.Create multiple queries using one of the mentioned options in Step 4, as\n                    required.\n\nTo save the search query, click Save search.\n\nTo populate the list of discovered assets instantly, click Select a\n                        saved search and choose a query from previously saved\n                    queries.\n\nYou can now create a migration project. See Creating a Simple Migration Project.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Partner Portal service, \n I can\u00e2\u0080\u0099t sign in to Partner Portal, \nHere are a few reasons why you might not be able to sign in to Partner Portal:\n\n\nAre you entering the user name and password for your Oracle account? Your user\n                    name is the email address you specified when registering for an Oracle\n                    account.\n\n\nAre you typing your user name and password correctly? Passwords are\n                    case-sensitive. Make sure you aren\u00e2\u0080\u0099t pressing the Caps Lock key.\n\n\nHas your administrator created a Partner Portal\n                    account for you and assigned you a role? By default, the person who registered\n                    to become a publisher for Oracle Cloud Marketplace is assigned the role of\n                    partner administrator. The administrator can then add accounts, assign roles,\n                    and grant access to other users in the company.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n What's Included With Cloud Shell, \nIn addition to the OCI CLI, the Cloud Shell VM\u00c2\u00a0comes with current versions of many useful\n            tools and utilities pre-installed, including:\n\nGit\nJava\nPython (2 and 3)\nGraalVM Enterprise JDK 17 and Native Image\nSQL Plus\nkubectl\nhelm\nmaven\ngradle\nterraform\nansible\nnode.js\niputils\njqmake\ntmux\nvim\nNPM\nwget\nzip/unzip\nnano\nemacs\npip\nbash\nsh\ntar\nnvm\nmysql-community-client\nDocker engine\nipython\noci-powershell-modules\nGoldenGate Admin client\nMost OCI SDKs, including:\nJava\nPython\nGo\nTypeScript and JavaScript\nRuby\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating an API Deployment Specification service, \n Using the Console to Create an API Deployment Specification, \nTo create an API\u00c2\u00a0deployment specification whilst creating an API deployment using dialogs in the Console, see Using the Console to Create an API Deployment from Scratch.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Distributed Tracing for Functions service, \n Using the Console to Enable Tracing and View Function Traces, \nA couple of steps are required to enable tracing and to view function traces for the Oracle Cloud Infrastructure\nApplication Performance Monitoring (APM) service. First,\n            enable tracing for the application containing the function. Then, enable tracing for one\n            or more functions. You can then view function traces in the APM Trace Explorer.\nUsing the Console to Enable Tracing\nTo enable tracing, follow these steps.\n\n\nSign in to the Console as a functions developer.\n\nIn the Console, open the navigation menu and click Developer Services. Under Functions, click Applications.\nSelect the region and compartment containing the Functions application. The\n                            Applications page shows all the applications in the compartment\n                        you selected.\nSelect the Functions application for which you want to enable tracing.\nTo enable tracing for the application:\nUnder Resources, click Traces.\nSelect the Trace Enabled option and specify:\nCompartment: The compartment in which to create the\n                                    trace. By default, the current compartment.\nAPM Domain: The APM domain (defined in the Application Performance Monitoring service) in which to create the trace. To use an existing APM\n                                    Domain, select an existing APM domain from the list. Or, to\n                                    create a new APM domain, click APM Domain. For more\n                                    information about APM domains, see Getting Started with Application Performance\n                                        Monitoring.  Note The APM Domain needs to have\n                                            both public and private data keys for\n                                        function tracing to work. If the keys do not exist, you can\n                                        create them through the console interface.\n\n\nClick Enable Trace to enable tracing for the application.\nHaving enabled tracing for the Functions application, you can now enable\n                        tracing for one or more functions in the application.\nTo enable tracing for specific functions in the application:\nUnder Resources, click Functions.\n\nSelect the Enable Trace option beside one or more function(s)\n                                for which you want to enable tracing. \nThe Enable Trace option is only shown if you have previously\n                                enabled tracing for the application. Note the following:\n\nIf the Enable Trace option is not shown, you must enable\n                                    tracing for the application. If you haven't already enabled\n                                    tracing for the application, see the previous step.\nIf you previously enabled tracing for the application but later\n                                    disabled it, an Enable application tracing link is shown.\n                                    Click the Enable application tracing link to re-enable\n                                    tracing for the application (see the previous step). Having\n                                    re-enabled tracing for the application, you can then enable\n                                    tracing for specific functions.\n\n\n\n\nWhen you have enabled tracing for the application and one or more functions, you can\n                view function traces.\n\nUsing the Console to View Function Traces\nTo view the traces for functions that have tracing enabled:\n\n\nSign in to the Console as a functions developer.\n\nIn the Console, open the navigation menu and click Developer Services. Under Functions, click Applications.\nSelect the region and compartment containing the Functions application with\n                    functions for which you want to view function traces. The Applications\n                        page shows all the applications in the compartment you selected.\nSelect the application containing the functions for which you want to view\n                    traces.\nTo see traces for functions:\nTo see traces for all the functions that have tracing enabled in the\n                                application:\nUnder Resources, click Traces.\nClick the name of the trace.  Note A trace name is only shown if\n                                        you have already enabled tracing for the\n                                    application.\n\nTo see the trace for a specific function that has tracing enabled: \nUnder Resources, click Functions.\nClick the Actions icon (three dots) beside the function, and\n                                    then click View Trace. Note The View Trace option\n                                        is only shown if you have already enabled tracing for the\n                                        function.\n\nThe traces for the functions you selected are shown in the APM Trace\n                        Explorer. By default, a trace is shown for the default function invocation\n                        span, and any custom spans defined for the function.\nIn the APM Trace Explorer:\nClick a trace to see the spans for that trace.\nClick a span to see the details captured for that span.\nFor more information about using the APM Trace Explorer, see Use Trace\n                            Explorer.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Installing a Remote Agent Appliance for VMware\n        vCenter service, \n Details for Deploying an OVA or OVF Template, This task describes the information that you can provide on vSphere Client when installing the remote agent appliance.\n\nAfter logging into vSphere Client, right-click an object pool, and then choose\n                    Deploy OVF Template. You can enter the details in the\n                    Deploy OVF Template wizard, as mentioned.\n\n\nFor the Select an OVF template page, click the Local file option and browse to select the remote agent appliance that you have downloaded in Step 4 of Installing a Remote Agent Appliance for VMware vCenter.\n\nFor the Select a name and folder page, enter a unique\n                    name for the virtual machine with which the VM is identified in VMware. \n\n Note Ensure that the virtual machine name is unique within the vCenter server\n                        virtual machine folder.\n\n\nFor the Select a compute resource page, proceed next to\n                    continue with the default deployment location. \nThe default deployment location is the object pool from where you started\n                    using the Deploy OVF Template wizard in Step 1.\n\nFor the Review details page, proceed next to continue\n                    with the default values.\n\nFor the Select storage page, proceed next to continue\n                    with the default values.\n\nFor the Select networks page, choose the following for\n                    the destination networks of the source network:\n\n\nExternal Network: Choose the network that\n                            provides connectivity with Oracle cloud (Internet).\nInternal Network: Choose the network that\n                            provides connectivity within VMware vCenter.\n\n\n\nFor the Customize template page, enter the following\n                    information for various properties:\n\n\nOS propertiesHostname: Specify the host network name. If you don't specify the hostname, Dynamic Host Configuration Protocol (DHCP) assigns a relevant hostname.\nNetwork properties\nIP address: Specify the IP address of eth0. Only IPv4 addresses are supported. If you don't specify the IP address, then it is set to DHCP.\nGateway: Specify the gateway of eth0. If\n                                    you don't specify the gateway, it is set to DHCP.\nDNS: Specify IP address of the domain name system (DNS) server. If you don't specify, then DHCP lease must include a DNS server IP address. For the replication to work, the Remote Agent Appliance must have connectivity to a DNS server that resolves addresses for names in the oraclecloud.com domain and the fully qualified domain names (FQDN) of VMware infrastructure components (vCenter Server and ESXi hosts). For more information, see Prerequisites.\nDNS Domain: Specifies the DNS domain. If\n                                    you don't specify the domain, it is set to DHCP.\n\nProxy properties\nHTTPS Proxy: Specify the HTTPS proxy\n                                    settings for Internet access. The login and password are\n                                    optional. \nNon-proxied DNS domains: Specify a\n                                    comma-separated list of domain HTTP(s) connections to bypass the\n                                    HTTPS proxy. \n\nTime propertiesNTP\n                                    Server: Specify a comma-separated list of NTP server\n                                addresses or DNS names to be used instead of the\n                                appliance-hard-coded list when the entry is not empty.\n\n\n\nAfter clicking Finish on the Ready to\n                complete page, the virtual machine is created under the selected object\n            pool. The virtual machine isn't powered on now. To power on the VM, see Step 6 of\n                    Installing a\n                    Remote Agent Appliance.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Setting Up Custom Domains and TLS Certificates service, \n Renewing Custom TLS Certificates Used by API Gateways, \nTLS certificates are valid for a limited period of time (typically one or two years) before they expire. If the TLS\u00c2\u00a0certificate used by an API\u00c2\u00a0gateway expires, calls to an API deployed on the API\u00c2\u00a0gateway might be marked as insecure by the API client (for example, by a browser or by the curl command line tool) and blocked. To avoid blocked calls, you have to renew TLS certificates before they expire (sometimes referred to as 'rotating' certificates).\nIf the API Gateway service obtained the original TLS certificate for you, the API Gateway service automatically renews the TLS\u00c2\u00a0certificate with the Oracle-designated Certificate Authority before it expires. However, if you obtained a custom TLS certificate yourself, you are responsible for renewing the custom TLS\u00c2\u00a0certificate with your chosen Certificate Authority before it expires. When you request the renewal of a TLS\u00c2\u00a0certificate, the Certificate Authority returns a completely new TLS\u00c2\u00a0certificate. \nThe procedure for renewing a custom TLS certificate used by API gateways depends on whether you've created API Gateway certificate resources or Certificates service certificate resources.\nRenewing custom TLS certificates for API Gateway certificate resources\nWhen you've created an API Gateway certificate resource used by an API gateway, you cannot simply update the existing API Gateway certificate resource with the new TLS certificate. Instead, you create a new API Gateway certificate resource, add the new TLS\u00c2\u00a0certificate to the new certificate resource, and then update any API gateways that used the previous certificate resource to use the new certificate resource.\n To renew the custom TLS\u00c2\u00a0certificate used by an API\u00c2\u00a0gateway:\n\n\nSubmit a TLS certificate renewal request to the Certificate Authority from which you originally obtained the TLS certificate. The exact steps to renew a TLS\u00c2\u00a0certificate depend on the Certificate Authority you use, so always refer to the Certificate Authority documentation for more detailed information.\nWhen you create the certificate renewal request, a public key is added to the request, and a corresponding private key is also generated and stored in a local file. You'll use this private key when you set up the new API Gateway certificate resource, so make a note of its location.\nThe Certificate Authority returns a file containing the new custom TLS certificate, and typically one or more files containing intermediate certificates forming a certificate chain from the TLS\u00c2\u00a0certificate back to the Certificate Authority.\n\nCreate a new API Gateway certificate resource and add to it the new TLS\u00c2\u00a0certificate, any intermediate certificates, and the new private key (see Step 2: Create an API Gateway certificate resource).\nUpdate all the existing API gateways that used the original API Gateway certificate resource to use the new API Gateway certificate resource (see Updating API Gateways and API Deployments).\nWhen there are no API\u00c2\u00a0gateways still using the original API Gateway certificate resource, delete the original certificate resource:\nIf using the Console: On the Certificates page, click the Actions icon (three dots) beside the original API Gateway certificate resource you want to delete, and then click Delete.\nIf using the CLI: Use the following command to delete the original API Gateway certificate resource:oci api-gateway certificate delete --certificate-id <certificate-ocid>\nNote that you cannot delete an API Gateway certificate resource if there are API\u00c2\u00a0gateways still using it.\n\n\nRenewing custom TLS certificates for Certificates service certificate resources\nWhen you've created a Certificates service certificate resource used by an API gateway, you can use the Certificates service to renew the TLS certificate by creating a new certificate version. The new certificate version has the same OCID as the original certificate, so you don't have to modify API gateways to use a new certificate resource. The API Gateway service automatically updates API gateways to use the new version. Note that there are some restrictions on the certificates that the Certificates service can renew. See Renewing a Certificate. \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n What's Included With Cloud Shell, \nIn addition to the OCI CLI, the Cloud Shell VM\u00c2\u00a0comes with current versions of many useful\n            tools and utilities pre-installed, including:\n\nGit\nJava\nPython (2 and 3)\nGraalVM Enterprise JDK 17 and Native Image\nSQL Plus\nkubectl\nhelm\nmaven\ngradle\nterraform\nansible\nnode.js\niputils\njqmake\ntmux\nvim\nNPM\nwget\nzip/unzip\nnano\nemacs\npip\nbash\nsh\ntar\nnvm\nmysql-community-client\nDocker engine\nipython\noci-powershell-modules\nGoldenGate Admin client\nMost OCI SDKs, including:\nJava\nPython\nGo\nTypeScript and JavaScript\nRuby\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Required IAM Policy, \nTo get started with Cloud Shell, you\u00e2\u0080\u0099ll need to grant user access to Cloud Shell via an IAM policy. Each service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nTo use Oracle Cloud Infrastructure, you must be given the required type of access in a policy written by an administrator in the tenancy's root compartment, whether you're using the Console or the REST API with an SDK, CLI, or other tool. If you try to perform an action and get a message that you don\u00e2\u0080\u0099t have permission or are unauthorized, confirm with your administrator that you've been granted access.\n Note  Cloud Shell does not support policies at the compartment level, only at the\n                tenancy level.The resource name for Cloud Shell is `cloud-shell`. The\n            following is an example policy to grant access to Cloud Shell:\nallow group <GROUP-NAME> to use cloud-shell in tenancy\n\nThis example policy shows how to allow a group within a domain to use Cloud\n            Shell:allow group <DOMAIN-NAME>/<GROUP-NAME> to use cloud-shell in tenancy\nIf you're new to policies, see Getting Started with Policies and Common Policies.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Transforming Incoming Requests and Outgoing Responses service, \n \nThere are often situations when you'll want an API gateway to modify incoming requests\n            before sending them to back-end services. Similarly, you might want the API gateway to\n            modify responses returned by back-end services. For example:\n\nBack-end services might require requests to include a particular set of HTTP headers\n                (for example, Accept-Language and Accept-Encoding). To hide this implementation\n                detail from API\u00c2\u00a0consumers and API clients, you can use your API gateway to add the\n                required headers.\nWeb servers often include full version information in response headers. For security\n                reasons, you might want to prevent API\u00c2\u00a0consumers and API clients knowing about the\n                underlying technology stack. You can use your API\u00c2\u00a0gateway to remove server headers\n                from responses.\nBack-end services might include sensitive information in a response. You can use your API\u00c2\u00a0gateway to remove such information.\n\n Using an API gateway, you can:\n\nAdd, remove, and modify headers in requests and responses.\nAdd, remove, and modify query parameters in requests.\nRewrite request URLs from a public format to an internal format, perhaps to support\n                legacy applications and migrations.\n\nYou use request and response policies to transform the headers and query parameters of\n            incoming requests, and the headers of outgoing responses (see Adding Request Policies and Response Policies to API Deployment Specifications).\nYou can include context variables in header and query parameter transformation request\n            and response policies. Including context variables enables you to modify headers and\n            query parameters with the values of other headers, query parameters, path parameters,\n            and authentication parameters. Note that values of context variable values are extracted\n            from the original request or response, and are not subsequently updated as an API\n            gateway uses a transformation policy to evaluate a request or response. For more\n            information about context variables, see Adding Context Variables to Policies and HTTP Back End Definitions.\nIf a header or query parameter transformation request or response policy will result in\n            an invalid header or query parameter, the  transformation policy is ignored.\nYou can add header and query parameter transformation request and response policies to an\n            API deployment specification by:\n\nusing the Console\nediting a JSON file\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Consumer Groups service, \n Consuming as a Group, \nAfter your instances join the consumer group, they can read messages from the stream\n            using GetMessages. Each call to\n            GetMessages returns the cursor to use in the next GetMessages call as the\n                opc-next-cursor header value. The returned cursor is never null,\n            but it expires in five minutes. As long as you keep consuming, you should never have to\n            re-create a cursor.\nWhen Streaming receives a request for\n            messages from an instance, the service:\n\nChecks to see whether a group rebalance is necessary\nCommits the offset(s) from that instance's previous\n                request, if any\nResponds with the messages defined by the request's cursor\n\nGetMessages batch sizes are based\n            on the average message size published to that stream. By default, the service returns as\n            many messages as possible. You can use the limit parameter to specify\n            any value up to 10,000, but consider your average message size to avoid exceeding\n            throughput on the stream or timeouts.\nIf there are no more unread messages in the partition, Streaming returns a list of empty\n            messages.\nBecause consumer groups remove instances that have stopped consuming messages for more\n            than 30 seconds, you should request fewer messages to avoid timeouts, or extend the\n            timeout using ConsumerHeartbeat. \nA partition cannot be assigned to multiple instances within the same consumer group. If\n            you have more instances than partitions, the unassigned instances can send GetMesages\n            requests, but they won't receive any messages. They remain otherwise idle until the\n            consumer group needs to replace an instance, such as when an existing member of the\n            group does not act within the timeout period.\nIf you need to manually update the group's position, you can use UpdateGroup to reset the location of\n            all consumers in the group to the specified location in the stream.\nOffsets and Commits\nOffsets indicate the location of a message within a partition. If a consumer restarts\n                or you need to recover from a failure, you can use the offset to restart reading\n                from the stream.\nWhen you use a consumer group, Streaming\n                handles offsets automatically. The default behavior of\n                    commitOnGet=true means that offsets from the previous\n                request are committed. For example:\nFor consumer A:\n\nA calls GetMessages and receives messages from an arbitrary partition, with\n                    offsets of 1\u00e2\u0080\u0093100.\nA processes all 100 messages successfully.\nA calls GetMessages, and the Streaming service commits offset 100 and returns messages with offsets\n                    101\u00e2\u0080\u0093200.\nA processes 15 messages, and then goes offline unexpectedly (for more\n                    than 30 seconds).\n\nA new consumer B:\n\nB calls GetMessages, and the Streaming service uses the latest committed offset and returns\n                    messages with offsets 101\u00e2\u0080\u0093200.\nB continues the message loop.\n\nIn this example, a portion (15) of the messages were processed at least once, which\n                means that they could have been processed more than once, but no data is lost.\nStreaming provides \"at-least-once\"\n                semantics for consumer groups. Consider when offsets are committed in a message\n                loop. If a consumer goes offline before committing a batch of messages, that batch\n                might be given to another consumer. When a partition is given to another consumer,\n                the consumer uses the latest committed offset to start consumption. The consumer\n                doesn't get messages before the committed offset. We recommend that consumer\n                applications take care of duplicates.\n Note\nMessage offsets aren't dense. Offsets are monotonically increasing numbers. They\n                    do not decrease, and sometimes they increase by more than one. For example, if\n                    you publish two messages to the same partition, the first message could have an\n                    offset of 42 and the second message could have an offset of 45 (offsets 43 and\n                    44 being non-existent).\n\nIf you want to override the default offset behavior and implement a custom offset\n                commit mechanism, set commitOnGet to false when\n                creating the group cursor. You can use ConsumerCommit to commit\n                messages without reading more messages. ConsumerCommit returns a cursor for you to\n                use in your next request.\n Caution\nWriting custom commit logic is complicated and full of race conditions and\n                    considerations. Many cases exist in which some internal state is changed, and\n                    the client is required to handle the situation.\n\n\nBalancing and Rebalancing\nStreaming considers the number of\n                partitions in the stream and the number of instances in the consumer group when\n                assessing balance. Group balancing is automatic. Each consumer is assigned to one or\n                more partitions based on the following calculation: \n(nPartitions / nConsumers) \u00c2\u00b1 1\nFor example, if there are eight partitions in the stream and four consumers in the\n                group, each consumer is assigned to two partitions. If there are 10 partitions in\n                the stream and four consumers in the group, two consumers are assigned to two\n                partitions, and two consumers are assigned to three partitions.\nAs instances join or leave a consumer group and requests are made for messages,\n                partition assignments are reassessed. If the stream has at least one partition more\n                than the number of current instances in the group, and a new instance joins,\n                partitions are reassigned to all instances, including the new one. If an instance in\n                the group stops consuming messages for more than 30 seconds, or fails to send a\n                    ConsumerHeartbeat\n                within 30 seconds, that instance is removed from the consumer group and its\n                partition is reassigned, if possible, to another instance.\nThese events are called rebalancing. The instances in the group are not aware\n                of the rebalancing process, but the group has coordinated to own a mutually\n                exclusive set of partitions in the stream.\nAt the end of a successful rebalance operation for a consumer group, every partition\n                within the stream is owned by an instance within the group.\nIn this way, you can scale the number of instances up to the number of the\n                    partitions until each instance is consuming messages from only one\n                partition. This configuration maximizes your stream's available throughput. After\n                that point, any new instance joining the group remains in an idle state without\n                being assigned to any partition.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Translating Text with the Console service, \n Translate your input text into one of the target supported languages.\n\nOpen the navigation menu and click Analytics & AI.\n                    Under AI Services, click\n                    Language.\n\nClick Text translation or Start\n                        translation on the overview page.\n\nChoose source and target languages:\n\nSource language\nTarget language\n\n\nPaste, or enter your text into the source language dialog box.\n\nClick Translate.\n\nThe results are displayed in the target dialog box. Use Reset to start a new translation.\n Tip Use Copy to copy the translated text to your clipboard to use elsewhere.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n View Related Documentation, Use the Help menu to access documentation and support.\nThe listed documentation relates to the current Console page.\nOpen the \nHelp menu () and click the documentation link you want.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Block Volume, "
    },
    {
        "text": "oracle cloud infrastructure, oci,  Pulse service, \n Oracle Pulse is a monitoring service for administrators to track Oracle Cloud service performance in areas of availability, storage, incident management, and change management across environments."
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n Post a Question to Oracle Forums, \nIf you cannot find an answer to your question through search, submit a new question to\n            one of the forums that Oracle supports. This option is available to all customers.\nCloud Customer Connect\nFor any issue related to Oracle Cloud Infrastructure, including provisioning of new resources, Console issues, identity, networking, documentation, storage, database, Edge services, or other solutions, you can post a question to Cloud Customer Connect at:\nhttps://community.oracle.com/customerconnect/categories/oracle-cloud-infrastructure-and-platform\nIf you are using only Always Free resources or using a Free Tier account, then use\n                Cloud Customer Connect for support queries.\n\nStack Overflow\nIf you are creating an application that integrates with Oracle Cloud Infrastructure APIs, endpoints, or services, then you\n                can also use Stack Overflow forums for development-related questions. Tag your\n                questions with oracle-cloud-infrastructure, as\n                follows:\nhttps://stackoverflow.com/questions/tagged/oracle-cloud-infrastructure\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Updating API Gateways and API Deployments service, \n Using the CLI, \nTo update existing API gateways and API deployments using the CLI:\n\nConfigure your client environment to use the CLI (Configuring Your Client Environment to use the CLI for API Gateway Development).\n\nTo update an existing API\u00c2\u00a0gateway: \n\n\nOpen a command prompt and run oci api-gateway gateway update  to update the API\u00c2\u00a0gateway:oci api-gateway gateway update --gateway-id <gateway-ocid> --<property-to-update> <property-value>\nwhere:\n\n<gateway-ocid> is the OCID of the API gateway to update. To find out the API gateway's OCID, see Listing API Gateways and API Deployments.\n<property-to-update> is the property to update. Note that you can only change the values for display-name, --response-cache-details, --network-security-group-ids, --ca-bundles, freeform-tags and defined-tags (and certificate-id> if this was originally set for the API gateway). All other values must be identical to values in the original gateway definition.\n<property-value> is the new value of the property you want to change.\nFor example:oci api-gateway gateway update --gateway-id ocid1.apigateway.oc1..aaaaaaaab______hga --display-name \"Hello World Gateway - version 2\"\nThe response to the command includes:\n\nThe lifecycle state (for example, ACTIVE, FAILED).\nThe id of the work request to update the API gateway (details of work requests are available for seven days after completion, cancellation, or failure).\nIf you want the command to wait to return control until the API gateway is active (or the request has failed), include either or both the following parameters:\n\n--wait-for-state ACTIVE\n\n--wait-for-state FAILED\n\nFor example:oci api-gateway gateway update --gateway-id ocid1.apigateway.oc1..aaaaaaaab______hga --display-name \"Hello World Gateway - version 2\" --wait-for-state ACTIVE\n\n\n(Optional)\u00c2\u00a0To see the status of the work request that is updating the API\u00c2\u00a0gateway, enter:oci api-gateway work-request get --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0To view the logs  of the work request that is updating the API\u00c2\u00a0gateway, enter:oci api-gateway work-request-log list --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0If the work request that is updating the API\u00c2\u00a0gateway fails and you want to review the error logs, enter:oci api-gateway work-request-error --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0\u00c2\u00a0To verify that the API\u00c2\u00a0gateway has been updated, enter the following command and confirm that the API\u00c2\u00a0gateway's properties are as you expect:oci api-gateway gateway get --gateway-id <gateway-ocid>\n\n\n\nTo update an existing API\u00c2\u00a0deployment:\n\n\nOpen a command prompt and run oci api-gateway deployment update  to update the API deployment:oci api-gateway deployment update --deployment-id <deployment-ocid> --specification file:///<filename>\nwhere:\n\n<deployment-ocid> is the OCID of the API deployment to update. To find out the API deployment's OCID, see Listing API Gateways and API Deployments.\n<filename> is the relative location and filename of the JSON\u00c2\u00a0file containing the replacement  API deployment specification. For example, replacement-specification.json. For more information about defining API deployment specifications, see Creating an API Deployment Specification.\nFor example:oci api-gateway deployment update --deployment-id ocid1.apideployment.oc1..aaaaaaaaab______pwa --specification file:///Users/jdoe/work/replacement-specification.json\nThe response to the command includes:\n\nThe lifecycle state (for example, ACTIVE, FAILED).\nThe id of the work request to update the API deployment (details of work requests are available for seven days after completion, cancellation, or failure).\nIf you want the command to wait to return control until the API deployment is active (or the request has failed), include either or both the following parameters:\n\n--wait-for-state ACTIVE\n\n--wait-for-state FAILED\n\nFor example:oci api-gateway deployment update --deployment-id ocid1.apideployment.oc1..aaaaaaaaab______pwa --specification file:///Users/jdoe/work/replacement-specification.json --wait-for-state ACTIVE\n\n\n(Optional)\u00c2\u00a0To see the status of the work request that is updating the API\u00c2\u00a0deployment, enter:oci api-gateway work-request get --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0To view the logs  of the work request that is updating the API\u00c2\u00a0deployment, enter:oci api-gateway work-request-log list --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0If the work request that is updating the API\u00c2\u00a0deployment fails and you want to review the error logs, enter:oci api-gateway work-request-error --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0\u00c2\u00a0To verify that the API\u00c2\u00a0deployment has been updated, enter the following command and confirm that the API\u00c2\u00a0deployment's properties are as you expect:oci api-gateway deployment get --deployment-id <deployment-ocid>\n\n\n\nFor more information about using the CLI, see Command Line Interface (CLI). For a complete list of flags and options available for CLI commands, see CLI\u00c2\u00a0Help.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n \nOracle Cloud Infrastructure (OCI) Cloud Shell is a web browser-based terminal accessible from the Oracle Cloud Console. Cloud Shell is free to use (within monthly tenancy limits), and provides access to a Linux shell, with a pre-authenticated Oracle Cloud Infrastructure CLI, a pre-authenticated Ansible installation, and other useful tools for following Oracle Cloud Infrastructure service tutorials and labs. Cloud Shell is a feature available to all OCI users, accessible from the Console. Your Cloud Shell will appear in the Oracle Cloud Console as a persistent frame of the Console, and will stay active as you navigate to different pages of the Console.\nCloud Shell provides:\n\n\nAn ephemeral machine to use as a host for a Linux shell, pre-configured with the latest version of the OCI\u00c2\u00a0Command Line Interface (CLI)\u00c2\u00a0and a number of useful tools\n\n\n5GB of storage for your home directory\n\n\nA persistent frame of the Console which stays active as you navigate to different pages of the console\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n How Cloud Shell Works, \nThe Cloud Shell machine is a small virtual machine running a Bash shell which you access through the OCI Console. Cloud Shell comes with a pre-authenticated OCI CLI, set to the Console tenancy home page region, as well as up-to-date tools and utilities. \nCloud Shell comes with 5GB of persistent storage for the home directory, so you can make local changes to your home directory, and then continue working on your project when you come back to Cloud Shell.\nCloud Shell is free to use (within your tenancy's monthly limits) and doesn\u00e2\u0080\u0099t require any setup or prerequisites other than an IAM policy granting access to Cloud Shell. Your Cloud Shell includes a VM provisioned for you that executes in its own tenancy (so it doesn't use any of your tenancy's resources)\u00c2\u00a0and hosts your shell in an Oracle Linux OS while you\u00e2\u0080\u0099re actively using Cloud Shell. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Queue Policies service, \n Use the Oracle Cloud Infrastructure Identity and Access Management (IAM) service to create policies\u00c2\u00a0 for your queues.\nThis topic covers details for writing policies to control access to the Queue service.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, \n\n Database Tools service, \n Oracle Cloud Infrastructure Database Tools enables you to create connections \n                to any Oracle or MySQL database service in OCI."
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Required IAM Policy, \nTo get started with Cloud Shell, you\u00e2\u0080\u0099ll need to grant user access to Cloud Shell via an IAM policy. Each service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nTo use Oracle Cloud Infrastructure, you must be given the required type of access in a policy written by an administrator in the tenancy's root compartment, whether you're using the Console or the REST API with an SDK, CLI, or other tool. If you try to perform an action and get a message that you don\u00e2\u0080\u0099t have permission or are unauthorized, confirm with your administrator that you've been granted access.\n Note  Cloud Shell does not support policies at the compartment level, only at the\n                tenancy level.The resource name for Cloud Shell is `cloud-shell`. The\n            following is an example policy to grant access to Cloud Shell:\nallow group <GROUP-NAME> to use cloud-shell in tenancy\n\nThis example policy shows how to allow a group within a domain to use Cloud\n            Shell:allow group <DOMAIN-NAME>/<GROUP-NAME> to use cloud-shell in tenancy\nIf you're new to policies, see Getting Started with Policies and Common Policies.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Performing a Diagnostic Reboot service, \n Using the CLI, \nOpen a command prompt and run the instance action command:\noci compute instance action --action DIAGNOSTICREBOOT --instance-id <INSTANCE_OCID>\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Required IAM Policy, \nTo get started with Cloud Shell, you\u00e2\u0080\u0099ll need to grant user access to Cloud Shell via an IAM policy. Each service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nTo use Oracle Cloud Infrastructure, you must be given the required type of access in a policy written by an administrator in the tenancy's root compartment, whether you're using the Console or the REST API with an SDK, CLI, or other tool. If you try to perform an action and get a message that you don\u00e2\u0080\u0099t have permission or are unauthorized, confirm with your administrator that you've been granted access.\n Note  Cloud Shell does not support policies at the compartment level, only at the\n                tenancy level.The resource name for Cloud Shell is `cloud-shell`. The\n            following is an example policy to grant access to Cloud Shell:\nallow group <GROUP-NAME> to use cloud-shell in tenancy\n\nThis example policy shows how to allow a group within a domain to use Cloud\n            Shell:allow group <DOMAIN-NAME>/<GROUP-NAME> to use cloud-shell in tenancy\nIf you're new to policies, see Getting Started with Policies and Common Policies.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n Post a Question to Oracle Forums, \nIf you cannot find an answer to your question through search, submit a new question to\n            one of the forums that Oracle supports. This option is available to all customers.\nCloud Customer Connect\nFor any issue related to Oracle Cloud Infrastructure, including provisioning of new resources, Console issues, identity, networking, documentation, storage, database, Edge services, or other solutions, you can post a question to Cloud Customer Connect at:\nhttps://community.oracle.com/customerconnect/categories/oracle-cloud-infrastructure-and-platform\nIf you are using only Always Free resources or using a Free Tier account, then use\n                Cloud Customer Connect for support queries.\n\nStack Overflow\nIf you are creating an application that integrates with Oracle Cloud Infrastructure APIs, endpoints, or services, then you\n                can also use Stack Overflow forums for development-related questions. Tag your\n                questions with oracle-cloud-infrastructure, as\n                follows:\nhttps://stackoverflow.com/questions/tagged/oracle-cloud-infrastructure\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cost and Usage Reports Overview service, \n Authentication and Authorization, \n\nEach service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nAn administrator in your organization needs to set up groups\u00c2\u00a0, compartments\u00c2\u00a0, and policies\u00c2\u00a0 that control which users can access which services, which resources, and the type of access. For example, the policies control who can create new users, create and manage the cloud network, launch instances,  create buckets, download objects, etc. For more information, see Getting Started with Policies. For specific details about writing policies for each of the different services, see Policy Reference. \nIf you\u00e2\u0080\u0099re a regular user (not an administrator) who needs to use the Oracle Cloud Infrastructure resources that your company owns, contact your administrator to set up a user ID for you. The administrator can confirm which compartment or compartments you should be using.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Services that Produce Events service, \n IAM, \nIAM resources that emit events:\n\n\nAuthentication Policy Event Types\n\n\nCredentials Event Types\n\n\nDynamic Group Event Types\n\n\nGroup Event Types\n\n\nIdentity Provider Event Types\n\n\nMulti-Factor Authentication TOTP\u00c2\u00a0Device Event Types\n\n\nPolicy Event Types\n\n\nUser Event Types\n\n\nAuthentication Policy Event Types\nThis is the event type that authentication policies emit:\n\n\nFriendly Name\nEvent Type\n\n\n\nUpdate Authentication Policy \ncom.oraclecloud.identityControlPlane.UpdateAuthenticationPolicy\n\n\n\nAuthentication Policy Example\n\nThis is a reference event for authentication policy events:\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.UpdateAuthenticationPolicy\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_compartment\",\n    \"resourceId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nCredentials  Event Types\nThese are the event types that credentials emit. \n\n\nFriendly Name\nEvent Type\n\n\n\n Create\nAuth Token\ncom.oraclecloud.identityControlPlane.CreateAuthToken\n\n\n\nCreate\nCustomer Secret Key \ncom.oraclecloud.identityControlPlane.CreateCustomerSecretKey\n\n\n\nCreate or Reset\nPassword\n\n\ncom.oraclecloud.identityControlPlane.CreateOrResetPassword\n\n\n\nCreate\nSMTP Credential \n\ncom.oraclecloud.identityControlPlane.CreateSmtpCredential\n\n\n\n Create\nSwift Password\n\ncom.oraclecloud.identityControlPlane.CreateSwiftPassword\n\n\n\n DeleteAPI Key\ncom.oraclecloud.identityControlPlane.DeleteApiKey\n\n\n\n Delete\n Auth Token\ncom.oraclecloud.identityControlPlane.DeleteAuthToken\n\n\n\n Delete\nCustomer Secret Key\ncom.oraclecloud.identityControlPlane.DeleteCustomerSecretKey\n\n\n\nDelete\nSMTP Credential \n\ncom.oraclecloud.identityControlPlane.DeleteSmtpCredential\n\n\n\nDelete\nSwift Password \n\ncom.oraclecloud.identityControlPlane.DeleteSwiftPassword\n\n\n\n Update\nAuth Token\ncom.oraclecloud.identityControlPlane.UpdateAuthToken\n\n\n\nUpdate\nAuthentication Policy \ncom.oraclecloud.identityControlPlane.UpdateAuthenticationPolicy\n\n\n\nUpdate\nCustomer Secret Key  \n\ncom.oraclecloud.identityControlPlane.UpdateCustomerSecretKey\n\n\n\nUpdate\nSMTP Credential \n\ncom.oraclecloud.identityControlPlane.UpdateSmtpCredential\n\n\n\nUpdateSwift Password \ncom.oraclecloud.identityControlPlane.UpdateSwiftPassword\n\n\n\n Upload\nAPI KEY\ncom.oraclecloud.identityControlPlane.UploadApiKey\n\n\n\nCredentials Example\n\nThis is a reference event for most credential events (create or reset password don't include additional details):\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.DeleteApiKey\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_user\",\n    \"resourceId\": \"<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    },\n    \"additionalDetails\": {\n      \"userId\": \"ocid1.user.oc1..<unique_ID>\"\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nDynamic Group Event Types\nThese are the event types that dynamic groups emit. \n\n\nFriendly Name\nEvent Type\n\n\n\nCreate Dynamic Group\n\ncom.oraclecloud.identityControlPlane.CreateDynamicGroup\n\n\n\n Delete\nDynamic Group\ncom.oraclecloud.identityControlPlane.DeleteDynamicGroup\n\n\n\n Update Dynamic Group\ncom.oraclecloud.identityControlPlane.UpdateDynamicGroup\n\n\n\nDynamic Group Example\n\nThis is a reference event for dynamic groups:\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.CreateDynamicGroup\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_dynamicgroup\",\n    \"resourceId\": \"ocid1.dynamicgroup.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nGroup Event Types\nThese are the event types that groups emit. \n\n\nFriendly Name\nEvent Type\n\n\n\nAdd User to Group\ncom.oraclecloud.identityControlPlane.AddUserToGroup\n\n\n\n\nCreate Group\n\ncom.oraclecloud.identityControlPlane.CreateGroup\n\n\n\n\nDelete Group\n\ncom.oraclecloud.identityControlPlane.DeleteGroup\n\n\n\nRemove User From Group\n\ncom.oraclecloud.identityControlPlane.RemoveUserFromGroup\n\n\n\nUpdate Group\ncom.oraclecloud.identityControlPlane.UpdateGroup\n\n\n\nGroup Example\n\nThis is a reference event for some groups (create, delete, and update events don't include additional details):\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.AddUserToGroup\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_group\",\n    \"resourceId\": \"ocid1.groupmembership.oc1.<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    },\n    \"additionalDetails\": {\n      \"userId\": \"ocid1.user.oc1..<unique_ID>\",\n      \"groupId\": \"ocid1.group.oc1..<unique_ID>\"\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nIdentity Provider Event Types\nThese are the event types that identity providers emit. \n\n\nFriendly Name\nEvent Type\n\n\n\n Add User to IdP Group\ncom.oraclecloud.identityControlPlane.AddUserToIdpGroup\n\n\n\n\nCreate Identity Provider \ncom.oraclecloud.identityControlPlane.CreateIdentityProvider\n\n\n\n\nCreate Identity Provider Group\n\n\ncom.oraclecloud.identityControlPlane.CreateIdentityProviderGroup\n\n\n\n\nCreate IdP Group Mapping \n\ncom.oraclecloud.identityControlPlane.CreateIdpGroupMapping\n\n\n\n\nCreate IdP User\n\n\ncom.oraclecloud.identityControlPlane.CreateIdpUser\n\n\n\nDelete Identity Provider\n\ncom.oraclecloud.identityControlPlane.DeleteIdentityProvider\n\n\n\nDelete Identity Provider Group\ncom.oraclecloud.identityControlPlane.DeleteIdentityProviderGroup\n\n\n\nDelete IdP Group Mapping\ncom.oraclecloud.identityControlPlane.DeleteIdpGroupMapping\n\n\n\nDelete IdP User\n\ncom.oraclecloud.identityControlPlane.DeleteIdpUser\n\n\n\n\nRemove User From IdP Group\n\ncom.oraclecloud.identityControlPlane.RemoveUserFromIdpGroup\n\n\n\nReset IdP SCIM Client\ncom.oraclecloud.identityControlPlane.ResetIdpScimClient\n\n\n\n\nUpdate Identity Provider\ncom.oraclecloud.identityControlPlane.UpdateIdentityProvider\n\n\n\n\n\nUpdate IdP Group Mapping\n\ncom.oraclecloud.identityControlPlane.UpdateIdpGroupMapping\n\n\n\n\nIdentity Provider Example\n\nThe following reference events are for identity provider events that include additional details. Some identity providers events do not include additional details. These events are create, delete, and update identity providers, as well as delete identity provider group, delete IdP user, and reset IdP\u00c2\u00a0SCIM. \nThis is a reference event for adding and removing users from IdP groups:\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.AddUserToIdpGroup\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_group\",\n    \"resourceId\": \"ocid1.idpgroup.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    },\n    \"additionalDetails\": {\n      \"userId\": \"ocid1.user.oc1..<unique_ID>\"\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\nThis is a reference event for create, update, and delete IdP group mapping:\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.CreateIdpGroupMapping\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_identityprovider\",\n    \"resourceId\": \"ocid1.idpgroupmapping.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    },\n    \"additionalDetails\": {\n      \"idpGroupName\": \"my_group\",\n      \"groupId\": \"ocid1.group.oc1..<unique_ID>\"\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\nThis is a reference event for create IdP user and create IdP group:\u00c2\u00a0\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.CreateIdentityProviderGroup\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_idpgroup\",\n    \"resourceId\": \"ocid1.idpgroup.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    },\n    \"additionalDetails\": {\n      \"externalIdentifier\": \"my_externalidentifier\"\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nMulti-Factor Authentication TOTP\u00c2\u00a0Device Event Types\nThese are the event types that MFA TOTP\u00c2\u00a0devices emit. \n\n\nFriendly Name\nEvent Type\n\n\n\nActivate MFA\u00c2\u00a0TOTP\u00c2\u00a0Device\ncom.oraclecloud.identityControlPlane.ActivateMfaTotpDevice\n\n\n\n\nCreate MFA\u00c2\u00a0TOTP\u00c2\u00a0Device\ncom.oraclecloud.identityControlPlane.CreateMfaTotpDevice\n\n\n\n\nDelete MFA\u00c2\u00a0TOTP\u00c2\u00a0Device\ncom.oraclecloud.identityControlPlane.DeleteMfaTotpDevice\n\n\n\n\nGenerate MFA\u00c2\u00a0TOTP\u00c2\u00a0Device Seed\ncom.oraclecloud.identityControlPlane.GenerateTotpSeed\n\n\n\n\nMulti-Factor Authentication TOTP\u00c2\u00a0Devices Example\n\nThis is a reference event for MFA TOTP\u00c2\u00a0Devices:\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.CreateMfaTotpDevice\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_user\",\n    \"resourceId\": \"ocid1.credential.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    },\n    \"additionalDetails\": {\n      \"userId\": \"ocid1.user.oc1..<unique_ID>\"\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nPolicy Event Types\nThese are the event types that policies emit. \n\n\nFriendly Name\nEvent Type\n\n\n\nCreate Policy\ncom.oraclecloud.identityControlPlane.CreatePolicy\n\n\n\n\nDelete Policy\ncom.oraclecloud.identityControlPlane.DeletePolicy\n\n\n\n\nUpdate Policy\ncom.oraclecloud.identityControlPlane.UpdatePolicy\n\n\n\n\nPolicy Example\n\nThis is a reference event for policies:\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.CreatePolicy\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_policy\",\n    \"resourceId\": \"ocid1.policy.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n}\n\nUser Event Types\nThese are the event types that users emit. \n\n\nFriendly Name\nEvent Type\n\n\n\nCreate User\ncom.oraclecloud.identityControlPlane.CreateUser\n\n\n\nDelete User\ncom.oraclecloud.identityControlPlane.DeleteUser\n\n\n\nUpdate User\ncom.oraclecloud.identityControlPlane.UpdateUser\n\n\n\nUpdate User Capabilities\ncom.oraclecloud.identityControlPlane.UpdateUserCapabilities\n\n\n\nUpdate User State\ncom.oraclecloud.identityControlPlane.UpdateUserState\n\n\n\nUser Example\n\nThis is a reference event for users:\n{\n  \"eventType\": \"com.oraclecloud.identityControlPlane.CreateUser\",\n  \"cloudEventsVersion\": \"0.1\",\n  \"eventTypeVersion\": \"2.0\",\n  \"source\": \"identityControlPlane\",\n  \"eventID\": \"<unique_ID>\",\n  \"eventTime\": \"2019-10-21T17:23:54.095Z\",\n  \"contentType\": \"application/json\",\n  \"data\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\",\n    \"compartmentName\": \"example_name\",\n    \"resourceName\": \"my_user\",\n    \"resourceId\": \"ocid1.user.oc1..<unique_ID>\",\n    \"availabilityDomain\": \"availability_domain\",\n    \"freeFormTags\": {\n      \"Department\": \"Finance\"\n    },\n    \"definedTags\": {\n      \"Operations\": {\n        \"CostCenter\": \"42\"\n      }\n    }\n  },\n  \"extensions\": {\n    \"compartmentId\": \"ocid1.compartment.oc1..<unique_ID>\"\n  }\n }\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n What's Included With Cloud Shell, \nIn addition to the OCI CLI, the Cloud Shell VM\u00c2\u00a0comes with current versions of many useful\n            tools and utilities pre-installed, including:\n\nGit\nJava\nPython (2 and 3)\nGraalVM Enterprise JDK 17 and Native Image\nSQL Plus\nkubectl\nhelm\nmaven\ngradle\nterraform\nansible\nnode.js\niputils\njqmake\ntmux\nvim\nNPM\nwget\nzip/unzip\nnano\nemacs\npip\nbash\nsh\ntar\nnvm\nmysql-community-client\nDocker engine\nipython\noci-powershell-modules\nGoldenGate Admin client\nMost OCI SDKs, including:\nJava\nPython\nGo\nTypeScript and JavaScript\nRuby\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Approving an Access Request service, \n Describes how to approve an access request."
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n \n When using Oracle Cloud Infrastructure, sometimes you need to get help from the community or to talk to someone in Oracle support. This topic provides more information about accessing these tools.\n Tip Console announcements appear at the top of the Console to communicate\n            timely, important information about service status. For more information, see Console\n            Announcements.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell Private Networking, \n Cloud Shell Private Networking allows you to connect a Cloud Shell session to a private\n            network so you can access resources in your private network without having the network\n            traffic flow over public networks. Examples of where Private Networking can be useful\n            include using it to SSH into compute instances inside of a private network or managing a\n            private OKE cluster.\n Note A Cloud Shell instance is a private instance, and works like a private instance for the purposes of network setup. Using only an internet gateway will not allow egress to the internet from a private subnet. Using a service gateway or a NAT gateway will. For more information, see the Internet Gateway documentation.\nRequirements and IAM Policy\nTo use Private Networking, you (or an administrator) will need to specify the\n                following policies:\n\n\nallow group <group> to use subnets in compartment <compartment>\n\n\nallow group <group> to use vnics in compartment <compartment>\n\n\nallow group <group> to use network-security-groups in compartment <compartment>\n\n\nallow group <group> to inspect vcns in compartment <compartment>\n\n\nIf you're new to policies, see Getting Started with Policies and Common Policies.\nYou'll also need to create private VCNs and Subnets in the appropriate compartments.\n                For more information, see VCNs and Subnets in\n                the Networking\n                documentation. \n\nGetting Started with Private NetworkingTo\n            change which network your Cloud Shell session is using, use the drop-down Network\n            menu at the top of the Cloud Shell terminal window:From this menu you can select a favorite private network connection.\n                To see more options, you can select the Private Network Definition List item,\n                which will display the Private Network Definition List panel. This\n                panel allows you to select additional private networks, and also designate favorite\n                private networks for quick selection (you can have up to 5 favorites):\nCreate a new private network definitionYou can create a\n                new private network definition by clicking the Create private network\n                    definition button. This will bring up the Create Private Network\n                    Definition panel.  Note To create a temporary\n                    ephemeral network, select Ephemeral Private Network Setup from the\n                    network selection drop-down. This is temporary network is only valid for the\n                    length of your Cloud Shell session, and will not be persisted to your list of\n                    defined private networks.Enter a name for your private network\n                definition in the Name text box. Select the VCN and the Subnet to use from the drop-down list boxes. You can also\n                optionally select one or more Network Security groups to use.  Note Only VCNs and Subnets in your home region are available.\n                    If you need to access a subnet in a region that is not your home region, you can\n                    use peering from the subnet used by Private Networking to reach it. For more\n                    information, see VCN Cross-Region Peering.  Note A subnet chosen for a Cloudshell Private Network\n                            must have at least one non-reserved IP address for the subnet's CIDR\n                            block available. If all non-reserved IP addresses have been allocated,\n                            Cloudshell cannot attach to that subnet.For example: If you want to set this definition as the active network,\n                enable the Use as network checkbox.Click the Create button to\n                create your Cloud Shell private network definition.Your Cloud Shell session\n                is now connected to your private network, as indicated in the Networking\n                drop-down at the top of the Cloud Shell terminal session:You can see details about your private network connection by clicking\n                the Details link:\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Get Started with Data Catalog service, \n 1. Create an Admin User Group, A new user has no permissions until you place the user in one or more groups and\n        create at least one policy to give that group permission to either the tenancy or\n        compartment. \n\nTo create a user group and add users to this group, perform the following steps:\n\n\nOpen a supported browser and enter the Console URL (https://cloud.oracle.com).\nTo log on to a specific region, add the region in the URL. For example, https://cloud.oracle.com/?region=us-ashburn-1. For information about the Data Catalog supported\n                    regions, see regions.\n\nEnter your cloud tenancy and click Continue.\n\nSign in with your credentials.\n\nOpen\n                the navigation menu and click Identity & Security. Under\n                    Identity, click Groups.\n\nIn the Groups page, click Create\n                        Group.\n\nIn the Create Group panel, enter the following details:\n\n\n\nField\nDescription\n\n\n\nName\nEnter a unique name for the group. The name must be\n                                        unique across all groups in your tenancy. You cannot change\n                                        the name later. The name must be 1\u00e2\u0080\u0093100 characters long and\n                                        can include the following characters: lowercase letters a-z,\n                                        uppercase letters A-Z, 0\u00e2\u0080\u00939, and the period (.), dash (-),\n                                        and underscore (_). Spaces are not allowed. For example,\n                                            data-catalog-admins. Note Avoid entering\n                                            confidential information. \n\n\nDescription\nEnter a friendly description. For example, Group of\n                                            data catalog admin users. You can change the\n                                        description later. \n\n\nShow Advanced Options\nClick this link to view the advanced options. The\n                                        available option is:\nTags: If you have permissions to create a resource,\n                                                then you also have permissions to apply free-form\n                                                tags to that resource. To apply a defined tag, you\n                                                must have permissions to use the tag namespace. If\n                                                you are not sure whether to apply tags, skip this\n                                                option (you can apply tags later) or ask your\n                                                administrator.\n\n\n\n\n\nClick Create.\n\n Note To add a user to the group, follow these steps:\nOn the Groups page, click the group that you\n                                created.\nIn the Group Details page, click\n                                    Add User to Group. \nIn the Add User to Group dialog box, select\n                                the user that you want to add, and then click Add.\n\n\n\nYou have successfully created a group for data catalog admin users and added users\n            to this group.\nData Catalog is used by various data professionals, such\n            as data engineers, data scientists, data stewards, and chief data officers. Each type of\n            user requires the permissions to perform tasks. You can create different groups for each\n            type of user (such as a group for all data catalog users) to manage these permissions\n            effectively. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Some Common Features service, \n Overview of Recipes, Understand the differences between Oracle-managed and user-managed recipes, how\n    user-managed recipes work, and what settings can be changed at the recipe and target\n    levels.\nThe three sections below also appear in About OCI Responder Recipes and About Detector Recipes.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Full Stack Disaster Recovery, \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Setting Up Certificate Authentication service, \n Learn how to set up certificate authentication and Vault secrets to use for network\n    traffic decryption.\nIf you want to use decryption rules, you must set up mapped secrets to use in a decryption\n      profile. A mapped secret is a secret that you create in Oracle Cloud Infrastructure Vault and then map to an inbound or outbound SSL\n      key. The secrets are used to decrypt and inspect SSL/TLS traffic with SSL Forward Proxy or SSL Inbound Inspection. \nSee Mapped Secrets and Decryption Profiles for more information about how the certificate is used with a policy. Important\n\nIf you plan on using SSL forward proxy or SSL inbound inspection, set up your Oracle Cloud Infrastructure Vault and secrets before you begin creating your policy.\nOnly one SSL forward proxy secret is allowed for each policy.\n\n\nTask 1: Allow the Network Firewall service to access Vault secrets\nCreate an IAM policy that allows the Network Firewall service to access and use your Vault secrets:allow service ngfw-sp-prod to read secret-family in compartment <compartment_name>  Warning If this permission is revoked at any point in the future, the service can't access your mapped secret, and the firewall stops decrypting traffic.\n\nTask 2: Create a vault and master key to store the certificate\n\n\nEnsure you have an IAM policy that lets\n            you create vaults, keys, and secrets in the Vault service. For\n            example:Allow group SecurityAdmins to manage vaults in tenancy\n\nAllow group SecurityAdmins to manage keys in tenancy\n\nAllow group SecurityAdmins to manage secret-family in tenancy For more\n            information, see IAM Details for the Vault\n              Service.\nCreate a vault to store the certificate in. \nCreate a master encryption key in the\n              vault. Important The master key must be a symmetric key. You cannot\n              encrypt secrets with asymmetric keys.\n\n\n\nTask 3: Store the certificate\nYou can use a self-signed or ca-signed certificate with OCI Network Firewall Service.\nOracle provides a script that you can use to generate a self-signed certificate.  Important\n\n\nThe Network Firewall service validates the provided certificate and stores it in the trustroot. To successfully validate the certificate, you must provide the entire SSL certificate chain (including the intermediate certificates root certficate and private key). Upload certificates in .pem format which are wrapped in the following  .json template.\n\nIf the leaf certificate specified in the \"certKeyPair\" is a forward-trust certificate, then it should have Certificate Authority Signing capability. Set the CA flag to \"true\". \nIn this example, if \"LEAF_CERT_01_PEM_CONTENT\" is a forward-trust certificate, its CA flag must be set to \"true\". {\n  \"caCertOrderedList\" : [\n    \"ROOT_CERT01_PEM_CONTENT\",\n    \"INTERMEDIATE_CERT01_PEM_CONTENT\",\n    \"INTERMEDIATE_CERT02_PEM_CONTENT\",\n  ],\n  \"certKeyPair\": {\n    \"cert\" : \"LEAF_CERT_01_PEM_CONTENT\",\n    \"key\":   \"PRIVATE_KEY_01_PEM_CONTENT\"\n  }\n}\n\n\n\n\nIf you want to use a self-signed OpenSSL certificate, you can use an Oracle provided script\n        to create one:\nDownload and install OpenSSL.\nDownload and install Perl.\nDownload the script from the Oracle GitHub repository.\nRun the script using the following command. Replace <test.test.com> with the DNS name of the webserver you need to protect: ./create-certificate inbound <test.test.com> or ./create-certificate forward <test.test.com>\n\n\nTask 4: Create secrets in the vault\nCreate a secret in the vault for each certificate you want to use.\n\nOpen the navigation menu, click Identity & Security, and then click Vault.\nUnder List Scope, in the Compartment list, click the name of the compartment where you want to create a secret.\n\nChoose the vault you created in Task 2: Create a vault and master key to store the certificate.\n\nClick Secrets, and then click Create Secret.\nIn the Create Secret dialog box, choose a compartment from the Create in Compartment list. (Secrets can exist outside the compartment the vault is in.)\nClick Name, and then enter a name to identify the secret. Use a name that corresponds to the type of certificate the secret contains. For example, \"ssl-inbound-inspection-certificate\".\nClick Description, and then enter a brief description of the secret to help identify it.\nChoose the master encryption key you created in Task 2: Create a vault and master key to store the certificate.\nSpecify the format of the secret contents as Plain-Text.\nClick Secret Contents, and then copy the certificate contents into the field. (The maximum allowable size for a secret bundle is 25 KB.)\nWhen you are finished, click Create Secret.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n \n When using Oracle Cloud Infrastructure, sometimes you need to get help from the community or to talk to someone in Oracle support. This topic provides more information about accessing these tools.\n Tip Console announcements appear at the top of the Console to communicate\n            timely, important information about service status. For more information, see Console\n            Announcements.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating Functions from Existing Docker Images service, \n Using Fn Project CLI Commands, \n Tip From time to time, new versions of the Fn Project CLI are released. We recommend you regularly check that the latest version is installed. For more information, see Steps to upgrade the Fn Project CLI.\nTo  use the Fn Project CLI to create a new function in the OCI Functions server from an existing Docker image that has already been pushed to the Docker registry:\n\n\nLog in to your development environment as a functions developer.\n\n\nIn a terminal window, create a new function by entering:fn create function <app-name> <function-name> <image-name>\nwhere:\n\n<app-name> is the name of an existing application in which  to create the new function.\n<function-name> is the name of the new function you want to create. Avoid entering confidential information.\n<image-name> is the name of the existing image in the Docker registry on which to base the new function. \nFor example:fn create function acmeapp acme-func phx.ocir.io/ansh81vru1zp/acme-repo/acme-func:0.0.3\nA new function  is created in OCI Functions, based on the existing image and with the name you specified\n\n\nVerify that the new function has been created by entering:fn list functions <app-name>\nFor example:$ fn list functions acme-app\n\nNAME            IMAGE\nacme-func       phx.ocir.io/ansh81vru1zp/acme-repo/acme-func:0.0.3\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Streaming Metrics service, \n Using the API, \n\nFor information about using the API and signing requests, see REST API documentation and Security Credentials. For information about SDKs, see SDKs and the CLI.\n\nUse the following APIs for monitoring:\nMonitoring API for metrics and alarms \nNotifications API for notifications (used with alarms)\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Tags service, \n Tagging Data Assets, \n\nHere\u00e2\u0080\u0099s how you tag data assets:\n\n\nOn the Home tab of a data catalog, click Data\n                    Assets.\n\nOn the Data Assets page, click the data asset that you\n                    want to tag.\n\nOn the data asset details page, under the Summary tab,\n                    click Tags.\n\nEnter the keywords with which you want to tag the data asset. You can also\n                    select from the list of existing tags. \n\n Note To remove a tag, click the remove icon next to the tag.\n\n\nThe updates to the tags are saved automatically.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Data Catalog Metastore service, \n Viewing the Details of a Metastore, \n\nHere's how you can view the details of the metastore that you created:\n\n\nOn the Data Catalog service page, click Metastores.\n\nClick the name of the metastore. Alternatively, click the Actions menu for the metastore and select View Details. The metastore details page appears. \n\nThe metastore details page displays the following details:\nMetastore Information tab: This tab provides the following information:\nName of the metastore\nOCID of the metastore - Click Show to view the URL and click Copy to copy it.  Note You can also copy the OCID from the Metastores main page. On the Metastores page, click the the Actions menu for the metastore and select Copy OCID. \nThe compartment in which the metastore is created\nThe URL of the default external table location - Click Show to view the URL and click Copy to copy it.\nThe Compartment OCID - Click Show to view the URL and click Copy to copy it.\nThe date and time the metastore is created.\nThe date and time the metastore is updated.\nThe URL of the default managed table location - Click Show to view the URL and click Copy to copy it.\n\nTags tab: This tabs provides information about the tags that you defined while creating the metastore.\n\n\n\n\nOn this page, you can also perform the following:\nEdit the name of the metastore.\nMove the metastore to a different compartment.\nDelete the metastore.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Container Registry service, \n Container Registry Capabilities and Limits, \nIn each region that is enabled for your tenancy, you can create up to 500 repositories in Oracle Cloud Infrastructure Registry consuming a maximum of 500 GB in total (if you need more storage, Contact Us). Each repository can hold up to 100,000 images. See Container Registry Limits.\nYou are charged for stored images, as shown in the Cloud Price List.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Agent Management service, \n Selecting Target Hosts with Dynamic Groups, \nTo set up a configuration for multiple hosts, you can use the Dynamic Group\n            feature from IAM. The overall process first\n            involves creating a compartment, then placing all the instances in the compartment you\n            want to collect logs from. Next, you can create the Dynamic Group. The Dynamic Group\n            policy statement would then point to the compartment that contains the instances.\n            Lastly, create a log group, custom log, and its associated agent configuration.\nSet the following policy\n            statement:allow dynamic-group <dynamic_group_name> to use log-content in tenancy\nThis policy statement allows the agent configuration to push logs to the Logging service\n            backend, which you can later see in the Logging Service's Search\n            page.\nIn the Dynamic Groups configuration, set up your Dynamic Group to have a rule that\n            includes all the agents that you want to use to send logs to the Logging service. For\n            example, in a Rule inside the Dynamic Group it can state:\nANY {instance.id = 'ocid1.instance.<region>.<location>.<unique_ID>', \ninstance.compartment.id = 'ocid1.compartment.<region>..<unique_ID>'}\nIf you remove instance.id =\n                    'ocid1.instance.<region>.<location>.<unique_ID>'\n            and just\n            have:ANY {instance.compartment.id = 'ocid1.compartment.<region>..<unique_ID>'}\n            this means use all the instances under this compartment to send logs. For more\n            information on Dynamic Groups, see About Dynamic Groups.\nNext, create the log group (see To create a log group). After the log group is created, you can then create the custom log and the agent\n            configuration (see Creating Custom Logs for steps to create the\n            custom log and agent configuration). During the agent configuration, you can use the\n            Dynamic Group you created earlier and select it in the Choose Host\n                Groups section of the Agent Configurations panel.\n            This links the log configuration with the instance you want to send logs to. Once the\n            agent configuration is active, the logs you see are sent by the instance, inside the\n            Dynamic Group you earlier set up. You can later click Explore with Log\n                Search in the agent configuration to view the logs through the\n                Search page (see Searching Logs).\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Passing Tokens to Authorizer Functions to Add Authentication and Authorization to API Deployments service, \n \nYou can add authentication and authorization functionality to an API gateway by having the API gateway pass a multi-argument or single-argument access token included in a request to an authorizer function deployed on OCI Functions for validation (as described in this topic). Alternatively, you can have the API gateway itself validate the tokens included in a request (as described in Validating Tokens to Add Authentication and Authorization to API Deployments).\nYou can add authentication and authorization functionality to API\u00c2\u00a0gateways by writing an 'authorizer function' that: \n\nProcesses request attributes to verify the identity of an API client with an identity provider.\nDetermines the operations that the API client is allowed to perform.\nReturns the operations the API client is allowed to perform as a list of 'access scopes' (an 'access scope' is an arbitrary string used to determine access).\nOptionally returns a key-value pair for use by the API deployment. For example, as a context variable for use in an HTTP back end definition (see Adding Context Variables to Policies and HTTP Back End Definitions).\n\nDepending on the functionality you require, you can write:\n\n(Recommended) A multi-argument authorizer function that accepts a user-defined, multi-argument access token comprising one or more elements of a request (see Creating a Multi-Argument Authorizer Function (Recommended)). Note that multi-argument authorizer functions can accept single access tokens contained in a request header or query parameter.\nA single-argument authorizer function that accepts a single-argument access token comprising a single value contained in a request header or query parameter in a request (see Creating a Single-Argument Authorizer Function).\n\nUsing a multi-argument (rather than a single-argument) authorizer function enables an API gateway to perform finer-grained, request-based authentication. A multi-argument authorizer function can query decision services and policy agents with attributes from the access token and with other request elements such as query parameters, hostname, and subdomain. \n Note Oracle recommends the use of multi-argument authorizer functions rather than single-argument authorizer functions because of their additional versatility. Single-argument authorizer functions were provided in earlier releases, and continue to be supported. However, since multi-argument authorizer functions can also accept single-argument access tokens contained in request headers and query parameter, there is no reason to create new single-argument authorizer functions. Furthermore, single-argument authorizer functions are planned for deprecation in a future release.\nHaving written the authorizer function, you can then deploy it to OCI Functions (see Deploying an Authorizer Function). \nFor a related Developer Tutorial containing an example single-argument authorizer function, see Functions: Validate an API Key with API Gateway.\nHaving deployed the authorizer function, you enable authentication and authorization for an API\u00c2\u00a0deployment by including two different kinds of request policy in the API deployment specification:\n\nAn authentication request policy for the entire API deployment that specifies:\n                \nThe OCID of the authorizer function that you deployed to OCI Functions that will perform authentication and authorization.\nThe request attributes to pass to the authorizer function.\nWhether unauthenticated API clients can access routes in the API\u00c2\u00a0deployment.\nAn authorization request policy for each route that specifies the operations an API client is allowed to perform, based on the API client's access scopes as returned by the authorizer function.\n\nYou can add authentication and authorization request policies to an API deployment specification by:\n\nUsing the Console.\nEditing a JSON\u00c2\u00a0file.\n\n Tip\nTo help troubleshoot issues with the authorizer function, consider adding an\n                execution log to the API deployment, with its log level set to Info (see Adding Logging to API Deployments).\nTo see details in the log files related to authentication and authorization, search for customAuth.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Importing Assets for Inventory service, \n In Oracle Cloud Migrations, you can choose to import assets\n        from CSV files instead of setting up a source environment. In such a scenario, you can\u00e2\u0080\u0099t\n        take advantage of the automated discovery and replication modules. \nIn this scenario, the cost and recommendations during migrations are provided based on\n            the information from the CSV files.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Streaming service, \n Benefits of Streams, Streams have several advantages over traditional messaging queues,\n        including:\n\nConfigurable message persistence\nYou control how long your data is retained. Messages in a stream are immutable\n                    and available for the entirety of the stream's configured retention time.\nReplay\nBecause a stream's messages are not removed immediately when processed by\n                    consumers, you can replay any and all messages in the stream at any time within\n                    the configured retention limit.\nMessage guarantees\nEach message is guaranteed to be delivered at least once. In some cases, such as\n                    a consumer's failure to commit messages before going offline, messages may be\n                    delivered multiple times. \nOrder guarantees\nMessages within a stream, per partition, are always delivered in the same order\n                    that they were produced.\nClient-side cursors\nYour client applications control and track which messages are read and can\n                        move the cursor as needed for maximum flexibility.\nHorizontal scale\nPartitions provide an opportunity to scale up throughput to meet the needs of\n                    multiple consumers, resulting in increased flexibility.\nConsumer groups\nConsumer groups handle all of the coordination that is required to deliver\n                    messages to multiple consumers in a balanced manner. Because this management is\n                    handled by a consumer group on behalf of all of its members, you can enjoy\n                    reduced overhead and operational ease.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Detecting Anomalies for Large Datasets service, \n Learn how to create a job that detects anomalies using asynchronous detection.\n\nYou can use asynchronous detection to detect anomalies in both univariate and multivariate detection datasets.\n\nTypical use cases suited for asynchronous detecting are:\n\nDetecting anomalies in very large datasets\n\nThe maximum number of data points supported by the detectAnomalies REST Synchronous API is 30K. This might impose restrictions in anomaly detection scenarios where a large number of data points typically in the millions need to be detected. You can analyze and detect anomalies in very large datasets upwards of 10 million data points.\n\nAutomating detection workflows\n\nIn IoT use cases, time series data is usually collected from large number of sensors and devices, and stored in a persistent data store such as a database or a file system. Often, this raw data has to be preprocessed (enriched) using PaaS services such as Data Flow before performing inferencing. You can easily integrate the asynchronous detection API's within data processing pipelines, and automate detection workflows.\n\nPostprocessing anomalous events\n\nIn certain anomaly detection scenarios, the detection data (detected anomalies) might need to be transformed or enriched before it can be consumed by downstream applications. With asynchronous detection, detected anomalies are saved in an Object Store bucket. You can use PaaS services such as Data Flow to analyze, process, and enrich the anomalous events. Furthermore, you can consume and render the anomalies in visualization graphs in Oracle Analytics Cloud to enable you to monitor target systems and take corrective actions.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, API Gateway Metrics service, \n \nYou can monitor the health, capacity, and performance of API\u00c2\u00a0gateways and API deployments\n            managed by the\u00c2\u00a0API Gateway service using metrics\u00c2\u00a0, alarms\u00c2\u00a0, and notifications. \nThis topic describes the metrics emitted by the API Gateway service in the oci_apigateway metric namespace.\nResources: gateways\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Harvesting Data Sources service, \n Deleting a Folder, \nHere\u00e2\u0080\u0099s how you delete a folder:\n\nAccess the Data Assets tab by clicking Data Assets on the Home tab.\n\nIn the Data Assets list, click the data asset that has the folder you want to\n          delete.\n\nFrom the Data Asset details tab, click the folder sub-tab. The folder sub-tab could be\n          named Buckets, Schemas, or Folders depending on the type of data assets.\n\nClick the folder you want to delete.\n\nFrom the folder details page, click Delete.\n\nClick Delete to confirm deletion.\n\n\nThe folder is deleted successfully.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Notebook Sessions service, \n Sizing Notebook Sessions, \nFor notebook sessions, we recommend you use a shape that has memory that's equivalent to three times the amount of data you want to process. For example for a 10 GB dataset, a VM.Standard2.2 or VM.Standard2.4 is a good option.\nIt's also a matter of budget and speed. Whenever you can, we recommend using GPUs. If you are using a VM.Standard2.16 or 2.24, we recommend you switch to GPUs. GPUs are more expensive, but the speed increase generally results in a reduction in cost for large operations. For example: we trained an XGBoost model on 11M rows that ran in about seven seconds on a GPU. The same model on a VM.Standard2.24 with all cores utilized took more than twenty minutes. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Securing Cloud Advisor service, \n Data Durability, \nCloud Advisor creates backups daily. No configuration is necessary.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Application Dependency Management Policies service, \n You use the Oracle Cloud Infrastructure Identity and Access Management (IAM) service to create policies.\nBy default, only users in the Administrators group can access all resources and functions in Application Dependency Management. To control non-administrator user access to Application Dependency Management resources and functions, you create IAM groups and then write policies that give those groups proper access. If you are new to IAM policies, see Getting Started with Policies.\nFor a complete list of Oracle Cloud Infrastructure policies, see Policy Reference and Common Policies.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Scenario: Split Messages by Metric Stream service, \n Setting Up This Scenario, Setup involves creating a threshold alarm enabled for metric stream-specific messages. In this hypothetical scenario, you select the custom metric MyCustomCPUMetric and the resource group MyServerResourceGroup.\nYou can complete these tasks in the Oracle Cloud Infrastructure\nConsole, CLI, or API.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Events service, \n How Events Works, \nOracle Cloud Infrastructure services emit events, which are structured messages that indicate changes in resources. Events (the messages, not the service) follow the CloudEvents industry standard format hosted by the Cloud Native Computing Foundation (CNCF). This standard allows for interoperability between various cloud providers or on-premises systems and cloud providers. An event could be a create, read, update, or delete (CRUD) operation, a resource lifecycle state change, or a system event impacting a resource. For example, an event can be emitted when a backup completes or fails, or a file in an Object Storage bucket is added, updated, or deleted. \nServices emit events for resources or data. For example, Object Storage emits events for buckets and objects. Services emit different types of events for resources, which are distinguished as event types. Buckets and objects have event types of create, update, and delete, for example. Event types are the changes that produce events by a given resource. For a list of services that produce events and the event types that those services track, see Services that Produce Events. \n  You work with events by creating rules. Rules include a filter you define to specify events produced by the resources in your tenancy. The filter is flexible: \n\nYou can define filters that match only certain events or all events. \nYou can define filters based on the way resources are tagged or the presence of specific values in attributes from the event itself. \n\nRules must also specify an action to trigger when the filter finds a matching event. Actions are responses you define for event matches. You set up select Oracle Cloud Infrastructure services that the Events service has established as actions (more on these select services follows). The resources for these services act as destinations for matching events. When the filter in the rule finds a match, the Events service delivers the matching event to one or more of the destinations you identified in the rule. The destination service that receives the event then processes the event in whatever manner you defined. This delivery provides the automation in your environment. \nYou can only deliver events to certain Oracle Cloud Infrastructure services with a rule. Use the following services to create actions:\u00c2\u00a0\n\n\nNotifications\n\nStreaming\n\nFunctions\n\n\n\n\n \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Certificates service, \n Authentication and Authorization, \nEach service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all\n            interfaces (the Console, SDK or CLI, and REST API).\nAn administrator in your organization needs to set up groups\u00c2\u00a0, compartments\u00c2\u00a0, and policies\u00c2\u00a0 that control which users can access which\n            services, which resources, and the type of access. For example, the policies control who\n            can create new users, create and manage the cloud network, launch instances, create\n            buckets, download objects, etc. For more information, see Getting Started with Policies. For specific details about\n            writing policies for each of the different services, see Policy Reference.\nIf you\u00e2\u0080\u0099re a regular user (not an administrator) who needs to use the Oracle Cloud Infrastructure resources that your company owns, contact\n            your administrator to set up a user ID for you. The administrator can confirm which\n            compartment or compartments you should be using.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Cloud Shell and Regions, \nWhen you start Cloud Shell, the service configures your Cloud Shell session with the currently selected region in the Console so that the OCI CLI is interacting with the selected Console region.\nIn the default bash prompt in Cloud Shell, the region that the OCI CLI is interacting with is echoed in the Cloud Shell command line prompt:\n\n\n\nAny changes to the selected region in Console after you've started your Cloud Shell session will not have an effect on your active Cloud Shell session.If you want to change the region that the OCI CLI is interacting with, in Cloud Shell, you can either:\n\nExit your current Cloud Shell session, then change the selected region in the Console, then start a new Cloud Shell session.\nModify the currently selected OCI CLI profile via the OCI_CLI_PROFILE environment variable\n\nFor more information, see the \"Managing Regions\" section in Using Cloud Shell. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n \n When using Oracle Cloud Infrastructure, sometimes you need to get help from the community or to talk to someone in Oracle support. This topic provides more information about accessing these tools.\n Tip Console announcements appear at the top of the Console to communicate\n            timely, important information about service status. For more information, see Console\n            Announcements.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Agent Management service, \n Verify Agent Installation, \nWindows:\n\nConnect to the instance.\nOpen Services.msc (Start menu and type services.msc). Scroll\n                until you see the \"Oracle Unified Monitoring Agent\" and that the agent is in a\n                \"Running\" state.\nIn the Task Scheduler under Task Scheduler Library, verify that the\n                    UnifiedAgentConfigUpdater exists, and has (or will) run successfully.\n                After the initial install, it can take up to 20 minutes for the first run. If\n                preferred, this can be run manually.\nAfter the UnifiedAgentConfigUpdater task has run, verify that a\n                \"unified-monitoring-agent.conf\" file in exists in\n                    C:\\oracle_unified_agent.\nAfter a few minutes, supervisor (unified-monitoring-agent-supervisor-0.log) logs and\n                worker (unified-monitoring-agent-0.log) logs appear in the\n                    C:\\oracle_unified_agent directory. \nThe preceding logs contain the Fluentd parser and plugin output.\n\nOracle Linux 7, Oracle Linux 8, CentOS 7, CentOS 8, CentOS Stream 8, Ubuntu 16, Ubuntu\n                18, and Ubuntu 20:\n\nConnect to the instance.\nCheck that the agent is running by running the following\n                command:systemctl status unified-monitoring-agent\nThe status looks like the\n                following:Loaded: loaded (/usr/lib/systemd/system/unified-monitoring-agent.service; enabled; vendor preset: disabled)\nActive: active (running) since Thu 2020-09-10 18:11:45 GMT; 2h 14min ago\nDocs: https://docs.cloud.oracle.com/\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Queries service, \n Error: Exceeded Maximum Metric Streams, Troubleshoot too many metric streams when querying metric data.\n\nAn error indicates that the metric query exceeded the maximum number of metric streams\u00c2\u00a0.\n\n\n\nThis issue occurs when the query evaluates too many metric streams.\n\nLimits information for returned data includes the 100,000 data point maximum and time range maximums (determined by resolution, which relates to interval). See MetricData.\n\n\n\n\n\n\nTo remedy this issue, update the query to evaluate a number of metric streams that is within the limit.\nFor example, select dimensions to reduce the number of metric streams. See Selecting Dimensions for a Query.\nTo evaluate all metric streams that were in the original query, spread the metric streams across multiple queries.\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Data Integration, For known issues with  Data Integration, see Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n \n When using Oracle Cloud Infrastructure, sometimes you need to get help from the community or to talk to someone in Oracle support. This topic provides more information about accessing these tools.\n Tip Console announcements appear at the top of the Console to communicate\n            timely, important information about service status. For more information, see Console\n            Announcements.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Speech Overview service, \n Authentication and Authorization, \n\nEach service in OCI integrates with IAM for authentication\n                and authorization, for all interfaces (the Console,\n                SDK or CLI, and REST API).\nAn administrator in your organization needs to set up groups\u00c2\u00a0, compartments\u00c2\u00a0, and policies\u00c2\u00a0 that control which users can access which services, which\n                resources, and the type of access. For example, the policies control who can create new users, create and manage the cloud network,\n                launch instances, create buckets, download objects, etc. For more information, see Getting Started with Policies.\n\nFor details about writing Speech policies, see\n                        About Speech Policies.\nFor details about writing policies for other services, see Policy Reference.\n\nIf you\u00e2\u0080\u0099re a regular user (not an administrator) who needs to use the OCI resources that your company owns, contact your administrator to set up a user\n                ID for you. The administrator can confirm which compartment or compartments you\n                should be using.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Container Registry service, \n Authentication and Authorization, \n\nEach service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nAn administrator in your organization needs to set up groups\u00c2\u00a0, compartments\u00c2\u00a0, and policies\u00c2\u00a0 that control which users can access which services, which resources, and the type of access. For example, the policies control who can create new users, create and manage the cloud network, launch instances,  create buckets, download objects, etc. For more information, see Getting Started with Policies. For specific details about writing policies for each of the different services, see Policy Reference. \nIf you\u00e2\u0080\u0099re a regular user (not an administrator) who needs to use the Oracle Cloud Infrastructure resources that your company owns, contact your administrator to set up a user ID for you. The administrator can confirm which compartment or compartments you should be using.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Container Instances, \nFor known issues with Container Instances, see Known Issues for Container Instances. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n Post a Question to Oracle Forums, \nIf you cannot find an answer to your question through search, submit a new question to\n            one of the forums that Oracle supports. This option is available to all customers.\nCloud Customer Connect\nFor any issue related to Oracle Cloud Infrastructure, including provisioning of new resources, Console issues, identity, networking, documentation, storage, database, Edge services, or other solutions, you can post a question to Cloud Customer Connect at:\nhttps://community.oracle.com/customerconnect/categories/oracle-cloud-infrastructure-and-platform\nIf you are using only Always Free resources or using a Free Tier account, then use\n                Cloud Customer Connect for support queries.\n\nStack Overflow\nIf you are creating an application that integrates with Oracle Cloud Infrastructure APIs, endpoints, or services, then you\n                can also use Stack Overflow forums for development-related questions. Tag your\n                questions with oracle-cloud-infrastructure, as\n                follows:\nhttps://stackoverflow.com/questions/tagged/oracle-cloud-infrastructure\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Viewing Work Requests service, \n \nMany Container Engine for Kubernetes service requests do not take effect\n            immediately. For example, the creation of a node pool isn't completed until all required\n            instances are active. In these cases, the request is fulfilled asynchronously, and its\n            progress tracked by an associated work request. A work request is an activity log that\n            provides visibility into in-progress asynchronous operations, enabling you to track each\n            step in the operation's progress. Each work request has an OCID that allows you to\n            interact with it programmatically and use it for automation. \nWork requests include information about the time the request started and finished. If an\n            operation fails, a work request can help you determine which step of the process had an\n            error. Some operations affect multiple resources. For example, creating a node pool also\n            affects instances. A work request provides a list of the resources that an operation\n            affects.\nFor more information, see Work Requests\n            and the Work Requests API.\nNode Pool Work Requests\nResources managed by Container Engine for Kubernetes can only\n                support one work request at a time. Work requests launched while another work\n                request is in progress will fail and return a conflict. Because some operations\n                depend on the completion of other operations, you must monitor each operation\u00e2\u0080\u0099s work\n                request and confirm it has succeeded before proceeding to the next operation. A\n                create node pool work request has a status of Succeeded when the workflow\n                successfully creates an instance and the instance is registered with an\n                    Active status. \n\nWork Request Status\nThe following table lists work request states:\n\n\nStatus\n\n\nDescription\n\n\n\nAccepted\n\n\nThe request is in the work request queue to be processed.\n\n\n\nIn Progress\n\n\nA work request record exists for the specified request, but no associated\n                            WORK_COMPLETED record exists.\n\n\n\nSucceeded\n\n\nA work request record exists for this request and an associated\n                            WORK_COMPLETED record has the state\n                            Succeeded.\n\n\n\nFailed\n\n\nA work request record exists for this request and an associated\n                            WORK_COMPLETED record has the state Failed.\n\n\n\nCanceling\n\n\nThe work request is in the process of canceling.\n\n\n\nCanceled\n\n\nThe work request has been canceled.\n\n\n\nRequired IAM Policy for Viewing Work Requests\n\nTo use Oracle Cloud Infrastructure, you must be granted security\n                access in a policy\u00c2\u00a0 by an administrator. This access\n                is required whether you're using the Console or the\n                REST API with an SDK, CLI, or other tool. If you get a message that you don\u00e2\u0080\u0099t have\n                permission or are unauthorized, verify with your administrator what type of access\n                you have and which compartment\u00c2\u00a0 to work in.\n\nFor administrators: Work requests inherit the permissions of the operation that\n                spawns the work request. To enable users to view the work requests, logs, and error\n                messages for an operation, write a policy that grants users permission to do the\n                operation. For example, to let users see the work requests associated with launching\n                instances, write a policy that enables users to launch instances.\nTo enable users to list all work requests in a tenancy, use the following policy:\nAllow group SupportTeam to inspect work-requests in tenancy\nIf you're new to policies, see Getting Started with Policies and Common Policies.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Scanning Function Images for Vulnerabilities service, \n Required IAM Policy for Scanning Function Images for Vulnerabilities, \nIf you enable repositories for image scanning, you must give the Vulnerability Scanning service permission to pull images from Container Registry.\nTo grant this permission for all images in the entire tenancy:allow service vulnerability-scanning-service to read repos in tenancy\nallow service vulnerability-scanning-service to read compartments in tenancy\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, About Oracle Managed Cloud Self-Service Platform service, \n \nThe Oracle Managed Cloud Self-Service Platform initiative enables a modernized experience\n            by offering self-service capabilities to MCS customers at OCI. The Self-Service Platform\n            delivers capabilities and automation used by MCS Operations directly for use by the\n            customer. It improves service agility while delivering a modernized managed application\n            lifecycle experience.\nDashboard\nThe Dashboard tab provides a short description of the product, together with release\n                notes covering the new features and site alerts.\nBy default, a customer will be displayed. Click the drop-down to select the\n                customer.\n\nHelp\nThe Help includes links to the Oracle Managed Cloud Self-Service Platform\n                documentation.\n\nAvatar/User\nThe Avatar/User includes Preferences and Log Out option. The Preferences contain\n                General Preferences, and CEMLIs (Preferences, Products, Customers). You can manage\n                your preferences, custom products, and customers from here.\n\nCEMLI\nOracle Managed Cloud Self-Service Platform provides a range of tools and services\n                designed to manage CEMLIs (Configurations, Extensions, Modifications, Localizations,\n                and Integrations) associated with your Oracle E-Business Suite environment. Manage\n                the full CEMLI lifecycle using this portal, from cataloging existing modifications\n                to investigating change and performance impact, and offering reliable and consistent\n                customization delivery across your infrastructure.\nManage Data Fixes, similar to customization, associated with you Oracle E-Business\n                Suite environment.\n\nConfigurations\nEnable/disable traces and make common configuration changes in a self-service mode\n                without the need for engaging Oracle teams.\nIf the customer you've selected has access rights only, the Configurations menu will\n                be displayed. Configurations page displays all the RFC executions the user has\n                submitted.\n\nBounce\nUsers can work with self-service Bounce to shut down, start up, and bounce DB Tier\n                and MidTiers and/or MidTier components (individual or combination of components).\n                Bounce is only applicable to NON-PROD instances.\n\nExadata CPU Scaling\nUsers can scale up or scale down the number of OCPUs assigned to their Exadata\n                infrastructure as well as the OCPUs assigned to individual databases hosted on that\n                infrastructure without a downtime. Scale Up/Scale Down activities can be scheduled\n                to be executed in the future.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Adding Stock Responses as an API Gateway Back End service, \n Editing a JSON File to Add Stock Responses to an API Deployment Specification, \nTo add stock responses to an API\u00c2\u00a0deployment specification in a JSON file:\u00c2\u00a0\n\n\nUsing your preferred JSON editor, edit the existing API deployment specification to which you want to add a\u00c2\u00a0stock response back end, or create a new API deployment specification (see Creating an API Deployment Specification).\nFor example, the following basic API deployment specification defines a simple Hello World serverless function in OCI Functions as a single back end:{\n  \"routes\": [\n    {\n      \"path\": \"/hello\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n        \"type\": \"ORACLE_FUNCTIONS_BACKEND\",\n        \"functionId\": \"ocid1.fnfunc.oc1.phx.aaaaaaaaab______xmq\"\n      }\n    }\n  ]\n}\n\n\nIn the routes section, include a new path section for a stock response  back end:{\n  \"routes\": [\n    {\n      \"path\": \"/hello\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n        \"type\": \"ORACLE_FUNCTIONS_BACKEND\",\n        \"functionId\": \"ocid1.fnfunc.oc1.phx.aaaaaaaaab______xmq\"\n      }\n    },\n    {\n      \"path\": \"<api-route-path>\",\n      \"methods\": [\"<method-list>\"],\n      \"backend\": {\n        \"type\": \"STOCK_RESPONSE_BACKEND\",\n        \"status\": <http-response-code>,\n        \"headers\": [{\n          \"name\": \"<header-name>\",\n          \"value\": \"<header-value>\"\n        }],\n        \"body\": \"<body-content>\"\n      }\n    }\n  ]\n}\nwhere:\n\n\n<api-route-path> specifies a path for API calls using the listed methods to the stock response back end. Note that the route path you specify:\n\n is relative to the deployment path prefix (see Deploying an API on an API Gateway by Creating an API Deployment)\nmust be preceded by a forward slash ( / ), and can be just that single forward slash\ncan contain multiple forward slashes (provided they are not adjacent), and can end with a forward slash\ncan include alphanumeric uppercase and lowercase characters\ncan include the special characters $ - _ . + ! * ' ( ) , % ; : @ & = \n\ncan include parameters and wildcards (see Adding Path Parameters and Wildcards to Route Paths)\n\n\n<method-list> specifies one or more methods accepted by the stock response back end, separated by commas. For example, \"GET, PUT\".\n\"type\": \"STOCK_RESPONSE_BACKEND\" indicates that the API\u00c2\u00a0gateway itself will act as the back end and return the stock response you define (the status code, the header fields and the body content).\n<http-response-code> is any valid HTTP response code. For example, 200 \n\"name\": \"<header-name>\", \"value\": \"<header-value>\" optionally specifies the name of an HTTP\u00c2\u00a0response header and its value. For example, \"name\": \"Content-Type\", \"value\":\"application/json\" . You can specify multiple \"name\": \"<header-name>\", \"value\": \"<header-value>\" pairs in the headers: section (up to a maximum of 50). Note that in each case:\n<header-name> must not exceed 1KB in length\n<header-value> must not exceed 4KB in length\n\"body\": \"<body-content>\" optionally specifies the content of the response body, in an appropriate format. For example:\n If the Content-Type header is text/plain, the response body might be \"body\": \"Hello world\".\n If the Content-Type header is application/json, the response body might be \"body\": \"{\\\"username\\\": \\\"john.doe\\\"}\". In the case of a JSON response, note that quotation marks in the response have to be escaped with a backslash ( \\ ) character.Note that <body-content> must not exceed 5KB in length (including any encoding).\nIn this example, a request to the /test path returns a 200 status code and a JSON payload in the body of the response.{\n  \"routes\": [\n    {\n      \"path\": \"/hello\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n        \"type\": \"ORACLE_FUNCTIONS_BACKEND\",\n        \"functionId\": \"ocid1.fnfunc.oc1.phx.aaaaaaaaab______xmq\"\n      }\n    },\n    {\n      \"path\": \"/test\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n        \"type\": \"STOCK_RESPONSE_BACKEND\",\n        \"status\": 200,\n        \"headers\": [{\n          \"name\": \"Content-Type\",\n          \"value\": \"application/json\"\n        }],\n        \"body\" : \"{\\\"username\\\": \\\"john.doe\\\"}\"\n      }\n    }\n  ]\n}\nIn this example, a request to the /test-redirect path returns a 302 status code and a temporary url in the Location header of the response. This example also demonstrates that you can create an API deployment specification with just one route to a back end of type STOCK_RESPONSE_BACKEND.{\n  \"routes\": [\n    {\n      \"path\": \"/test-redirect\",\n      \"methods\": [\"GET\"],\n      \"backend\": {\n        \"type\": \"STOCK_RESPONSE_BACKEND\",\n        \"status\": 302,\n        \"headers\": [{\n          \"name\": \"Location\",\n          \"value\": \"http://www.example.com\"\n        }]\n      }\n    }\n  ]\n}\n\nSave the JSON\u00c2\u00a0file containing the API deployment specification.\n\nUse the API deployment specification when you create  or update an API deployment in the following ways:\n\nby specifying the JSON file in the Console when you select the Upload an existing API option\nby specifying the JSON file in a request to the API Gateway REST\u00c2\u00a0API\nFor more information, see Deploying an API on an API Gateway by Creating an API Deployment and Updating API Gateways and API Deployments.\n\n(Optional) Confirm the API has been deployed successfully by calling it (see Calling an API Deployed on an API Gateway).\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Viewing Work Requests service, \n Listing Work Requests, List the work requests for a cluster or node pool resource.\nUse one of the following methods to display a list of work requests for a selected\n            cluster or node pool resource.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Key Concepts service, \n Business Insight Metrics, \nThe Business Insight functionality in Oracle Pulse uses two categories of metrics:\n\n\nKey Performance Indicators (KPI) metrics provide high-level insight into a\n                    critical business measurement, such as inventory levels or accounts status. KPI\n                    metrics can be tracked visually via a Business Insight chart. In addition,\n                    thresholds and alerting can be configured for these KPI charts, assisting\n                    proactive tracking.\n\n\nDetailed metrics are metrics associated with the KPI metric which provide\n                    further insight into any issues identified in the KPI chart. These metrics are\n                    visible via the table view. For example, if the KPI chart indicates that the\n                    percentage of accounts with the Open status is too high ahead of your\n                    Period-Close event, the table view can provide complementary data highlighting\n                    the name of the accounts, which geographical region they belong to, or who is a\n                    contact point in that region. Together, the KPI chart and the table view\n                    facilitate you in proactively tracking your key business objectives, and provide\n                    you with further insight to interpret the KPI measurements and to take\n                    data-driven action.\n\n\nThe Business Insight widget on the Pulse Dashboard provides a high-level summary view of\n            provisioned Business Insight reports. For more information, see the Business Insight Widget section in Checking the Performance of Your Services.\nThe Business Insight dashboard summarizes information about the metrics that you\n            requested to include in your Business Insight report, allowing you to monitor your\n            metrics of interest. For more information, see the Monitoring Business Insight Metrics section in\n                Using the Business Insight Reports.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating a Container Instance service, \n Networking Requirements, \nWhen you specify a container image, the registry that the image lives in must be reachable from the subnet that you provide for the container instance. If the container image lives in Container Registry, specify the image in a subnet in a VCN with a service gateway. If the container image lives in an external registry hosted on the public internet, specify the image in a public subnet in a VCN with an internet gateway or in a private subnet in a VCN with a NAT gateway.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview of Audit service, \n Authentication and Authorization, \n\nEach service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nAn administrator in your organization needs to set up groups\u00c2\u00a0, compartments\u00c2\u00a0, and policies\u00c2\u00a0 that control which users can access which services, which resources, and the type of access. For example, the policies control who can create new users, create and manage the cloud network, launch instances,  create buckets, download objects, etc. For more information, see Getting Started with Policies. For specific details about writing policies for each of the different services, see Policy Reference. \nIf you\u00e2\u0080\u0099re a regular user (not an administrator) who needs to use the Oracle Cloud Infrastructure resources that your company owns, contact your administrator to set up a user ID for you. The administrator can confirm which compartment or compartments you should be using.\n\nAdministrators: For an example of policy that gives groups access to audit logs, see Required IAM Policy. To modify the Audit log retention period, you must be a member of the Administrators group. See The Administrators Group and Policy.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Using Consumer Groups service, \n \nConsumers can be configured to consume messages as part of a group. In a production\n            environment with multiple partitions, using a consumer group is our recommended method\n            of consuming Streaming messages.\nEach stream partition is assigned to a member of a consumer group. An individual member\n            of a consumer group is called an instance. Each instance in a consumer group\n            receives messages from one or more partitions, unless there are more instances than\n            partitions. Instances in excess of the partition count for the stream do not receive\n            messages.\nConsumer groups handle the coordination that is required for multiple consumers to share\n            the consumption of a stream. A consumer group automatically:\n\nAssigns one or more partitions to an instance\nTracks the messages received by the group and manages commits\nRequests the proper partition(s) and offset(s) on behalf of each instance\nBalances the group as instances join or leave\n\nUp to 50 consumer groups can read from a single stream. Each consumer group receives all\n            of the messages in the stream at least once.\nConsumer groups are ephemeral. They disappear when they're not used for the retention\n            period of the stream.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Starting Job Runs service, \n Using the Console, \n\nLog into your tenancy using the Console with the necessary policies.\n\nOpen the navigation menu and click Analytics & AI.\n                    Under Machine Learning, click Data\n                        Science.\n\nSelect the compartment that contains the project you want to use. \n\nClick the name of a project. \n\nClick Jobs.\n\nSelect a job to work with.\n\nClick start a job run.\n(Optional) \n                Select a different compartment for the job. \n(Optional) \n                Enter a unique name for the job run (limit of 255 characters). If you don't\n                    provide a name, a name is automatically generated for you. \nFor example:jobrun20210808222435\n(Optional) \n                To use logging, click Select, and then ensure that\n                    Enable logging is selected.\n\n\nSelect a log group from the list. You can change to a different\n                            compartment to specify a log group in a different compartment from the\n                            job.\n\n\nSelect one of the following to store all stdout and stderr messages:\n\n\nEnable automatic log creation\n\nData Science automatically creates a log when the job starts.\n\nSelect a log\n\nSelect a log to use.\n\n\n\n\n\n(Optional) \n                Click Select to return to the job run creation\n                    page.\n(Optional) \n                You can override the default job configuration that was defined when the job\n                    was created using these options:\n\n\nCustom environment variable key\n\nEnvironment variables to control the job.\n\nValue\n\nValue for your custom environment variable key.\nYou can click Additional custom environment\n                                        variables to specify more variables.\n\nCommand line arguments\n\nThe command line arguments that you want to use for running the\n                                    job. \n\nMaximum runtime (in minutes)\n\nThe maximum number of minutes that the job can run. The service\n                                    cancels the job run if its runtime exceeds the specified value.\n                                    The maximum runtime is 30 days. We recommend that you configure\n                                    a maximum runtime on all job runs to prevent runaway job\n                                    runs.\n\n\n\n(Optional) \n                Add tags to easily locate and track the resource by selecting a tag namespace,\n                    then entering the key and value. To add more than one tag, click +Additional\n                        Tags.\n\nTagging describes the various tags\n                        that you can use organize and find resources including cost-tracking tags.\n\n\nClick Start.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Overview service, \n The Anomaly Detection service is a multi-tenant service that analyzes large volume of multivariate or univariate time series data.\nThe Anomaly Detection is, accessible over public ReST APIs by authenticated users by using the OCI CLI, SDK or Console. The service is powered by machine learning (ML) and statistical algorithms that understand the complex relationships between different signals in diverse system components. The Anomaly Detection service increases the reliability of businesses by monitoring their critical assets and detecting anomalies early with high precision.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Contents of an Audit Log Event service, \n An Example Audit Log, \nThe following is an example of an event recorded by the Audit service. \n{\n\t\"eventType\": \"com.oraclecloud.ComputeApi.GetInstance\",\n\t\"cloudEventsVersion\": \"0.1\",\n\t\"eventTypeVersion\": \"2.0\",\n\t\"source\": \"ComputeApi\",\n\t\"eventId\": \"<unique_ID>\",\n\t\"eventTime\": \"2019-09-18T00:10:59.252Z\",\n\t\"contentType\": \"application/json\",\n\t\"data\": {\n\t\t\"eventGroupingId\": null,\n\t\t\"eventName\": \"GetInstance\",\n\t\t\"compartmentId\": \"ocid1.tenancy.oc1..<unique_ID>\",\n\t\t\"compartmentName\": \"compartmentA\",\n\t\t\"resourceName\": \"my_instance\",\n\t\t\"resourceId\": \"ocid1.instance.oc1.phx.<unique_ID>\",\n\t\t\"availabilityDomain\": \"<availability_domain>\",\n\t\t\"freeformTags\": null,\n\t\t\"definedTags\": null,\n\t\t\"identity\": {\n\t\t\t\"principalName\": \"ExampleName\",\n\t\t\t\"principalId\": \"ocid1.user.oc1..<unique_ID>\",\n\t\t\t\"authType\": \"natv\",\n\t\t\t\"callerName\": null,\n\t\t\t\"callerId\": null,\n\t\t\t\"tenantId\": \"ocid1.tenancy.oc1..<unique_ID>\",\n\t\t\t\"ipAddress\": \"172.24.80.88\",\n\t\t\t\"credentials\": null,\n\t\t\t\"userAgent\": \"Jersey/2.23 (HttpUrlConnection 1.8.0_212)\",\n\t\t\t\"consoleSessionId\": null\n\t\t},\n\t\t\"request\": {\n\t\t\t\"id\": \"<unique_ID>\",\n\t\t\t\"path\": \"/20160918/instances/ocid1.instance.oc1.phx.<unique_ID>\",\n\t\t\t\"action\": \"GET\",\n\t\t\t\"parameters\": {},\n\t\t\t\"headers\": {\n\t\t\t\t\"opc-principal\": [\n\t\t\t\t\t\"{\\\"tenantId\\\":\\\"ocid1.tenancy.oc1..<unique_ID>\\\",\\\"subjectId\\\":\\\"ocid1.user.oc1..<unique_ID>\\\",\\\"claims\\\":[{\\\"key\\\":\\\"pstype\\\",\\\"value\\\":\\\"natv\\\",\\\"issuer\\\":\\\"authService.oracle.com\\\"},{\\\"key\\\":\\\"h_host\\\",\\\"value\\\":\\\"iaas.r2.oracleiaas.com\\\",\\\"issuer\\\":\\\"h\\\"},{\\\"key\\\":\\\"h_opc-request-id\\\",\\\"value\\\":\\\"<unique_ID>\\\",\\\"issuer\\\":\\\"h\\\"},{\\\"key\\\":\\\"ptype\\\",\\\"value\\\":\\\"user\\\",\\\"issuer\\\":\\\"authService.oracle.com\\\"},{\\\"key\\\":\\\"h_date\\\",\\\"value\\\":\\\"Wed, 18 Sep 2019 00:10:58 UTC\\\",\\\"issuer\\\":\\\"h\\\"},{\\\"key\\\":\\\"h_accept\\\",\\\"value\\\":\\\"application/json\\\",\\\"issuer\\\":\\\"h\\\"},{\\\"key\\\":\\\"authorization\\\",\\\"value\\\":\\\"Signature headers=\\\\\\\"date (request-target) host accept opc-request-id\\\\\\\",keyId=\\\\\\\"ocid1.tenancy.oc1..<unique_ID>/ocid1.user.oc1..<unique_ID>/8c:b4:5f:18:e7:ec:db:08:b8:fa:d2:2a:7d:11:76:ac\\\\\\\",algorithm=\\\\\\\"rsa-pss-sha256\\\\\\\",signature=\\\\\\\"<unique_ID>\\\\\\\",version=\\\\\\\"1\\\\\\\"\\\",\\\"issuer\\\":\\\"h\\\"},{\\\"key\\\":\\\"h_(request-target)\\\",\\\"value\\\":\\\"get /20160918/instances/ocid1.instance.oc1.phx.<unique_ID>\\\",\\\"issuer\\\":\\\"h\\\"}]}\"\n\t\t\t\t],\n\t\t\t\t\"Accept\": [\n\t\t\t\t\t\"application/json\"\n\t\t\t\t],\n\t\t\t\t\"X-Oracle-Auth-Client-CN\": [\n\t\t\t\t\t\"splat-proxy-se-02302.node.ad2.r2\"\n\t\t\t\t],\n\t\t\t\t\"X-Forwarded-Host\": [\n\t\t\t\t\t\"compute-api.svc.ad1.r2\"\n\t\t\t\t],\n\t\t\t\t\"Connection\": [\n\t\t\t\t\t\"close\"\n\t\t\t\t],\n\t\t\t\t\"User-Agent\": [\n\t\t\t\t\t\"Jersey/2.23 (HttpUrlConnection 1.8.0_212)\"\n\t\t\t\t],\n\t\t\t\t\"X-Forwarded-For\": [\n\t\t\t\t\t\"172.24.80.88\"\n\t\t\t\t],\n\t\t\t\t\"X-Real-IP\": [\n\t\t\t\t\t\"172.24.80.88\"\n\t\t\t\t],\n\t\t\t\t\"oci-original-url\": [\n\t\t\t\t\t\"https://iaas.r2.oracleiaas.com/20160918/instances/ocid1.instance.oc1.phx.<unique_ID>\"\n\t\t\t\t],\n\t\t\t\t\"opc-request-id\": [\n\t\t\t\t\t\"<unique_ID>\"\n\t\t\t\t],\n\t\t\t\t\"Date\": [\n\t\t\t\t\t\"Wed, 18 Sep 2019 00:10:58 UTC\"\n\t\t\t\t]\n\t\t\t}\n\t\t},\n\t\t\"response\": {\n\t\t\t\"status\": \"200\",\n\t\t\t\"responseTime\": \"2019-09-18T00:10:59.278Z\",\n\t\t\t\"headers\": {\n\t\t\t\t\"ETag\": [\n\t\t\t\t\t\"<unique_ID>\"\n\t\t\t\t],\n\t\t\t\t\"Connection\": [\n\t\t\t\t\t\"close\"\n\t\t\t\t],\n\t\t\t\t\"Content-Length\": [\n\t\t\t\t\t\"1828\"\n\t\t\t\t],\n\t\t\t\t\"opc-request-id\": [\n\t\t\t\t\t\"<unique_ID>\"\n\t\t\t\t],\n\t\t\t\t\"Date\": [\n\t\t\t\t\t\"Wed, 18 Sep 2019 00:10:59 GMT\"\n\t\t\t\t],\n\t\t\t\t\"Content-Type\": [\n\t\t\t\t\t\"application/json\"\n\t\t\t\t]\n\t\t\t},\n\t\t\t\"payload\": {\n\t\t\t\t\"resourceName\": \"my_instance\",\n\t\t\t\t\"id\": \"ocid1.instance.oc1.phx.<unique_ID>\"\n\t\t\t},\n\t\t\t\"message\": null\n\t\t},\n\t\t\"stateChange\": {\n\t\t\t\"previous\": null,\n\t\t\t\"current\": null\n\t\t},\n\t\t\"additionalDetails\": {\n\t\t\t\"imageId\": \"ocid1.image.oc1.phx.<unique_ID>\",\n\t\t\t\"shape\": \"VM.Standard1.1\",\n\t\t\t\"type\": \"CustomerVmi\"\n\t\t}\n\t}\n}\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Rules for Events service, \n \nThis topic describes how to manage rules for the Events service. For more information about Events, see Overview of Events.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Media Flow, \nFor known issues with Media Flow, see Known Issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Cloud Shell service, \n Required IAM Policy, \nTo get started with Cloud Shell, you\u00e2\u0080\u0099ll need to grant user access to Cloud Shell via an IAM policy. Each service in Oracle Cloud Infrastructure integrates with IAM for authentication and authorization, for all interfaces (the Console, SDK or CLI, and REST API).\nTo use Oracle Cloud Infrastructure, you must be given the required type of access in a policy written by an administrator in the tenancy's root compartment, whether you're using the Console or the REST API with an SDK, CLI, or other tool. If you try to perform an action and get a message that you don\u00e2\u0080\u0099t have permission or are unauthorized, confirm with your administrator that you've been granted access.\n Note  Cloud Shell does not support policies at the compartment level, only at the\n                tenancy level.The resource name for Cloud Shell is `cloud-shell`. The\n            following is an example policy to grant access to Cloud Shell:\nallow group <GROUP-NAME> to use cloud-shell in tenancy\n\nThis example policy shows how to allow a group within a domain to use Cloud\n            Shell:allow group <DOMAIN-NAME>/<GROUP-NAME> to use cloud-shell in tenancy\nIf you're new to policies, see Getting Started with Policies and Common Policies.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Remote Agent Appliances service, \n Prerequisites, \nBefore you start using the remote agent appliance in OCI, perform the following tasks:\nAdd the required IAM policies.\n\nInstall a Remote Agent Appliance for VMware vCenter\n\n\nRegister the Remote Agent Appliance\n\n\nDNS Resolution\nFor the replication to work, the Remote Agent Appliance must have connectivity to a\n                domain name system (DNS) server that resolves addresses for names in the\n                    oraclecloud.com domain and the fully qualified domain names\n                (FQDN) of VMware infrastructure components (vCenter server and ESXi hosts).\nTo verify if your DNS resolution is working properly before deploying your virtual appliance, perform the following steps:\n\nFind the IP address of the DNS server that you intend to use (for example,\n                        10.0.2.1).\nConnect to the vCenter management interface, and find an FQDN used by a host (for example, esx1.vcluster.mycompany.local ).\nTo see if the name is properly resolved, run a DNS diagnostic tool. MacOS and\n                    most Linux distribution have domain information groper (dig) tool preinstalled.\n                    The dig that you can use for verification is, dig @{dns_server_IP}\n                        {FQDN}. Example: dig @10.0.2.1\n                        esx1.vcluster.mycompany.local\n\nIf correct IP address of the host is returned in the output, then your DNS resolution is working properly. To correctly configure the DNS, see VMware and DNS server documentation.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Load Balancer Metrics service, \n Describes the metrics emitted by the Load Balancer service in the oci_lbaas metric namespace.\nYou can monitor the health, capacity, and performance of your load balancers by using metrics, alarms, and notifications. See Monitoring and Notifications for general information on how to understand and use the various Oracle Cloud Infrastructure monitoring tools available to you.\nYour load balancer acts as an intermediary for data traffic between clients and your\n            application servers. Clients send requests to your load balancer and the load balancer\n            distributes the requests to your backend servers according to rules you establish. See\n            the diagram in Overview of Load Balancer for a high-level view of\n            a simple public load balancing system configuration.\nThe Load Balancer service metrics help you measure the number and type of connections, and quantity of data managed by your load balancer. You can use metrics data to diagnose and troubleshoot load balancer and client issues. The metrics also help you analyze the HTTP responses returned by the servers in your backend set. \nTo view a default set of metrics charts in the Console, navigate to the load balancer or backend set you're interested in, and then click Metrics. You also can use the Monitoring service to create custom queries.\nSee Viewing Load Balancer Metrics to view the available\n            types of metrics for a load balancer.\nPrerequisites\n\nIAM policies: To monitor resources, you must be given the required type of access in a policy\u00c2\u00a0 written by an administrator, whether you're using the Console or the REST API with an SDK, CLI, or other tool. The policy must give you access to the monitoring services as well as the resources being monitored. If you try to perform an action and get a message that you don\u00e2\u0080\u0099t have permission or are unauthorized, confirm with your administrator the type of access you've been granted and which compartment\u00c2\u00a0 you should work in. For more information about user authorizations for monitoring, see IAM Policies (Monitoring).\n\nThe metrics listed on this page are automatically available for any load\n                        balancer, listener, and backend set you create. You do not need to enable\n                        monitoring on the resource to get these metrics.\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Function Development Kits (FDKs) service, \n How to upgrade an existing function to use the latest FDK build-time and runtime base\n        image version for a supported language, \nTo upgrade an existing function so that the Fn Project CLI uses the latest FDK build-time\n            and runtime base image versions for a supported language to build the function\n            executable, and to provide the runtime environment:\n\nIf it hasn't already been upgraded, upgrade the Fn Project CLI to the most recent\n                version (version 0.6.7 or later). See Upgrading the Fn Project CLI.\nIn a terminal window, change to the directory containing the function code and open\n                the func.yaml file in a text editor.The build_image: and\n                        run_image: parameters show the FDK build-time and runtime\n                    base image versions currently being used by the Fn Project CLI to build the\n                    function executable, and to provide the runtime environment. For\n                    example:build_image: fnproject/fn-java-fdk-build:jdk11-1.0.105\nrun_image: fnproject/fn-java-fdk:jre11-1.0.105If the\n                        build_image: and run_image: parameters are\n                    not present in the func.yaml file, use the fn build or\n                        fn deploy commands to build the function. Doing so will add\n                    the build_image: and run_image: parameters to\n                    the func.yaml file, set to the FDK build image and runtime image versions\n                    currently being used by the Fn Project CLI.\n\nFind out the FDK build-time image and runtime base image versions for the version\n                    of the language you want the Fn Project CLI to use (see How to find out the latest FDK build-time and runtime base image versions for a particular supported language version). \n\nOpen the func.yaml file in a text editor (if it's not already open), and update it\n                as follows:\nChange the values of the build_image: and\n                            run_image: parameters to the FDK build-time and runtime\n                        base image versions you identified in the previous step.For example, you\n                            might\n                            change:build_image: fnproject/fn-java-fdk-build:jdk11-1.0.105\nrun_image: fnproject/fn-java-fdk:jre11-1.0.105tobuild_image: fnproject/fn-java-fdk-build:jdk11-1.0.130\nrun_image: fnproject/fn-java-fdk:jre11-1.0.130\nFor consistency and to avoid confusion, change the value of the\n                            runtime: parameter to correspond to the\n                            --runtime command option for the version of the\n                        language. For example:runtime: java11\n\nFor Java functions only, open the pom.xml file in a text editor and update the\n                    <fdk.version> element to correspond to the version specified\n                in the func.yaml.For example, you might change\n                        <fdk.version>1.0.105</fdk.version> to\n                        <fdk.version>1.0.130</fdk.version>.\nDeploy the function again and test it to confirm that the function code is\n                compatible with the new FDK build-time and runtime base image versions that the Fn\n                Project CLI is now using to build the function executable, and to provide the\n                runtime environment.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Service Connectors service, \n How Do I Know When Issues Occur?, Identify when issues occur with service connectors.\n\n\n\nLook for the following indicators of issues with service connectors.\n\nData freshness for a single service connector: Look for unexpected lapses of time between data movement. \nOpen the navigation menu and click Analytics & AI. Under Messaging, click Service Connector Hub.\nChoose a Compartment.\nClick the name of the service connector that you want.\nUnder Resources, click Metrics.\nReview the Data Freshness metric chart.\n\nData freshness across service connectors: Look for unexpected lapses of time between data movement. \n\nOpen the navigation menu and click Observability & Management. Under Monitoring, click Service Metrics. \n\nReview the following metric charts:\u00c2\u00a0\nData Freshness\n\nTo view data freshness for all service connectors in a compartment\n\nOpen the navigation menu and click Observability & Management. Under Monitoring, click Service Metrics. \n\nChoose the Compartment that contains the service connectors you want to view data freshness for.\n\nFor Metric namespace, select oci_service_connector_hub.\n\nReview the following metric charts:\u00c2\u00a0\nData Freshness\n\n\n\nLogging source: If your service connector retrieves data from a log, then it might be attempting more than the maximum amount of hourly retrieval of data per connector (1 GB). Log data at the target is not delivered if this issue continues to occur past 24 hours (the maximum duration for catching missed data in previous transmissions by the service connector). To determine if this issue is occurring, create alarms to monitor the following indicators.\n Note For steps to edit alarm queries in MQL, see Editing the MQL Expression When Updating an Alarm.\n\n\nIndicator (Metric)\nAlarm query in MQL, with comments\n\n\n\nData older than 12 hours (Data Freshness)\n\nDataFreshness[1h].mean() > 43200000\nComments:\n\nThe value 43200000 is the number of milliseconds in 12 hours.\nAlarm trigger delay can be 1 minute or more.\n\n\n\n\nError at source (any error) (Errors at Source)\n\nErrorsAtSource[15m].groupby(errorCode,connectorId).min() > 0\nComments:\n\nSet the alarm trigger delay for 15 minutes. When the alarm trigger delay is set to 15 minutes, the alarm checks for service connectors that have had no successful runs in the last 15 minutes.\nResults are grouped by error code and service connector.\n\n\n\n\nInternal errors at source that don't resolve after 15 minutes (5xx) (Errors at Source)\n\nErrorsAtSource[15m]{errorCode =~ \"5*\"}.groupby(connectorId).sum() > 0 && \nErrorsAtSource[15m].groupby(connectorId).min() > 0\nComments:\n\nInternal errors might indicate an issue at the source, which could delay delivery of data.\nTo trigger the alarm at shorter intervals, change the interval ([15m]).\nTo delay the trigger, change the alarm trigger delay.\nAlarm trigger delay can be 1 minute or more.\n\n\n\n\nThrottling errors at source (429) (Errors at Source)\n\nErrorsAtSource[15m]{errorCode = \"429\"}.groupby(connectorId).sum() >0 && \nErrorsAtSource[15m].groupby(connectorId).min() > 0\nComments:\n\nFor more information on throttling errors, see documented limits for the relevant service.\nFor example, for throttling errors related to the Streaming source, see Limits on Streaming Resources. Throttling at the Streaming source occurs when a service connector attempts to read a stream from a partition, other calls to the same partition are also occurring, and the number of calls exceeds service limits. \nAlarm trigger delay can be 1 minute or more.\n\n\n\n\nService communication errors at source (-1) (Errors at Source)\n\nErrorsAtSource[15m]{errorCode = \"-1\"}.groupby(connectorId).sum() >0 && \nErrorsAtSource[15m].groupby(connectorId).min() > 0\n\n\n\n404 error at source (Errors at Source)\n\nErrorsAtSource[15m]{errorCode = \"404\"}.groupby(connectorId).sum() >0\nComments:\n\nEither the service connector can't access the log or it doesn't exist.\nEnsure that policies exist for accessing the specified log. See Access to Source, Task, and Target Services.\nConfirm that the specified log exists by searching for it in Logging.\nAlarm trigger delay can be 1 minute or more.\n\n\n\n\nZero bytes read (when data is expected) (Bytes Read from Source)\n\nBytesReadFromSource[15m].groupby(connectorId).sum() == 0\nComments:\n\nIf errors are not occurring at source, target, or task, then the log might not exist. Confirm that the specified log exists by searching for it in Logging.\nAlarm trigger delay can be 1 minute or more.\n\n\n\n\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Document Understanding service, \n Pretrained Models, Troubleshoot common problems with pretrained models in Document Understanding.When analyzing a small, image-based document, you get the error, Error status: 500\n          Internal error occurred.\nThe image size is smaller than the  minimum size for an image-based document of 32x32 pixels.\nUse a suitably sized image.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Audit Logs service, \n \nOn the Audit page, you can explore audit logs. Audit logs are also\n            searchable on the Search page, and you can view Audit logs in\n            every compartment by selecting the /_Audit log group on the\n                Search page. For an overview of Audit, see Overview of Audit.\n Note This page replaces the classic Audit page features found in the\n                Governance & Administration portion of the\n            Console, which will eventually be deprecated. As a result, a new and improved\n                Audit experience is now part of Oracle Cloud Infrastructure Logging, and we recommend you use this latest\n            version of Audit instead.\nRequired Permissions for Audit Logs\nTo view and search Audit logs, you must have the corresponding Audit-related\n                permissions. See Details for the Audit Service\n                and Required Permissions for Searching Logs for more\n                information.\n\nFiltering Audit Logs\nTo filter Audit logs:\n\n\nOpen the navigation menu and click Observability & Management. Under Logging, click Audit. The\n                        list of audit logs in the current compartment is displayed.\nChoose a compartment you have permission to work in.\nIn User, add user filters. Multiple users can be\n                        added.\nIn Resource, add resource filters. Multiple resources\n                        can be filtered on.\nIn Request action types, select an action\n                            operation:\nGET\nPOST\nPUT\nPATCH\nDELETE\nMultiple request action types can be filtered on.\nIn Event type, add event filters. Multiple event\n                        filters can be added.\nIn Custom filters, start typing to automatically\n                        display filter settings, along with operators. For example, entering\n                            d displays filters starting with that letter. Use\n                        the up or down arrow keys to select from the list, or continue typing to\n                        enter what you want to filter on. This functions the same as this field on\n                        the Logging Search page. Note If you want to find log\n                            events with a specific status code, include quotes (\") around the code\n                            to avoid results that have those numbers embedded in a longer\n                            string.\nIn Filter by time, select from one of the preset time\n                            periods:\nPast 5 Minutes (the default)\nPast 15 Minutes \nPast Hour\nPast 3 Hours\nToday\nCustom (choose your own using the Start Date\n                                and End Date fields)\n\nAfter entering your search text or filters, click\n                            Apply. Note Since the\n                                Audit page automatically refreshes after\n                            applying filters, you do not need to click the\n                                Apply button as you select different filters.\n                            You will, however, need to click Apply again\n                            after some time has passed and new logs have appeared. \n\n\nThe Convert to search option allows viewing your Audit Log\n                results in the Search page, to further search and perform\n                analysis across other logs in the system. When you use this option, the Advanced Search version\n                of the Search page is filled with the chosen filter\n                parameters (available in the Query field).\nClick View query syntax to view the actual syntax query\n                statement(s) associated with your filter settings. If you have applied multiple\n                filters for a field, you can view how the query is constructed in terms of the\n                combined OR and AND statements.\n\nExploring the Details of Events\nOn the Explore events tab, each log entry is organized in\n                terms of the Event Time, User,\n                    Resource, Type,\n                    Action, and Status. Click and\n                expand an audit log entry. Each entry displays the log data in a JSON field view,\n                similar to the Search page, where you can collapse and expand\n                nodes, or click the copy icon to copy the log entry to the clipboard.\nTo export log dataAt the top right portion of Explore events, click\n                            Export Log Data (JSON). This feature allows you\n                        to export the log data to a JSON file that you can save to your system.\n\nViewing the Activity Stream\nClick the Activity stream tab to view the audit logs as a\n                visual sequential list (by date, from newest to oldest log event). You click and\n                expand an event to display the event in JSON format, and you can click the copy icon\n                to copy the audit event to the clipboard.\n\nExporting Audit Events\nAudit events can be exported using Service Connector Hub. \n\nAudit Schema\nSee Version 2 Audit Log Schema for more information on the audit logging schema.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating a Topic service, \n Create a topic in Notifications."
    },
    {
        "text": "oracle cloud infrastructure, oci, Scenario: Sending Metrics to Object Storage service, \n Using the Console, \n\n\nOpen the navigation menu and click Analytics & AI. Under Messaging, click Service Connector Hub.\n\n\nChoose the Compartment where you want to create the service connector.\n\n\nClick Create Service Connector.\n\n\nOn the Create service connector page, move metrics to an Object Storage bucket:\n\nType a Connector name. Avoid entering confidential information. Example: \"Metrics to Bucket\"\nSelect the Resource compartment where you want to store the new service connector.\nUnder Configure service connector, select your source and target services to move log data to a metric:\nSource: Monitoring\nTarget: Object Storage\n\nUnder Configure source, select the compute instance and block volume metrics in each compartment:\n\nMetrics compartment: The first compartment containing the compute instances and block volumes you want metrics for.\n\n\nNamespaces: Select oci_computeagent and oci_blockstore.\n\n\nClick + Another compartment to add the second compartment.\n\n\nMetrics compartment: The second compartment containing the compute instances and block volumes you want metrics for.\n\n\nNamespaces: Select oci_computeagent and oci_blockstore.\n\n\nSkip the optional task (Configure task). \nUnder Configure target, select the bucket you want to move the metrics to: \nSelect the Compartment that contains the bucket.\nSelect the Bucket you want.\n\n\n\n\nIf you are prompted to create a policy (required for the service connector to access source, task, and target services), click Create.\n\n\nClick Create.\nThe new service connector immediately begins moving metrics to the selected bucket.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Oracle Support Rewards Overview service, \n Viewing the Rewards Summary, \nTo view the rewards summary and other details, open the navigation menu and click Billing & Cost Management. Under\n          Programs and Rewards, click Oracle\n        Support Rewards. The Oracle Support Rewards page is\n      displayed.\n Note If your subscription and products are eligible for rewards but there is no associated\n      usage, a message is displayed to indicate that no rewards data was found (since no rewards\n      data has accrued yet).\nThe page allows you to view rewards by subscription, which you can select from the\n      corresponding Subscription list. The following rewards summary is\n      shown:\n\nAvailable Support Rewards: The total amount of accrued rewards you\n        can use.\nRedeemed Support Rewards: The total amount of rewards you have\n        redeemed.\nCurrent Contractual Rate: The rewards accrual rate. For example,\n        customers can accrue rewards either at $0.25 for every $1 of OCI usage, or $0.33 for every $1 of OCI usage if they have a ULA (Unrestricted License\n        Agreements).\nExpiring Soon: The rewards amount that expires within 30 days.\n\nFollowing the rewards summary, a more detailed tabular view of your rewards is listed:\n\n\nField\nDescription\n\n\n\nExpiration Date\nThe date when rewards expire.\n\n\nAccrual Date\nThe date the rewards were earned.\n\n\nTotal Usage\nThe total usage amount evaluated for rewards (Eligible\n                Usage + Non-Eligible Usage = Total\n                Usage).\n\n\nEligible Usage\nThe amount of usage that is eligible for rewards spending.\n\n\nNon-Eligible Usage\nThe amount of usage not eligible for rewards.Note: Not all usage accrues rewards.\n                Consumption of third-party services and offerings, such as VMware, Microsoft, and\n                Oracle Cloud Marketplace, are not eligible to earn rewards. See https://www.oracle.com/cloud/rewards/faq/\n                for more information.\n\n\nAccrued Rewards\nThe sum of any remaining rewards. Equivalent to Available Support\n                Rewards in the rewards summary.\n\n\nRedeemed\nThe amount of redeemed rewards. Equivalent to Redeemed Support\n                Rewards in the summary. \n\n\nRemaining\nThe amount of remaining (Accrued Rewards -\n                Redeemed) rewards. Remaining rewards that are expiring soon\n              are highlighted in red.Note: Eligible usage details are not available for months where\n                reward information was uploaded manually.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Resizing a Cluster service, \n Vertical Resizing, \nVertical resizing allows you to increase the memory and OCPU resources for your cluster's\n            master nodes, data nodes, and OpenSearch Dashboard nodes. You can also increase the\n            amount of available storage for the data nodes only. This form of scaling enables you to\n            increase the performance of your search clusters.\nFor most vertical resizing scenarios to improve performance, you will only scale up the\n            data nodes. If your scenario requires network traffic to be routed more quickly, you\n            should scale up master nodes. If your scenario requires a lot of chart-related work for\n            your OpenSearch Dashboard, you should scale up the OpenSearch Dashboard nodes.\nYou can increase all vertical resize settings during the same vertical resize operation,\n            except for the data node storage setting. You can only increase the data node storage\n            during a vertical resize operation where no other settings are being adjusted. When you\n            increase the data node storage, the cluster's search functionality remains in read/write\n            mode. \n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Scenario: Sending Metrics to Object Storage service, \n Learn how to send metrics to a bucket in Object Storage using Service Connector Hub. \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, About Vision Policies service, \n Policy to Access Training Datasets in Object Storage, The policies required to access training datasets in Object Storage from Vision in the\n    same tenancy or cross-tenancy.\n\n\nSame tenancy training dataset access\nIf your customized training dataset is located in your tenancy's Object Storage, then create a group in the tenancy to\n            authorize the users who can access the Object Storage\n            there. Add the following policy in your tenancy at the root compartment level to grant\n            object storage USE permission to the\n            group:allow group <group_in_tenancy> to use object-family in compartment <training-dataset-located-object-storage-compartment>\nCross-tenancy training dataset access\nIf your customized training dataset is located in tenancy_B object store, and your\n            user group in tenancy_A, then you must define an ENDORSE READ policy on the user group\n            in tenancy\n            A:define tenancy <tenancy_B> as <tenancy_B_ocid>\nendorse group <group_in_tenancy_A> to read object in tenancy <tenancy_B>\nYou must also define an ADMIT READ policy in tenancy_B for the user group in\n            tenancy_A:define tenancy <tenancy_A> as <tenancy_A_ocid>\ndefine group <group_in_tenancy_A> as <group_in_tenancy_A_ocid>\nadmit group <group_in_tenancy_A> of tenancy <tenancy_A> to read object in compartment <training-dataset-located-object-storage-compartment>\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Signing Function Images and Enforcing the Use of Signed Images from Registry service, \n Creating a Signature Verification Policy for an Application, \nTo define a signature verification policy for an application and specify a master encryption key that can be used to sign images:\n\n\nSign in to the Console as a functions developer.\n\nIn the Console, open the navigation menu and click Developer Services. Under Functions, click Applications.\nSelect the region you are using with OCI Functions. Oracle recommends that you use the same region as the Docker registry that's specified in the Fn Project CLI context (see Creating an Fn Project CLI Context to Connect to Oracle Cloud Infrastructure). \n\nSelect the compartment containing the application for which you want to define a signature verification policy.\nThe Applications page shows all the applications in the compartment you selected.\n\nClick the name of the application for which you want to define a signature verification policy.\nUnder Resources, click Signature Verification.\nClick Manage Signature Verification.\nSelect Enable signature verification policies for this application to enable the application to use the signature verification policy you define. If a policy to grant OCI Functions access to Oracle Cloud Infrastructure Registry does not already exist, you are prompted to create such a policy. If you're an administrator, create the policy. Otherwise, ask your administrator to create the policy for you. See Required IAM Policies for Enforcing the Use of Signed Images.\n\nSelect a master encryption key in Oracle Cloud Infrastructure Vault that must have been used to sign images.\nIf policies to grant OCI Functions access to the master encryption key in Oracle Cloud Infrastructure Vault do not already exist, you are prompted to create such policies. If you're an administrator, create the policies. Otherwise, ask your administrator to create the policies for you. See Required IAM Policies for Enforcing the Use of Signed Images.\nNote that any existing functions in the application must be based on images that have already been signed by the master encryption key that you select. Otherwise, you will not be able to create the signature verification policy.\n\n\nClick Save Changes.\n\n\nFrom now on:\n\nWhen you deploy a function in this application (for example, using the fn deploy command), you have to set image signing options. These options identify the master encryption key in the application's signature verification policy, including the OCID of the master encryption key. Assuming you specify a valid master encryption key, the image is pushed to Oracle Cloud Infrastructure Registry and signed with the encryption key.\nWhen you create a new function (or update an existing function) in this application using the Console or the Fn Project CLI, you have to specify an existing image that has been signed using the master encryption key in the application's signature verification policy. \nWhen a function in this application is invoked, OCI Functions first verifies the image in Oracle Cloud Infrastructure Registry. OCI Functions only pulls the image from Oracle Cloud Infrastructure Registry and invokes the function if encryption key verification is successful. \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Troubleshooting Oracle Cloud Agent service, \n Step 4: Generate a Diagnostic File for Oracle Cloud Agent, \nTo make it easier for Oracle support to help you troubleshoot issues with the Oracle Cloud Agent software, you can run the Oracle Cloud Agent diagnostic tool on your compute instances. The diagnostic tool generates a file that contains debugging information and logs for the plugins that Oracle Cloud Agent manages.\nThe diagnostic tool is installed with Oracle Cloud Agent version 1.14.0 and later. To update Oracle Cloud Agent, see Updating the Oracle Cloud Agent Software.\nAfter you complete the previous troubleshooting steps, run the diagnostic tool and then file a support ticket with the file that contains debugging information and logs for the plugins.\nTo generate a diagnostic file on a Linux instance\nConnect to the instance.\n\nChange directories to the folder where the diagnostic tool is saved:\ncd /usr/bin/ocatools\n\n\nRun the diagnostic tool:\nsudo ./diagnostic\nThe tool generates a TAR file with a name in the format oca-diag-<date>.<identifier>.tar.gz. Provide the file when you open your support request.\n\n\nTo generate a diagnostic file on a Windows instance\nConnect to the instance.\n\nChange directories to the folder where the diagnostic tool is saved:\ncd C:\\Program Files\\Oracle Cloud Agent\\ocatools\n\n\nOpen PowerShell as an administrator. Then, run the diagnostic tool:\n.\\diagnostic.ps1\nThe tool generates a ZIP file and saves it to C:\\Users\\opc\\Desktop\\. Provide the file when you open your support request.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Preparing for API Gateway service, \n Availability by Region, \nThe API Gateway service is available in the Oracle Cloud Infrastructure regions listed at Regions and Availability Domains. Refer to that topic to see region identifiers, region keys, and availability domain names.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Function Metrics service, \n \nYou can monitor the health, capacity, and performance of functions you've deployed to OCI Functions by using metrics\u00c2\u00a0, alarms\u00c2\u00a0, and notifications. \nThis topic describes the metrics emitted by the metric namespace oci_faas (the OCI Functions service).\nResources: functions\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Extend Console Pages Using Schema Documents service, \n Requirements for Schema Documents, \nSchema documents for Resource Manager have the following\n            requirements:\n\n\nYAML format.\n\n\nData types must be consistent with the associated Terraform configuration.\nFor example, let\u00e2\u0080\u0099s say that you declare the type number for the availability variable in the schema. In this situation, availability must have the same declared type (number) in the associated Terraform configuration. (By default, variables with no declared type use string.)\n\n\nPlacement under the root folder of the Resource Manager Terraform configuration. (By default, the schema document assumes that the root folder is the working directory.)\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Getting Help and Contacting Support service, \n Use Support Chat in the Console, \nUse Support Chat to get immediate help with common issues. To connect to the Oracle Support Digital Assistant: Open the \nHelp menu () and click Chat with us.\nA chat window opens that connects you to My Oracle Support.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Work Requests service, \n Viewing Work Requests, Follow these steps to view work requests for a dataset in Data Labeling.\n\nFollow one of the two ways to display the list of work requests:\n\nOn the dataset's details page, click More\n                            Actions, then click View work\n                                requests. \nFrom the Dataset list page, click Work\n                            requests.\nThe list of work requests for the compartment displays, showing the\n                    operation type, status, percent completion, accepted date and time, and finished\n                    date and time.\n\nClick the operation type you want to view, and the Work Request Details page\n                    displays.\nBy default, log messages are displayed, showing the timestamp and message for\n                    each log. You can display error messages by clicking Error\n                        messages. The timestamp, type, and message are shown for each\n                    error. Revert to the logs by clicking Log\n                    messages.\n\nTo see the log or error message in full:\n\n\nClick the action icon next to the message you want to view.\nClick View full message. The Log messages, or\n                            Error messages panel displays, with the full message.\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Managing Certificate Authorities service, \n Use Certificates to create and manage the certificate\n        authorities that issue digital certificates.\nCertificate authority (CA) management tasks include the following:\n\nCreating a CA\nViewing CA details\nEditing CA details\nEditing the certificate revocation list (CRL)\nIssuing a subordinate CA\nViewing associations\nEditing CA rules\nRenewing a CA to create a new CA version\nMoving a CA to a different compartment\nDeleting a CA\n\nEvery CA has one or more CA versions. As such, CA management also includes the following\n            tasks specific to CA versions:\n\nViewing CA version bundles\nMaking a CA version the current version of a CA\nRevoking a CA version (supported for subordinate CAs only)\nDeleting a CA version\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Artifact Registry IAM Policies service, \n Details for Verb + Resource-Type Combinations, Identify the permissions and API operations covered by each verb for Artifact\n        Registry resources.\n\nThe level of access is cumulative as you go from inspect to\n                    read to use to manage.\nA plus sign (+) in a table cell indicates incremental access when\n                compared to the preceding cell.\n\nartifact-repositories\nThis table lists the permissions and the APIs that are fully covered by that\n                permission, for the artifact-repositories resource.\nThe artifact-repositories resource has no API that requires more\n                than one permission.\n\n\nVerbs\nPermissions\nAPIs Fully Covered\n\n\n\ninspect\nARTIFACT_REPOSITORY_INSPECT\nListRepositories\n\n\nread\n\ninspect+\nARTIFACT_REPOSITORY_READ\n\n\ninspect+\nGetRepository\n\n\n\nuse\n\nread+\nARTIFACT_REPOSITORY_UPDATE\n\n\nread+\nUpdateRepository\n\n\n\nmanage\n\nuse+\nARTIFACT_REPOSITORY_CREATE\nARTIFACT_REPOSITORY_DELETE\nARTIFACT_REPOSITORY_MOVE\n\n\nuse+\nCreateRepository\nDeleteRepository\nChangeRepositoryCompartment\n\n\n\n\ngeneric-artifacts\nThis table lists the permissions and the APIs that are fully covered by that\n                permission, for the generic-artifacts resource.\nThe generic-artifacts resource has no API that requires more than\n                one permission.\n\n\nVerbs\nPermissions\nAPIs Fully Covered\n\n\n\ninspect\nGENERIC_ARTIFACT_INSPECT\nListGenericArtifacts\n\n\nread\n\ninspect+\nGENERIC_ARTIFACT_READ\n\n\ninspect+\nGetGenericArtifact\nGetGenericArtifactContent\nGetGenericArtifactByPath\nGetGenericArtifactContentByPath\n\n\n\nuse\n\nread+\nGENERIC_ARTIFACT_UPDATE\n\n\nread+\nUpdateGenericArtifact\nUpdateGenericArtifactByPath\n\n\n\nmanage\n\nuse+\nGENERIC_ARTIFACT_CREATE\nGENERIC_ARTIFACT_DELETE\n\n\nuse+\nPutGenericArtifactContentByPath\nDeleteGenericArtifact\nDeleteGenericArtifactByPath\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Application Dependency ManagementOverview service, \n Key Concepts and Terminology, \nThe following terminology will help you get started with Application Dependency Management. The Oracle Cloud Infrastructure documentation provides related terminology.\n\nKnowledge Base\nA knowledge base is associated with vulnerability audits. When you configure a vulnerability audit, you specify the knowledge base with which it is associated.\n\n\nVulnerability\nA vulnerability is a weakness or error in a project artifact, such as an application dependency. A vulnerability is a generalization of an information security flaw, such as those described by the Common Vulnerabilities and Exposures (CVE) system. The National Vulnerability Database (NVD) provides a measure of the severity of a software vulnerability, using the Common Vulnerability Scoring System (CVSS), ranging from 0 to 10. The NVD supports both CVSS v2.0 and v3.X standards. For more information about vulnerability metrics, see National Vulnerability Database.\n\n\nVulnerability Audit\nA vulnerability audit describes the vulnerabilities of your application and its dependencies. A vulnerability audit is associated with a knowledge base.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Configuring a Private Network service, \n Detaching a Private Endpoint, You detach a private endpoint from the data catalog it is attached to before you can\n        delete the private endpoint. Also, if you want to attach a different private endpoint to a\n        data catalog, you must detach any private endpoint already attached to the data\n        catalog.\n\nHere's how you detach a private endpoint from a data catalog.\n\n\nFrom the Data Catalogs page in the Console, click the Actions menu for the data catalog where you want to detach a private endpoint and then select Detach Private Endpoint.\n\nFrom the Detach Private Endpoint dialog, click Yes, Detach.\n\n\nA notification displays indicating that the private endpoint is being detached from\n                the data catalog. A notification is also displayed after the private endpoint is\n                detached successfully from the data catalog.\n Important The data catalog data assets that use the private endpoint that\n                you detached from the data catalog can no longer be harvested again.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci,  Searching for Artifacts service, \n Search for artifacts by path or version prefix.\nPrefix Search\nTo organize related artifacts in a repository, you can name them with paths or\n                versions that start with the same string. Then, you can narrow down the list of a\n                repository's artifacts by using a prefix search.\nYou can use a prefix search for an artifact path or version:\n\n\n\nArtifact path prefix search: Enter a string to find artifact that\n                        begin with that string.\nFor example, you can search for project01 prefix and get the\n                        following results: \n\n\nproject01/my-test-app/test-artifact\nproject01/my-web-app/artifact-abc\n\n\n\n\nVersion prefix search: Enter a string to find artifact versions that\n                        begin with that string.\nFor example, you can search for 1.0 prefix and get the\n                        following results:\n\n\n1.0.0.1\n1.0.2\n\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Setting Up Contextual Notifications for an Instance service, \n Steps, \nThese steps show how to set up a contextual notification for an instance, for the first time.\n\nOpen the navigation menu and click Compute. Under Compute, click Instances.\n\nClick the instance that you're interested in.\n\nClick the Notifications tab.\n\nWhen no notifications exist for the instance, the Notifications tab lists quick start templates. \nAn example quick start template allows you to set up notifications for high CPU usage.\n\n\nClick the quick start template that you want.\n\nIn the Create Notification panel, scroll down to Topics and Subscriptions.\n\nA new topic is automatically set up for you to add contact information to.\n\n\nContact Information: Add at least one entry for where you want to receive messages.\n\n\n\nEmail: Enter an email address.\n\n\nSlack: Enter a Slack endpoint.\nEndpoint format:\nhttps://hooks.slack.com/services/<webhook-token>\n\nSMS (for cell phone text messages): Enter a phone number.\n\n\n(Optional) \n                Modify the default settings listed above Topic and Subscriptions.\n\nFor example, change the event type or alarm severity.\n\n\nClick Create Notification.\n\nMessages are sent to the contact information entries whenever the condition of the notification is satisfied.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Known Issues service, \n Events, \nCurrently, there are no known Events issues.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Features and Reports service, \n \nThe following features and reports are available in Oracle Pulse.\n\n\nGeneric features:\n\n\nService and Environment Configuration - I want to get lay-of-the-land information at a glance as far as the services, environments and hosts associated with the environments.\n\n\nIdentifying Contacts for Your Organization - I want to see all the contacts associated with my organization's services.\n\n\nViewing Notifications - I want to see all the active notifications associated with my organization's services.\n\n\nGenerating Reports for Different Time Periods - I want to change the reporting period for my Oracle Pulse reports.\n\n\nMy Charts and Environments - I want to define the charts and the environments subject to my Oracle Pulse reports.\n\n\nExporting Data - I want to have data available for later use.\n\n\n\n\nMenu-specific features:\n\n\nChecking the Performance of Your Services - I want to get high-level information about my production and non-production environments.\n\n\nUsing the Calendar Reports - I want to see the 52-week plan of the business events and Requests for Change (RFC) that have been worked out for my organization.\n\n\nUsing the Availability Reports - I want to see the latest representation of availability for my organization's services.\n\n\nUsing the Storage Reports - I want to understand how my storage resources are used.\n\n\nUsing the Business Transaction Monitoring Reports - I want to understand and manage the performance of my transaction processing system.\n\n\nUsing the Performance Reports - I want to see the load on different hosts and databases.\n\n\nUsing the Self Healing Reports - I want to see the corrective actions performed across all my services and environments.\n\n\nUsing the Incident Management Reports - I want to see reports of service requests across all my services and environments.\n\n\nUsing the Change Management Reports - I want to see reports of change requests across all my services and environments.\n\n\nUsing the Cloud Service Units Reports - I want to see details about the consumption, entitlement and procurement of my Cloud Service Units (CSU).\n\n\nUsing the Business Insight Reports - I want to get a business reporting view for my selected Oracle services.\n\n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Aggregating Metric Streams in a Query service, \n Examples, \n\n\nExample 1: Aggregate Metric Streams for count()\n\nServiceConnectorHubErrors[1m].grouping().count()\n\nExample 2: Aggregate Metric Streams for max()\n\nIopsRead[1m]{compartmentID = \"<compartment_OCID>\"}.grouping().max()\nIn this example, the query returns the maximum (max()) IopsRead metric data at a one-minute interval, filtered to a compartment, with all results aggregated. \n\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Contents of an Audit Log Event service, \n Resource Identifiers, \n\nMost types of Oracle Cloud Infrastructure resources have a unique, Oracle-assigned identifier called an Oracle Cloud ID (OCID). For information about the OCID format and other ways to identify your resources, see Resource Identifiers.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Load Balancer Timeout Connection Settings service, \n Keep-Alive Settings, \nThe Load Balancer service does not honor keep-alive settings\n            from backend servers. The load balancer closes backend server connections that are idle\n            for more than 300 seconds. Oracle recommends that you do not allow your backend servers\n            to close connections to the load balancer. To prevent possible 502 errors, ensure that\n            your backend servers do not close idle connections in less than 310 seconds.\n\nThe Load Balancer service sets the keep-alive value to maintain the connection for 10,000 transactions or until it has been idle for 65 seconds, whichever limit occurs first. \n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Deleting API Gateways and API Deployments service, \n Using the CLI, \nTo delete API gateways and API deployments using the CLI:\n\nConfigure your client environment to use the CLI (Configuring Your Client Environment to use the CLI for API Gateway Development).\n\nTo delete an existing API\u00c2\u00a0gateway: \n\n\nOpen a command prompt and run oci api-gateway gateway delete  to delete the API\u00c2\u00a0gateway:oci api-gateway gateway delete --gateway-id <gateway-ocid>\nwhere:\n\n<gateway-ocid> is the OCID of the API gateway to delete. To find out the API gateway's OCID, see Listing API Gateways and API Deployments.\nFor example:oci api-gateway gateway delete --gateway-id ocid1.apigateway.oc1..aaaaaaaab______hga\nNote that you cannot delete an API gateway if it still has API deployments on it (including API\u00c2\u00a0deployments that are in different compartments to the API\u00c2\u00a0gateway itself). You must delete the API\u00c2\u00a0deployments first.\nThe response to the command includes:\n\nThe lifecycle state (for example, DELETED, FAILED).\nThe id of the work request to delete the API gateway (details of work requests are available for seven days after completion, cancellation, or failure).\nIf you want the command to wait to return control until the API gateway has been deleted (or the request has failed), include either or both the following parameters:\n\n--wait-for-state DELETED\n\n--wait-for-state FAILED\n\nFor example:oci api-gateway gateway delete --gateway-id ocid1.apigateway.oc1..aaaaaaaab______hga --wait-for-state DELETED\n\n\n(Optional)\u00c2\u00a0To see the status of the work request that is deleting the API\u00c2\u00a0gateway, enter:oci api-gateway work-request get --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0To view the logs  of the work request that is deleting the API\u00c2\u00a0gateway, enter:oci api-gateway work-request-log list --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0If the work request that is deleting the API\u00c2\u00a0gateway fails and you want to review the error logs, enter:oci api-gateway work-request-error --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0\u00c2\u00a0To verify that the API\u00c2\u00a0gateway has been deleted, enter the following command and confirm that the API\u00c2\u00a0gateway's lifecycle state is DELETED:oci api-gateway gateway get --gateway-id <gateway-ocid>\n\n\n\nTo delete an existing API\u00c2\u00a0deployment:\n\n\nOpen a command prompt and run oci api-gateway deployment delete  to delete the API deployment:oci api-gateway deployment delete --deployment-id <deployment-ocid>\nwhere:\n\n<deployment-ocid> is the OCID of the API deployment to delete. To find out the API deployment's OCID, see Listing API Gateways and API Deployments.\nFor example:oci api-gateway deployment delete --deployment-id ocid1.apideployment.oc1..aaaaaaaaab______pwa\nThe response to the command includes:\n\nThe lifecycle state (for example, ACTIVE, DELETED).\nThe id of the work request to delete the API deployment (details of work requests are available for seven days after completion, cancellation, or failure).\nIf you want the command to wait to return control until the API deployment is active (or the request has failed), include either or both the following parameters:\n\n--wait-for-state DELETED\n\n--wait-for-state FAILED\n\nFor example:oci api-gateway deployment delete --deployment-id ocid1.apideployment.oc1..aaaaaaaaab______pwa --wait-for-state DELETED\n\n\n(Optional)\u00c2\u00a0To see the status of the work request that is deleting the API\u00c2\u00a0deployment, enter:oci api-gateway work-request get --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0To view the logs  of the work request that is deleting the API\u00c2\u00a0deployment, enter:oci api-gateway work-request-log list --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0If the work request that is deleting the API\u00c2\u00a0deployment fails and you want to review the error logs, enter:oci api-gateway work-request-error --work-request-id <work-request-ocid>\n\n\n(Optional)\u00c2\u00a0\u00c2\u00a0To verify that the API\u00c2\u00a0deployment has been deleted, enter the following command and confirm that the API\u00c2\u00a0deployment 's lifecycle state is DELETED:oci api-gateway deployment get --deployment-id <deployment-ocid>\n\n\n\nFor more information about using the CLI, see Command Line Interface (CLI). For a complete list of flags and options available for CLI commands, see CLI\u00c2\u00a0Help.\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating a Firewall service, \n Next Steps, \n\nView the network firewall work request.\nRoute traffic to the network firewall.\nMonitor the network firewall. \nTroubleshoot network firewalls and policies.\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Creating Applications service, \n Using the Console, \nTo  create a new application in  OCI Functions using the Console:\n\nConfirm that you have completed the steps in the Functions QuickStart Guides.\n\nSign in to the Console as a functions developer.\n\nIn the Console, open the navigation menu and click Developer Services. Under Functions, click Applications.\nSelect the region you are using with OCI Functions. Oracle recommends that you use the same region as the Docker registry that's specified in the Fn Project CLI context (see Creating an Fn Project CLI Context to Connect to Oracle Cloud Infrastructure). \n\nSelect the compartment specified in the Fn Project CLI\u00c2\u00a0context (see Creating an Fn Project CLI Context to Connect to Oracle Cloud Infrastructure).\nThe Applications page shows the applications already defined in the compartment.\n\n\nClick Create Application and specify:\n\nA name for the new application (for example, acmeapp). Avoid entering confidential information.\n\nThe VCN and subnet (or subnets, up to a maximum of three) in which to run functions. For example, a VCN\u00c2\u00a0called acme-vcn-01 and a public subnet called Public Subnet IHsY:US-PHOENIX-AD-1). Note that a public subnet requires an internet gateway in the VCN, and a private subnet requires a service gateway in the VCN. If a regional subnet has been defined, best practice is to select that subnet to make failover across availability domains simpler to implement. If a regional subnet has not been defined and you need to meet high availability requirements, select multiple subnets. Oracle recommends that the subnets are in the same region as the Docker registry that's specified in the Fn Project CLI context (see Creating an Fn Project CLI Context to Connect to Oracle Cloud Infrastructure).\nNote that specifying a private subnet for an application does not prevent access from the internet to the invoke endpoints of functions in the application. Use identity policies to control access to function invoke endpoints (see Controlling Access to Invoke and Manage Functions).\n\n\n\nClick Create.\nThe new application appears in the list of applications.\n\n\n"
    },
    {
        "text": "oracle cloud infrastructure, oci, Services that Produce Events service, \n Autonomous Recovery, \nFor more details about events emitted by the Autonomous Recovery Service, see Recovery Service Events.\n"
    }
]